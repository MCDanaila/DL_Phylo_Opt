{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(DynamicRegressionModel, self).__init__()\n",
    "        layers = [nn.Linear(input_size, hidden_sizes[0]), nn.ReLU()]\n",
    "        \n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            layers += [nn.Linear(hidden_sizes[i-1], hidden_sizes[i]), nn.ReLU()]\n",
    "        \n",
    "        layers += [nn.Linear(hidden_sizes[-1], output_size)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_TO_DROP = ['prune_name','rgft_name','orig_ds_ll','ll_prune','time_prune',\n",
    "                'd_ll_prune', 'orig_ds_id','ll_rgft','time_rgft', 'd_ll_merged',                 \n",
    "                'name2ntaxa_pruned_prune','name2ntaxa_remaining_prune',\n",
    "                'name2ntaxa_pruned_rgft','name2ntaxa_remaining_rgft']\n",
    "\n",
    "#COLS_TO_DROP = ['prune_name','rgft_name','orig_ds_ll','ll_prune','time_prune',\n",
    "#                'd_ll_prune', 'orig_ds_id','ll_rgft','time_rgft', 'd_ll_merged']\n",
    "\n",
    "TARGET_COL = 'd_ll_merged'\n",
    "\n",
    "file_path = './data/validation_data/learning_all_moves.csv'\n",
    "df = pd.read_csv(file_path, index_col='iteration', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are present 266 different datasets\n"
     ]
    }
   ],
   "source": [
    "groups = df['orig_ds_id']\n",
    "print(f'Are present {len(groups.unique())} different datasets')\n",
    "data = df.drop(COLS_TO_DROP, axis=1)\n",
    "\n",
    "labels = df[TARGET_COL].values\n",
    "features = data.values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "#scaler = RobustScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "features_tensor = torch.tensor(features_scaled, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 00:40:48,288] A new study created in memory with name: no-name-c68298de-dd09-4758-aded-657823b7e7b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fold 1\n",
      "Epoch [1/10], Loss: 7400.6753, AVGLoss: 28014.3609\n",
      "Epoch [2/10], Loss: 14990.5625, AVGLoss: 21731.5352\n",
      "Epoch [3/10], Loss: 11205.0771, AVGLoss: 17229.5196\n",
      "Epoch [4/10], Loss: 14147.7373, AVGLoss: 16079.6509\n",
      "Epoch [5/10], Loss: 6761.5991, AVGLoss: 15158.7718\n",
      "Epoch [6/10], Loss: 46965.9609, AVGLoss: 14321.9484\n",
      "Epoch [7/10], Loss: 11324.2051, AVGLoss: 13579.5589\n",
      "Epoch [8/10], Loss: 19528.2441, AVGLoss: 12993.6143\n",
      "Epoch [9/10], Loss: 4097.0659, AVGLoss: 12565.6541\n",
      "Epoch [10/10], Loss: 21152.4922, AVGLoss: 12208.5294\n",
      "Fold 1, MAE: 93.67870330810547, MSE: 26042.904296875, R^2: 0.32972757236738404\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 26112.5254, AVGLoss: 22308.5251\n",
      "Epoch [2/10], Loss: 3407.9590, AVGLoss: 16241.8058\n",
      "Epoch [3/10], Loss: 9133.9580, AVGLoss: 14536.7019\n",
      "Epoch [4/10], Loss: 10329.0547, AVGLoss: 14112.1211\n",
      "Epoch [5/10], Loss: 4473.9487, AVGLoss: 13809.7138\n",
      "Epoch [6/10], Loss: 9549.0742, AVGLoss: 13550.8261\n",
      "Epoch [7/10], Loss: 17834.3613, AVGLoss: 13363.2113\n",
      "Epoch [8/10], Loss: 8703.7178, AVGLoss: 13206.1122\n",
      "Epoch [9/10], Loss: 12082.6670, AVGLoss: 13075.8247\n",
      "Epoch [10/10], Loss: 23188.7168, AVGLoss: 12967.1500\n",
      "Fold 2, MAE: 98.63751983642578, MSE: 50996.328125, R^2: 0.4044019704473243\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 9316.9941, AVGLoss: 27612.5329\n",
      "Epoch [2/10], Loss: 12889.1768, AVGLoss: 20593.6179\n",
      "Epoch [3/10], Loss: 5960.7798, AVGLoss: 17337.1790\n",
      "Epoch [4/10], Loss: 8369.7002, AVGLoss: 16390.2028\n",
      "Epoch [5/10], Loss: 11387.8291, AVGLoss: 15653.3086\n",
      "Epoch [6/10], Loss: 10594.5312, AVGLoss: 14976.4741\n",
      "Epoch [7/10], Loss: 20828.8828, AVGLoss: 14344.0801\n",
      "Epoch [8/10], Loss: 15071.6162, AVGLoss: 13802.9558\n",
      "Epoch [9/10], Loss: 18338.9941, AVGLoss: 13385.1823\n",
      "Epoch [10/10], Loss: 5740.8721, AVGLoss: 13020.8334\n",
      "Fold 3, MAE: 82.29425048828125, MSE: 22841.845703125, R^2: 0.39559088640565987\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 14390.6953, AVGLoss: 27937.0299\n",
      "Epoch [2/10], Loss: 12960.0312, AVGLoss: 19375.1801\n",
      "Epoch [3/10], Loss: 19215.8047, AVGLoss: 16825.1647\n",
      "Epoch [4/10], Loss: 12232.3916, AVGLoss: 16044.6981\n",
      "Epoch [5/10], Loss: 10240.1533, AVGLoss: 15316.4934\n",
      "Epoch [6/10], Loss: 20517.7031, AVGLoss: 14634.5481\n",
      "Epoch [7/10], Loss: 9864.7822, AVGLoss: 14082.7694\n",
      "Epoch [8/10], Loss: 12797.2119, AVGLoss: 13641.8937\n",
      "Epoch [9/10], Loss: 15714.5898, AVGLoss: 13231.4050\n",
      "Epoch [10/10], Loss: 41415.9453, AVGLoss: 12850.5565\n",
      "Fold 4, MAE: 75.85054016113281, MSE: 15705.3974609375, R^2: 0.41313262132038486\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 13276.8643, AVGLoss: 26636.0024\n",
      "Epoch [2/10], Loss: 22269.0371, AVGLoss: 19208.7177\n",
      "Epoch [3/10], Loss: 3510.7024, AVGLoss: 16083.6061\n",
      "Epoch [4/10], Loss: 6176.2261, AVGLoss: 15247.1369\n",
      "Epoch [5/10], Loss: 53556.2070, AVGLoss: 14470.8440\n",
      "Epoch [6/10], Loss: 7743.1157, AVGLoss: 13702.5520\n",
      "Epoch [7/10], Loss: 10097.4785, AVGLoss: 13089.3931\n",
      "Epoch [8/10], Loss: 3934.5952, AVGLoss: 12627.0957\n",
      "Epoch [9/10], Loss: 7330.7510, AVGLoss: 12278.1238\n",
      "Epoch [10/10], Loss: 9159.1533, AVGLoss: 12013.9677\n",
      "Fold 5, MAE: 80.28744506835938, MSE: 26333.470703125, R^2: 0.4301673759688195\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 4976.0679, AVGLoss: 29864.3274\n",
      "Epoch [2/10], Loss: 5883.5464, AVGLoss: 23692.3806\n",
      "Epoch [3/10], Loss: 17541.8379, AVGLoss: 19179.9747\n",
      "Epoch [4/10], Loss: 10183.1016, AVGLoss: 18150.3819\n",
      "Epoch [5/10], Loss: 5990.2070, AVGLoss: 17513.3721\n",
      "Epoch [6/10], Loss: 14392.2129, AVGLoss: 16943.5739\n",
      "Epoch [7/10], Loss: 10826.1328, AVGLoss: 16451.9211\n",
      "Epoch [8/10], Loss: 18204.4375, AVGLoss: 15990.4051\n",
      "Epoch [9/10], Loss: 6672.3872, AVGLoss: 15557.5813\n",
      "Epoch [10/10], Loss: 13275.8330, AVGLoss: 15172.3220\n",
      "Fold 6, MAE: 62.36008071899414, MSE: 8622.6435546875, R^2: 0.3241934578150313\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 17610.6055, AVGLoss: 29780.7553\n",
      "Epoch [2/10], Loss: 11371.8955, AVGLoss: 22214.0252\n",
      "Epoch [3/10], Loss: 22397.0117, AVGLoss: 18002.7382\n",
      "Epoch [4/10], Loss: 21440.1621, AVGLoss: 17132.4215\n",
      "Epoch [5/10], Loss: 4819.7412, AVGLoss: 16542.2510\n",
      "Epoch [6/10], Loss: 6471.8911, AVGLoss: 15965.8353\n",
      "Epoch [7/10], Loss: 11291.8408, AVGLoss: 15299.8467\n",
      "Epoch [8/10], Loss: 19010.1504, AVGLoss: 14550.6205\n",
      "Epoch [9/10], Loss: 15451.4502, AVGLoss: 14056.1205\n",
      "Epoch [10/10], Loss: 14287.5078, AVGLoss: 13689.3854\n",
      "Fold 7, MAE: 73.2096939086914, MSE: 13122.5361328125, R^2: 0.16858785883240557\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 34305.4258, AVGLoss: 29932.9727\n",
      "Epoch [2/10], Loss: 21975.7090, AVGLoss: 24874.0102\n",
      "Epoch [3/10], Loss: 15842.6357, AVGLoss: 19358.2104\n",
      "Epoch [4/10], Loss: 11705.7002, AVGLoss: 17617.3763\n",
      "Epoch [5/10], Loss: 4381.8247, AVGLoss: 16919.8366\n",
      "Epoch [6/10], Loss: 28957.4746, AVGLoss: 16273.5212\n",
      "Epoch [7/10], Loss: 9978.1689, AVGLoss: 15604.4195\n",
      "Epoch [8/10], Loss: 11441.4609, AVGLoss: 15048.1382\n",
      "Epoch [9/10], Loss: 13501.0947, AVGLoss: 14594.8822\n",
      "Epoch [10/10], Loss: 19253.8652, AVGLoss: 14234.6047\n",
      "Fold 8, MAE: 65.15180969238281, MSE: 9832.9970703125, R^2: 0.49959399522131476\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 16512.1250, AVGLoss: 29117.4105\n",
      "Epoch [2/10], Loss: 3358.7124, AVGLoss: 21810.3725\n",
      "Epoch [3/10], Loss: 2881.5510, AVGLoss: 17856.1406\n",
      "Epoch [4/10], Loss: 10187.4805, AVGLoss: 16944.6365\n",
      "Epoch [5/10], Loss: 2727.0862, AVGLoss: 16276.6243\n",
      "Epoch [6/10], Loss: 16640.4668, AVGLoss: 15591.7198\n",
      "Epoch [7/10], Loss: 17223.3652, AVGLoss: 14938.4391\n",
      "Epoch [8/10], Loss: 13947.0078, AVGLoss: 14428.1079\n",
      "Epoch [9/10], Loss: 11057.3906, AVGLoss: 14041.2227\n",
      "Epoch [10/10], Loss: 2969.0215, AVGLoss: 13772.8459\n",
      "Fold 9, MAE: 84.9101333618164, MSE: 19328.404296875, R^2: 0.340872747894271\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 9610.6260, AVGLoss: 27848.9383\n",
      "Epoch [2/10], Loss: 14244.5967, AVGLoss: 20260.8909\n",
      "Epoch [3/10], Loss: 35209.5156, AVGLoss: 17333.6137\n",
      "Epoch [4/10], Loss: 11973.8809, AVGLoss: 16418.0777\n",
      "Epoch [5/10], Loss: 12743.4824, AVGLoss: 15683.6898\n",
      "Epoch [6/10], Loss: 18773.8281, AVGLoss: 14979.0725\n",
      "Epoch [7/10], Loss: 12990.6064, AVGLoss: 14338.8079\n",
      "Epoch [8/10], Loss: 15632.7686, AVGLoss: 13885.6529\n",
      "Epoch [9/10], Loss: 21344.5762, AVGLoss: 13582.8049\n",
      "Epoch [10/10], Loss: 5420.7832, AVGLoss: 13359.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 01:14:54,668] Trial 0 finished with value: 0.3867656384835983 and parameters: {'lr': 7.047249111653818e-05, 'num_layers': 4, 'n_units_l0': 76, 'n_units_l1': 54, 'n_units_l2': 104, 'n_units_l3': 33}. Best is trial 0 with value: 0.3867656384835983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 69.723876953125, MSE: 15845.6806640625, R^2: 0.5613878985633882\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 10865.3936, AVGLoss: 19497.4670\n",
      "Epoch [2/10], Loss: 55989.8750, AVGLoss: 15376.4636\n",
      "Epoch [3/10], Loss: 46994.7812, AVGLoss: 14409.1091\n",
      "Epoch [4/10], Loss: 6961.2827, AVGLoss: 13770.2580\n",
      "Epoch [5/10], Loss: 25259.2246, AVGLoss: 13260.6888\n",
      "Epoch [6/10], Loss: 10932.0625, AVGLoss: 12830.5825\n",
      "Epoch [7/10], Loss: 10512.2285, AVGLoss: 12511.0988\n",
      "Epoch [8/10], Loss: 5265.6938, AVGLoss: 12242.2121\n",
      "Epoch [9/10], Loss: 4621.4932, AVGLoss: 12054.6310\n",
      "Epoch [10/10], Loss: 5703.7012, AVGLoss: 11903.3612\n",
      "Fold 1, MAE: 93.0851058959961, MSE: 23235.138671875, R^2: 0.4019916814047757\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 3875.0852, AVGLoss: 16430.8226\n",
      "Epoch [2/10], Loss: 6663.2349, AVGLoss: 13874.9418\n",
      "Epoch [3/10], Loss: 10076.8252, AVGLoss: 13513.4713\n",
      "Epoch [4/10], Loss: 18037.2578, AVGLoss: 13239.0772\n",
      "Epoch [5/10], Loss: 80871.1406, AVGLoss: 13029.2191\n",
      "Epoch [6/10], Loss: 14529.6797, AVGLoss: 12776.5829\n",
      "Epoch [7/10], Loss: 6363.9561, AVGLoss: 12531.3638\n",
      "Epoch [8/10], Loss: 16370.9453, AVGLoss: 12282.9305\n",
      "Epoch [9/10], Loss: 4365.0093, AVGLoss: 12075.3448\n",
      "Epoch [10/10], Loss: 21603.3926, AVGLoss: 11854.0720\n",
      "Fold 2, MAE: 95.7039794921875, MSE: 43059.75, R^2: 0.49709513835737285\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 12915.7168, AVGLoss: 19850.1604\n",
      "Epoch [2/10], Loss: 16523.3398, AVGLoss: 15751.4520\n",
      "Epoch [3/10], Loss: 77353.3438, AVGLoss: 14597.4201\n",
      "Epoch [4/10], Loss: 14865.5693, AVGLoss: 13855.9744\n",
      "Epoch [5/10], Loss: 28150.3184, AVGLoss: 13221.7185\n",
      "Epoch [6/10], Loss: 9715.5791, AVGLoss: 12705.0240\n",
      "Epoch [7/10], Loss: 13018.6328, AVGLoss: 12352.1783\n",
      "Epoch [8/10], Loss: 8722.6309, AVGLoss: 12109.7912\n",
      "Epoch [9/10], Loss: 9366.5723, AVGLoss: 11935.1000\n",
      "Epoch [10/10], Loss: 59229.6055, AVGLoss: 11800.5242\n",
      "Fold 3, MAE: 90.36402893066406, MSE: 26197.876953125, R^2: 0.3067882462060516\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 5500.6792, AVGLoss: 20612.2050\n",
      "Epoch [2/10], Loss: 8571.6572, AVGLoss: 16263.3918\n",
      "Epoch [3/10], Loss: 5685.0039, AVGLoss: 15377.3843\n",
      "Epoch [4/10], Loss: 11770.6045, AVGLoss: 14783.7946\n",
      "Epoch [5/10], Loss: 25226.6855, AVGLoss: 14219.5955\n",
      "Epoch [6/10], Loss: 12419.9756, AVGLoss: 13749.9632\n",
      "Epoch [7/10], Loss: 7756.4536, AVGLoss: 13404.4860\n",
      "Epoch [8/10], Loss: 11638.2500, AVGLoss: 13148.2158\n",
      "Epoch [9/10], Loss: 24852.6055, AVGLoss: 12948.3985\n",
      "Epoch [10/10], Loss: 14713.7842, AVGLoss: 12799.7266\n",
      "Fold 4, MAE: 77.51762390136719, MSE: 15541.8671875, R^2: 0.4192433307455876\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 7373.5449, AVGLoss: 18819.8599\n",
      "Epoch [2/10], Loss: 3502.0571, AVGLoss: 15114.1949\n",
      "Epoch [3/10], Loss: 6203.2085, AVGLoss: 14229.8715\n",
      "Epoch [4/10], Loss: 10716.7227, AVGLoss: 13562.6566\n",
      "Epoch [5/10], Loss: 6339.7603, AVGLoss: 12957.3558\n",
      "Epoch [6/10], Loss: 68521.3516, AVGLoss: 12401.6073\n",
      "Epoch [7/10], Loss: 5526.2461, AVGLoss: 11912.3293\n",
      "Epoch [8/10], Loss: 5124.6187, AVGLoss: 11533.1267\n",
      "Epoch [9/10], Loss: 6901.4248, AVGLoss: 11236.5545\n",
      "Epoch [10/10], Loss: 13538.6953, AVGLoss: 11021.3805\n",
      "Fold 5, MAE: 80.23826599121094, MSE: 27058.08203125, R^2: 0.41448743808236377\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 38101.5039, AVGLoss: 21223.8081\n",
      "Epoch [2/10], Loss: 13135.2266, AVGLoss: 17309.1838\n",
      "Epoch [3/10], Loss: 8781.3828, AVGLoss: 16317.1176\n",
      "Epoch [4/10], Loss: 32188.6504, AVGLoss: 15574.4365\n",
      "Epoch [5/10], Loss: 18251.2656, AVGLoss: 14953.8277\n",
      "Epoch [6/10], Loss: 8770.7051, AVGLoss: 14449.9126\n",
      "Epoch [7/10], Loss: 6587.1816, AVGLoss: 14085.2673\n",
      "Epoch [8/10], Loss: 4805.8125, AVGLoss: 13801.8322\n",
      "Epoch [9/10], Loss: 5101.7139, AVGLoss: 13575.0355\n",
      "Epoch [10/10], Loss: 12218.5352, AVGLoss: 13382.4690\n",
      "Fold 6, MAE: 62.87257766723633, MSE: 8516.0859375, R^2: 0.3325450194518269\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 12198.2021, AVGLoss: 20666.1147\n",
      "Epoch [2/10], Loss: 8360.3564, AVGLoss: 16491.9164\n",
      "Epoch [3/10], Loss: 7668.3838, AVGLoss: 15687.0378\n",
      "Epoch [4/10], Loss: 9994.5586, AVGLoss: 15006.4547\n",
      "Epoch [5/10], Loss: 15539.8604, AVGLoss: 14273.9881\n",
      "Epoch [6/10], Loss: 5315.4360, AVGLoss: 13654.8259\n",
      "Epoch [7/10], Loss: 10012.9814, AVGLoss: 13218.9860\n",
      "Epoch [8/10], Loss: 14356.4346, AVGLoss: 12917.3951\n",
      "Epoch [9/10], Loss: 21720.2891, AVGLoss: 12694.6250\n",
      "Epoch [10/10], Loss: 8614.2891, AVGLoss: 12496.2361\n",
      "Fold 7, MAE: 74.20643615722656, MSE: 14242.0068359375, R^2: 0.09766087510152743\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 16678.4023, AVGLoss: 20921.3587\n",
      "Epoch [2/10], Loss: 13863.9248, AVGLoss: 16722.9605\n",
      "Epoch [3/10], Loss: 10289.0752, AVGLoss: 15847.1230\n",
      "Epoch [4/10], Loss: 17086.0801, AVGLoss: 15270.3865\n",
      "Epoch [5/10], Loss: 13274.9619, AVGLoss: 14700.7623\n",
      "Epoch [6/10], Loss: 10172.0566, AVGLoss: 14255.7500\n",
      "Epoch [7/10], Loss: 12700.1797, AVGLoss: 13900.5118\n",
      "Epoch [8/10], Loss: 17366.6758, AVGLoss: 13651.3415\n",
      "Epoch [9/10], Loss: 7158.4316, AVGLoss: 13466.6988\n",
      "Epoch [10/10], Loss: 4723.3940, AVGLoss: 13290.0695\n",
      "Fold 8, MAE: 63.26442337036133, MSE: 9032.8427734375, R^2: 0.5403142462699384\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 5710.8052, AVGLoss: 20285.4146\n",
      "Epoch [2/10], Loss: 23677.5664, AVGLoss: 16461.2836\n",
      "Epoch [3/10], Loss: 4352.1294, AVGLoss: 15491.8350\n",
      "Epoch [4/10], Loss: 2877.3567, AVGLoss: 14854.4749\n",
      "Epoch [5/10], Loss: 5409.7397, AVGLoss: 14280.7523\n",
      "Epoch [6/10], Loss: 18000.3867, AVGLoss: 13777.6874\n",
      "Epoch [7/10], Loss: 4932.4023, AVGLoss: 13386.6112\n",
      "Epoch [8/10], Loss: 14877.4775, AVGLoss: 13115.0910\n",
      "Epoch [9/10], Loss: 5859.4199, AVGLoss: 12909.4479\n",
      "Epoch [10/10], Loss: 3017.6489, AVGLoss: 12722.9368\n",
      "Fold 9, MAE: 87.21443939208984, MSE: 20137.498046875, R^2: 0.31328141000670107\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 18717.7832, AVGLoss: 20219.4032\n",
      "Epoch [2/10], Loss: 6950.6465, AVGLoss: 16222.9277\n",
      "Epoch [3/10], Loss: 17779.8027, AVGLoss: 15340.7810\n",
      "Epoch [4/10], Loss: 14966.6758, AVGLoss: 14720.9250\n",
      "Epoch [5/10], Loss: 6654.0308, AVGLoss: 14155.4869\n",
      "Epoch [6/10], Loss: 7402.6880, AVGLoss: 13678.8682\n",
      "Epoch [7/10], Loss: 10788.3057, AVGLoss: 13289.9671\n",
      "Epoch [8/10], Loss: 6326.7808, AVGLoss: 12933.5576\n",
      "Epoch [9/10], Loss: 7908.0239, AVGLoss: 12672.2318\n",
      "Epoch [10/10], Loss: 9372.7383, AVGLoss: 12466.8541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 01:42:10,999] Trial 1 finished with value: 0.3916948616311412 and parameters: {'lr': 0.000991079707114551, 'num_layers': 2, 'n_units_l0': 118, 'n_units_l1': 114}. Best is trial 1 with value: 0.3916948616311412.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 67.83736419677734, MSE: 14684.0810546875, R^2: 0.5935412306852665\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 15453.2959, AVGLoss: 33200.8781\n",
      "Epoch [2/10], Loss: 12580.2979, AVGLoss: 26961.6599\n",
      "Epoch [3/10], Loss: 15018.8066, AVGLoss: 26465.5865\n",
      "Epoch [4/10], Loss: 22283.8262, AVGLoss: 26121.6994\n",
      "Epoch [5/10], Loss: 12884.0928, AVGLoss: 25847.7572\n",
      "Epoch [6/10], Loss: 33475.8438, AVGLoss: 25608.2408\n",
      "Epoch [7/10], Loss: 17941.1387, AVGLoss: 25374.6731\n",
      "Epoch [8/10], Loss: 19242.6328, AVGLoss: 25141.0912\n",
      "Epoch [9/10], Loss: 13676.0176, AVGLoss: 24905.4170\n",
      "Epoch [10/10], Loss: 10788.9160, AVGLoss: 24667.6600\n",
      "Fold 1, MAE: 96.88160705566406, MSE: 27316.310546875, R^2: 0.2969536412131789\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 105547.6719, AVGLoss: 27963.2540\n",
      "Epoch [2/10], Loss: 10471.0000, AVGLoss: 22179.5628\n",
      "Epoch [3/10], Loss: 31181.8047, AVGLoss: 21928.3235\n",
      "Epoch [4/10], Loss: 12497.6572, AVGLoss: 21847.6454\n",
      "Epoch [5/10], Loss: 8812.8828, AVGLoss: 21792.2867\n",
      "Epoch [6/10], Loss: 6249.5649, AVGLoss: 21744.6422\n",
      "Epoch [7/10], Loss: 10227.7607, AVGLoss: 21703.6739\n",
      "Epoch [8/10], Loss: 63307.1953, AVGLoss: 21670.2950\n",
      "Epoch [9/10], Loss: 9111.0000, AVGLoss: 21636.5821\n",
      "Epoch [10/10], Loss: 145161.2656, AVGLoss: 21614.6789\n",
      "Fold 2, MAE: 116.1075439453125, MSE: 73752.6953125, R^2: 0.13862517979418798\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 18840.1328, AVGLoss: 33113.8729\n",
      "Epoch [2/10], Loss: 48862.6641, AVGLoss: 26743.1236\n",
      "Epoch [3/10], Loss: 10167.9453, AVGLoss: 26292.7802\n",
      "Epoch [4/10], Loss: 11090.0537, AVGLoss: 26048.7994\n",
      "Epoch [5/10], Loss: 14431.7402, AVGLoss: 25877.5919\n",
      "Epoch [6/10], Loss: 31465.7422, AVGLoss: 25726.7623\n",
      "Epoch [7/10], Loss: 10403.2490, AVGLoss: 25578.5566\n",
      "Epoch [8/10], Loss: 52426.7031, AVGLoss: 25430.6293\n",
      "Epoch [9/10], Loss: 24819.5840, AVGLoss: 25277.4476\n",
      "Epoch [10/10], Loss: 36604.9102, AVGLoss: 25125.5799\n",
      "Fold 3, MAE: 96.46890258789062, MSE: 30044.36328125, R^2: 0.20500796428297807\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 36781.8789, AVGLoss: 34206.6932\n",
      "Epoch [2/10], Loss: 24145.8379, AVGLoss: 27920.7540\n",
      "Epoch [3/10], Loss: 20736.9570, AVGLoss: 27361.1805\n",
      "Epoch [4/10], Loss: 23933.7656, AVGLoss: 26968.5466\n",
      "Epoch [5/10], Loss: 11322.7715, AVGLoss: 26633.7384\n",
      "Epoch [6/10], Loss: 9515.1035, AVGLoss: 26325.9926\n",
      "Epoch [7/10], Loss: 12010.8955, AVGLoss: 26027.3659\n",
      "Epoch [8/10], Loss: 33703.9766, AVGLoss: 25725.2304\n",
      "Epoch [9/10], Loss: 114663.5234, AVGLoss: 25418.6983\n",
      "Epoch [10/10], Loss: 8583.4111, AVGLoss: 25106.3074\n",
      "Fold 4, MAE: 89.29487609863281, MSE: 18876.544921875, R^2: 0.29463563191024644\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 16556.6465, AVGLoss: 32566.6861\n",
      "Epoch [2/10], Loss: 8930.2168, AVGLoss: 25918.8416\n",
      "Epoch [3/10], Loss: 9998.1465, AVGLoss: 25339.9668\n",
      "Epoch [4/10], Loss: 15422.1943, AVGLoss: 25016.5604\n",
      "Epoch [5/10], Loss: 53904.2070, AVGLoss: 24758.1153\n",
      "Epoch [6/10], Loss: 7596.9697, AVGLoss: 24512.0319\n",
      "Epoch [7/10], Loss: 25410.1465, AVGLoss: 24270.6866\n",
      "Epoch [8/10], Loss: 9501.9082, AVGLoss: 24022.9652\n",
      "Epoch [9/10], Loss: 9812.4482, AVGLoss: 23768.9942\n",
      "Epoch [10/10], Loss: 7150.8271, AVGLoss: 23509.3676\n",
      "Fold 5, MAE: 99.8111343383789, MSE: 35776.15625, R^2: 0.22583607883641998\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 12257.3799, AVGLoss: 35489.8492\n",
      "Epoch [2/10], Loss: 11028.2881, AVGLoss: 28730.1496\n",
      "Epoch [3/10], Loss: 21567.0098, AVGLoss: 28291.5736\n",
      "Epoch [4/10], Loss: 11344.4736, AVGLoss: 28050.3273\n",
      "Epoch [5/10], Loss: 14624.8633, AVGLoss: 27879.8143\n",
      "Epoch [6/10], Loss: 14127.0000, AVGLoss: 27741.1678\n",
      "Epoch [7/10], Loss: 25700.2031, AVGLoss: 27616.4505\n",
      "Epoch [8/10], Loss: 8908.1074, AVGLoss: 27494.0354\n",
      "Epoch [9/10], Loss: 63803.4258, AVGLoss: 27377.4923\n",
      "Epoch [10/10], Loss: 68241.0625, AVGLoss: 27260.3561\n",
      "Fold 6, MAE: 87.92024993896484, MSE: 13570.13671875, R^2: -0.06357012286911745\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 18141.9258, AVGLoss: 35275.9255\n",
      "Epoch [2/10], Loss: 53468.4141, AVGLoss: 28748.2356\n",
      "Epoch [3/10], Loss: 18486.4805, AVGLoss: 28337.4115\n",
      "Epoch [4/10], Loss: 36856.5781, AVGLoss: 28030.7663\n",
      "Epoch [5/10], Loss: 19096.4863, AVGLoss: 27665.5388\n",
      "Epoch [6/10], Loss: 17399.2070, AVGLoss: 27321.8691\n",
      "Epoch [7/10], Loss: 41717.9141, AVGLoss: 26990.8911\n",
      "Epoch [8/10], Loss: 32660.0566, AVGLoss: 26674.8689\n",
      "Epoch [9/10], Loss: 10612.8467, AVGLoss: 26369.7307\n",
      "Epoch [10/10], Loss: 9597.3672, AVGLoss: 26074.6912\n",
      "Fold 7, MAE: 84.09210205078125, MSE: 12605.1962890625, R^2: 0.20136531267273727\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 20891.5801, AVGLoss: 35134.2423\n",
      "Epoch [2/10], Loss: 22126.5020, AVGLoss: 28762.0560\n",
      "Epoch [3/10], Loss: 72621.4062, AVGLoss: 28328.4369\n",
      "Epoch [4/10], Loss: 18935.6426, AVGLoss: 28060.9721\n",
      "Epoch [5/10], Loss: 11823.9756, AVGLoss: 27877.8450\n",
      "Epoch [6/10], Loss: 43677.0000, AVGLoss: 27734.0568\n",
      "Epoch [7/10], Loss: 19236.1934, AVGLoss: 27602.4500\n",
      "Epoch [8/10], Loss: 31336.4141, AVGLoss: 27478.6538\n",
      "Epoch [9/10], Loss: 25318.8438, AVGLoss: 27357.5615\n",
      "Epoch [10/10], Loss: 20086.9922, AVGLoss: 27239.7935\n",
      "Fold 8, MAE: 77.44681549072266, MSE: 13216.025390625, R^2: 0.3274301411524907\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 19102.8984, AVGLoss: 34201.7717\n",
      "Epoch [2/10], Loss: 12392.2793, AVGLoss: 28574.9502\n",
      "Epoch [3/10], Loss: 27776.1426, AVGLoss: 28385.5729\n",
      "Epoch [4/10], Loss: 10312.3623, AVGLoss: 28323.5267\n",
      "Epoch [5/10], Loss: 20829.5488, AVGLoss: 28284.6792\n",
      "Epoch [6/10], Loss: 12486.2246, AVGLoss: 28250.4416\n",
      "Epoch [7/10], Loss: 12361.2539, AVGLoss: 28219.9708\n",
      "Epoch [8/10], Loss: 6422.8120, AVGLoss: 28192.4237\n",
      "Epoch [9/10], Loss: 5408.1392, AVGLoss: 28167.5553\n",
      "Epoch [10/10], Loss: 4253.1699, AVGLoss: 28145.4307\n",
      "Fold 9, MAE: 83.03424072265625, MSE: 15678.978515625, R^2: 0.465323579853283\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 12703.1914, AVGLoss: 33435.4891\n",
      "Epoch [2/10], Loss: 15928.6543, AVGLoss: 27528.9635\n",
      "Epoch [3/10], Loss: 11631.6709, AVGLoss: 27087.9798\n",
      "Epoch [4/10], Loss: 9744.0908, AVGLoss: 26833.7807\n",
      "Epoch [5/10], Loss: 65555.6875, AVGLoss: 26652.6867\n",
      "Epoch [6/10], Loss: 11665.3828, AVGLoss: 26512.9653\n",
      "Epoch [7/10], Loss: 7633.4888, AVGLoss: 26389.0756\n",
      "Epoch [8/10], Loss: 44383.8438, AVGLoss: 26269.4478\n",
      "Epoch [9/10], Loss: 13736.1182, AVGLoss: 26151.9722\n",
      "Epoch [10/10], Loss: 15850.2178, AVGLoss: 26034.6673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 02:01:00,567] Trial 2 finished with value: 0.2431155669450163 and parameters: {'lr': 0.0002279391855375882, 'num_layers': 1, 'n_units_l0': 44}. Best is trial 1 with value: 0.3916948616311412.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 92.24771881103516, MSE: 23860.0546875, R^2: 0.33954826260375814\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 10921.1377, AVGLoss: 26199.1231\n",
      "Epoch [2/10], Loss: 9251.4941, AVGLoss: 17373.2795\n",
      "Epoch [3/10], Loss: 66226.9688, AVGLoss: 15325.6003\n",
      "Epoch [4/10], Loss: 6845.2139, AVGLoss: 14144.0753\n",
      "Epoch [5/10], Loss: 8579.7285, AVGLoss: 13409.2610\n",
      "Epoch [6/10], Loss: 9086.0479, AVGLoss: 12991.9128\n",
      "Epoch [7/10], Loss: 9124.3623, AVGLoss: 12721.9115\n",
      "Epoch [8/10], Loss: 18923.3809, AVGLoss: 12525.8552\n",
      "Epoch [9/10], Loss: 9260.4453, AVGLoss: 12323.4886\n",
      "Epoch [10/10], Loss: 8605.7666, AVGLoss: 12091.8265\n",
      "Fold 1, MAE: 85.86998748779297, MSE: 21231.587890625, R^2: 0.453557573055114\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 22497.7109, AVGLoss: 22433.3913\n",
      "Epoch [2/10], Loss: 7523.6411, AVGLoss: 16523.3528\n",
      "Epoch [3/10], Loss: 9125.3340, AVGLoss: 14539.7537\n",
      "Epoch [4/10], Loss: 5289.6514, AVGLoss: 14075.0380\n",
      "Epoch [5/10], Loss: 6852.4395, AVGLoss: 13773.0534\n",
      "Epoch [6/10], Loss: 4241.1982, AVGLoss: 13540.3714\n",
      "Epoch [7/10], Loss: 7186.8281, AVGLoss: 13360.6086\n",
      "Epoch [8/10], Loss: 18128.4629, AVGLoss: 13210.7032\n",
      "Epoch [9/10], Loss: 11979.4658, AVGLoss: 13089.0090\n",
      "Epoch [10/10], Loss: 6823.6577, AVGLoss: 12981.5094\n",
      "Fold 2, MAE: 95.9151840209961, MSE: 44635.9296875, R^2: 0.4786865717954757\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 13991.0254, AVGLoss: 27325.3384\n",
      "Epoch [2/10], Loss: 8505.4316, AVGLoss: 19377.7233\n",
      "Epoch [3/10], Loss: 8907.9160, AVGLoss: 16836.3666\n",
      "Epoch [4/10], Loss: 9968.3545, AVGLoss: 15876.7193\n",
      "Epoch [5/10], Loss: 13297.8477, AVGLoss: 15002.8218\n",
      "Epoch [6/10], Loss: 8363.2422, AVGLoss: 14128.2777\n",
      "Epoch [7/10], Loss: 36318.7188, AVGLoss: 13399.2133\n",
      "Epoch [8/10], Loss: 15013.1523, AVGLoss: 12953.1724\n",
      "Epoch [9/10], Loss: 28629.4844, AVGLoss: 12649.1451\n",
      "Epoch [10/10], Loss: 16006.5879, AVGLoss: 12390.0652\n",
      "Fold 3, MAE: 93.29248046875, MSE: 27432.490234375, R^2: 0.27411983102085635\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 7966.4390, AVGLoss: 26789.7241\n",
      "Epoch [2/10], Loss: 20646.3086, AVGLoss: 17842.3700\n",
      "Epoch [3/10], Loss: 9747.8701, AVGLoss: 16547.2226\n",
      "Epoch [4/10], Loss: 6299.3037, AVGLoss: 15700.0602\n",
      "Epoch [5/10], Loss: 7093.8755, AVGLoss: 14847.7392\n",
      "Epoch [6/10], Loss: 7649.0127, AVGLoss: 14121.6221\n",
      "Epoch [7/10], Loss: 3857.5735, AVGLoss: 13623.6335\n",
      "Epoch [8/10], Loss: 8156.1030, AVGLoss: 13244.8898\n",
      "Epoch [9/10], Loss: 13930.4414, AVGLoss: 12917.0837\n",
      "Epoch [10/10], Loss: 6782.8384, AVGLoss: 12615.9927\n",
      "Fold 4, MAE: 74.27043151855469, MSE: 15024.505859375, R^2: 0.4385756986088025\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 4084.3989, AVGLoss: 25907.6045\n",
      "Epoch [2/10], Loss: 29640.5078, AVGLoss: 17612.7302\n",
      "Epoch [3/10], Loss: 17397.8438, AVGLoss: 15464.2026\n",
      "Epoch [4/10], Loss: 3871.5139, AVGLoss: 14314.5966\n",
      "Epoch [5/10], Loss: 6548.0210, AVGLoss: 13248.5781\n",
      "Epoch [6/10], Loss: 10960.8379, AVGLoss: 12541.1543\n",
      "Epoch [7/10], Loss: 19329.9844, AVGLoss: 12128.1775\n",
      "Epoch [8/10], Loss: 4385.2231, AVGLoss: 11826.2954\n",
      "Epoch [9/10], Loss: 7084.1040, AVGLoss: 11605.8751\n",
      "Epoch [10/10], Loss: 3502.0747, AVGLoss: 11408.9608\n",
      "Fold 5, MAE: 82.99799346923828, MSE: 26288.8203125, R^2: 0.4311335941329173\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 7289.1514, AVGLoss: 27719.8233\n",
      "Epoch [2/10], Loss: 13468.3516, AVGLoss: 18648.9794\n",
      "Epoch [3/10], Loss: 17026.4727, AVGLoss: 16787.0678\n",
      "Epoch [4/10], Loss: 9514.4482, AVGLoss: 15653.5642\n",
      "Epoch [5/10], Loss: 10566.6562, AVGLoss: 14741.8403\n",
      "Epoch [6/10], Loss: 5669.0200, AVGLoss: 14173.6836\n",
      "Epoch [7/10], Loss: 35567.4648, AVGLoss: 13767.8588\n",
      "Epoch [8/10], Loss: 18513.8516, AVGLoss: 13425.6299\n",
      "Epoch [9/10], Loss: 4749.2930, AVGLoss: 13128.3728\n",
      "Epoch [10/10], Loss: 13346.1445, AVGLoss: 12893.7742\n",
      "Fold 6, MAE: 53.752017974853516, MSE: 6231.8212890625, R^2: 0.5115761011396789\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 10732.4600, AVGLoss: 27849.0344\n",
      "Epoch [2/10], Loss: 30992.0078, AVGLoss: 18455.8763\n",
      "Epoch [3/10], Loss: 9866.7637, AVGLoss: 16833.1841\n",
      "Epoch [4/10], Loss: 14208.8418, AVGLoss: 15953.4028\n",
      "Epoch [5/10], Loss: 13493.7812, AVGLoss: 15126.6322\n",
      "Epoch [6/10], Loss: 7965.5532, AVGLoss: 14399.7312\n",
      "Epoch [7/10], Loss: 4461.0747, AVGLoss: 13859.0227\n",
      "Epoch [8/10], Loss: 7247.6162, AVGLoss: 13499.0105\n",
      "Epoch [9/10], Loss: 12724.2363, AVGLoss: 13275.6604\n",
      "Epoch [10/10], Loss: 69149.2500, AVGLoss: 13103.6414\n",
      "Fold 7, MAE: 74.10862731933594, MSE: 14283.296875, R^2: 0.09504472838444888\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 27175.3438, AVGLoss: 27389.5739\n",
      "Epoch [2/10], Loss: 15443.2256, AVGLoss: 18396.7338\n",
      "Epoch [3/10], Loss: 9255.9492, AVGLoss: 16857.8228\n",
      "Epoch [4/10], Loss: 17040.0391, AVGLoss: 15816.4060\n",
      "Epoch [5/10], Loss: 23184.7363, AVGLoss: 15002.7230\n",
      "Epoch [6/10], Loss: 12406.9922, AVGLoss: 14444.3583\n",
      "Epoch [7/10], Loss: 15627.2607, AVGLoss: 14076.9425\n",
      "Epoch [8/10], Loss: 10777.7002, AVGLoss: 13777.5538\n",
      "Epoch [9/10], Loss: 20775.2402, AVGLoss: 13540.6327\n",
      "Epoch [10/10], Loss: 10255.3242, AVGLoss: 13352.3940\n",
      "Fold 8, MAE: 61.56993103027344, MSE: 9872.021484375, R^2: 0.49760806658022905\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 1834.1792, AVGLoss: 27438.1296\n",
      "Epoch [2/10], Loss: 17198.7266, AVGLoss: 18211.9610\n",
      "Epoch [3/10], Loss: 5830.4082, AVGLoss: 16417.7490\n",
      "Epoch [4/10], Loss: 5626.6172, AVGLoss: 15155.7933\n",
      "Epoch [5/10], Loss: 30449.1562, AVGLoss: 14282.0329\n",
      "Epoch [6/10], Loss: 1991.2659, AVGLoss: 13760.7136\n",
      "Epoch [7/10], Loss: 13885.9961, AVGLoss: 13414.9150\n",
      "Epoch [8/10], Loss: 5696.0381, AVGLoss: 13125.1617\n",
      "Epoch [9/10], Loss: 7657.3613, AVGLoss: 12872.6431\n",
      "Epoch [10/10], Loss: 40002.6445, AVGLoss: 12655.2335\n",
      "Fold 9, MAE: 86.56326293945312, MSE: 21002.765625, R^2: 0.28377448637735314\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 7522.4180, AVGLoss: 25478.2624\n",
      "Epoch [2/10], Loss: 15667.5352, AVGLoss: 17556.8366\n",
      "Epoch [3/10], Loss: 12717.7246, AVGLoss: 16280.5874\n",
      "Epoch [4/10], Loss: 18233.0020, AVGLoss: 15297.1422\n",
      "Epoch [5/10], Loss: 22446.1602, AVGLoss: 14415.0658\n",
      "Epoch [6/10], Loss: 28808.0547, AVGLoss: 13880.1200\n",
      "Epoch [7/10], Loss: 22560.3828, AVGLoss: 13547.5037\n",
      "Epoch [8/10], Loss: 7425.7544, AVGLoss: 13288.8807\n",
      "Epoch [9/10], Loss: 11637.6914, AVGLoss: 13079.4083\n",
      "Epoch [10/10], Loss: 12553.7773, AVGLoss: 12894.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 02:36:48,673] Trial 3 finished with value: 0.40348780795787587 and parameters: {'lr': 0.00010036057886686167, 'num_layers': 5, 'n_units_l0': 66, 'n_units_l1': 53, 'n_units_l2': 111, 'n_units_l3': 21, 'n_units_l4': 19}. Best is trial 3 with value: 0.40348780795787587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 68.68785095214844, MSE: 15505.599609375, R^2: 0.5708014284838825\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 6610.4131, AVGLoss: 25275.6351\n",
      "Epoch [2/10], Loss: 9613.7979, AVGLoss: 18055.3588\n",
      "Epoch [3/10], Loss: 14977.1016, AVGLoss: 16720.5975\n",
      "Epoch [4/10], Loss: 11432.6953, AVGLoss: 16127.8260\n",
      "Epoch [5/10], Loss: 4429.3955, AVGLoss: 15523.3333\n",
      "Epoch [6/10], Loss: 9374.0635, AVGLoss: 14966.5034\n",
      "Epoch [7/10], Loss: 7002.0229, AVGLoss: 14578.9422\n",
      "Epoch [8/10], Loss: 10739.2646, AVGLoss: 14283.4360\n",
      "Epoch [9/10], Loss: 8868.3330, AVGLoss: 14042.2780\n",
      "Epoch [10/10], Loss: 10983.9697, AVGLoss: 13824.7831\n",
      "Fold 1, MAE: 93.4051284790039, MSE: 24234.787109375, R^2: 0.3762634687571518\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 7368.0225, AVGLoss: 20619.9407\n",
      "Epoch [2/10], Loss: 11051.2734, AVGLoss: 15020.9309\n",
      "Epoch [3/10], Loss: 9411.5566, AVGLoss: 14362.2422\n",
      "Epoch [4/10], Loss: 8424.8730, AVGLoss: 14076.3673\n",
      "Epoch [5/10], Loss: 6785.0679, AVGLoss: 13874.1410\n",
      "Epoch [6/10], Loss: 6643.0845, AVGLoss: 13737.2528\n",
      "Epoch [7/10], Loss: 9729.8838, AVGLoss: 13616.7672\n",
      "Epoch [8/10], Loss: 7741.2456, AVGLoss: 13506.2728\n",
      "Epoch [9/10], Loss: 17653.2363, AVGLoss: 13410.7011\n",
      "Epoch [10/10], Loss: 10416.1152, AVGLoss: 13315.8007\n",
      "Fold 2, MAE: 96.35264587402344, MSE: 46907.9375, R^2: 0.452151288011698\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 75520.3828, AVGLoss: 25423.6934\n",
      "Epoch [2/10], Loss: 7597.3555, AVGLoss: 18074.1290\n",
      "Epoch [3/10], Loss: 15827.5859, AVGLoss: 16857.1793\n",
      "Epoch [4/10], Loss: 7106.8198, AVGLoss: 16072.3734\n",
      "Epoch [5/10], Loss: 15547.0459, AVGLoss: 15463.5407\n",
      "Epoch [6/10], Loss: 8693.8086, AVGLoss: 15007.6808\n",
      "Epoch [7/10], Loss: 11985.6689, AVGLoss: 14646.7597\n",
      "Epoch [8/10], Loss: 6509.0342, AVGLoss: 14368.2630\n",
      "Epoch [9/10], Loss: 58621.0820, AVGLoss: 14138.8986\n",
      "Epoch [10/10], Loss: 27077.3672, AVGLoss: 13933.8072\n",
      "Fold 3, MAE: 89.51278686523438, MSE: 26241.5546875, R^2: 0.3056326439981444\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 42446.1680, AVGLoss: 27118.2962\n",
      "Epoch [2/10], Loss: 13077.1953, AVGLoss: 18462.5632\n",
      "Epoch [3/10], Loss: 7909.3789, AVGLoss: 17345.1687\n",
      "Epoch [4/10], Loss: 9238.1191, AVGLoss: 16759.2871\n",
      "Epoch [5/10], Loss: 21855.9004, AVGLoss: 16259.3144\n",
      "Epoch [6/10], Loss: 7001.3545, AVGLoss: 15857.1330\n",
      "Epoch [7/10], Loss: 35839.3711, AVGLoss: 15564.8585\n",
      "Epoch [8/10], Loss: 7062.7817, AVGLoss: 15339.5099\n",
      "Epoch [9/10], Loss: 7196.6543, AVGLoss: 15129.9781\n",
      "Epoch [10/10], Loss: 9086.1836, AVGLoss: 14914.6924\n",
      "Fold 4, MAE: 78.17796325683594, MSE: 15854.7255859375, R^2: 0.40755266607777785\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 10619.7930, AVGLoss: 23522.2192\n",
      "Epoch [2/10], Loss: 9063.1963, AVGLoss: 16867.9664\n",
      "Epoch [3/10], Loss: 19576.4023, AVGLoss: 16105.2823\n",
      "Epoch [4/10], Loss: 5384.7695, AVGLoss: 15574.9430\n",
      "Epoch [5/10], Loss: 3115.4541, AVGLoss: 15093.6399\n",
      "Epoch [6/10], Loss: 9643.0264, AVGLoss: 14735.9655\n",
      "Epoch [7/10], Loss: 8113.3672, AVGLoss: 14442.2034\n",
      "Epoch [8/10], Loss: 5350.8872, AVGLoss: 14201.1186\n",
      "Epoch [9/10], Loss: 8857.0596, AVGLoss: 13981.5649\n",
      "Epoch [10/10], Loss: 3982.8650, AVGLoss: 13786.8822\n",
      "Fold 5, MAE: 84.38186645507812, MSE: 26708.8046875, R^2: 0.4220454542324079\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 20745.5586, AVGLoss: 26223.1997\n",
      "Epoch [2/10], Loss: 34926.8320, AVGLoss: 18986.4424\n",
      "Epoch [3/10], Loss: 8943.2725, AVGLoss: 18152.1741\n",
      "Epoch [4/10], Loss: 4984.1602, AVGLoss: 17658.1534\n",
      "Epoch [5/10], Loss: 19201.7422, AVGLoss: 17205.7381\n",
      "Epoch [6/10], Loss: 8125.6499, AVGLoss: 16771.9894\n",
      "Epoch [7/10], Loss: 8472.9473, AVGLoss: 16401.8969\n",
      "Epoch [8/10], Loss: 16227.9609, AVGLoss: 16109.1602\n",
      "Epoch [9/10], Loss: 81121.1875, AVGLoss: 15862.5992\n",
      "Epoch [10/10], Loss: 9965.4297, AVGLoss: 15626.4427\n",
      "Fold 6, MAE: 59.11076736450195, MSE: 7682.56884765625, R^2: 0.3978726235075758\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 13177.5137, AVGLoss: 26944.2982\n",
      "Epoch [2/10], Loss: 10402.2383, AVGLoss: 18849.1426\n",
      "Epoch [3/10], Loss: 17272.1016, AVGLoss: 17741.9786\n",
      "Epoch [4/10], Loss: 16320.8428, AVGLoss: 17090.5841\n",
      "Epoch [5/10], Loss: 13667.0596, AVGLoss: 16611.5510\n",
      "Epoch [6/10], Loss: 23577.2285, AVGLoss: 16215.0652\n",
      "Epoch [7/10], Loss: 11998.0654, AVGLoss: 15883.9202\n",
      "Epoch [8/10], Loss: 4924.8613, AVGLoss: 15613.5686\n",
      "Epoch [9/10], Loss: 5756.6909, AVGLoss: 15374.2850\n",
      "Epoch [10/10], Loss: 22955.3086, AVGLoss: 15136.0708\n",
      "Fold 7, MAE: 74.26925659179688, MSE: 12934.4287109375, R^2: 0.18050592428313705\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 21109.6816, AVGLoss: 27283.8364\n",
      "Epoch [2/10], Loss: 18774.6934, AVGLoss: 19738.6260\n",
      "Epoch [3/10], Loss: 42872.7578, AVGLoss: 18007.5824\n",
      "Epoch [4/10], Loss: 7748.0718, AVGLoss: 17488.6732\n",
      "Epoch [5/10], Loss: 9059.0938, AVGLoss: 17120.8681\n",
      "Epoch [6/10], Loss: 37797.2930, AVGLoss: 16768.6664\n",
      "Epoch [7/10], Loss: 11848.2314, AVGLoss: 16399.3590\n",
      "Epoch [8/10], Loss: 9914.2275, AVGLoss: 16115.4346\n",
      "Epoch [9/10], Loss: 16558.0098, AVGLoss: 15911.5548\n",
      "Epoch [10/10], Loss: 4982.5928, AVGLoss: 15746.5021\n",
      "Fold 8, MAE: 66.90531921386719, MSE: 10352.59765625, R^2: 0.4731513524078076\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 47113.2812, AVGLoss: 26021.1508\n",
      "Epoch [2/10], Loss: 29744.9766, AVGLoss: 18567.3782\n",
      "Epoch [3/10], Loss: 39554.3711, AVGLoss: 17564.9066\n",
      "Epoch [4/10], Loss: 9231.2266, AVGLoss: 17018.3149\n",
      "Epoch [5/10], Loss: 33276.1523, AVGLoss: 16549.1184\n",
      "Epoch [6/10], Loss: 1386.7246, AVGLoss: 16159.3000\n",
      "Epoch [7/10], Loss: 4948.6987, AVGLoss: 15864.6488\n",
      "Epoch [8/10], Loss: 10993.2334, AVGLoss: 15635.7221\n",
      "Epoch [9/10], Loss: 8145.9897, AVGLoss: 15423.4824\n",
      "Epoch [10/10], Loss: 19443.8340, AVGLoss: 15246.8516\n",
      "Fold 9, MAE: 81.31853485107422, MSE: 19161.623046875, R^2: 0.3465601960370025\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 40181.9023, AVGLoss: 25507.7412\n",
      "Epoch [2/10], Loss: 9860.2734, AVGLoss: 18362.0013\n",
      "Epoch [3/10], Loss: 7838.2886, AVGLoss: 17292.3677\n",
      "Epoch [4/10], Loss: 10622.6055, AVGLoss: 16680.6026\n",
      "Epoch [5/10], Loss: 9561.6602, AVGLoss: 16173.4917\n",
      "Epoch [6/10], Loss: 24757.2422, AVGLoss: 15781.6456\n",
      "Epoch [7/10], Loss: 10245.9443, AVGLoss: 15467.4695\n",
      "Epoch [8/10], Loss: 10646.8301, AVGLoss: 15209.1936\n",
      "Epoch [9/10], Loss: 7680.3945, AVGLoss: 14964.7403\n",
      "Epoch [10/10], Loss: 9578.2188, AVGLoss: 14743.2436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 03:02:02,305] Trial 4 finished with value: 0.39059802823886425 and parameters: {'lr': 0.0004443006758539235, 'num_layers': 2, 'n_units_l0': 128, 'n_units_l1': 31}. Best is trial 3 with value: 0.40348780795787587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 73.36746978759766, MSE: 16465.013671875, R^2: 0.5442446650759396\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 7404.7202, AVGLoss: 40924.5419\n",
      "Epoch [2/10], Loss: 19524.1367, AVGLoss: 28795.5014\n",
      "Epoch [3/10], Loss: 15272.8125, AVGLoss: 27414.0486\n",
      "Epoch [4/10], Loss: 18563.7871, AVGLoss: 26977.6211\n",
      "Epoch [5/10], Loss: 10698.0518, AVGLoss: 26638.5672\n",
      "Epoch [6/10], Loss: 18291.8730, AVGLoss: 26367.7053\n",
      "Epoch [7/10], Loss: 11133.0527, AVGLoss: 26132.3172\n",
      "Epoch [8/10], Loss: 7682.2690, AVGLoss: 25911.8838\n",
      "Epoch [9/10], Loss: 10045.4365, AVGLoss: 25684.6301\n",
      "Epoch [10/10], Loss: 20010.3320, AVGLoss: 25440.9070\n",
      "Fold 1, MAE: 99.62218475341797, MSE: 28210.0546875, R^2: 0.27395104494060696\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 32066.9648, AVGLoss: 34012.9687\n",
      "Epoch [2/10], Loss: 8346.6650, AVGLoss: 23614.2224\n",
      "Epoch [3/10], Loss: 8757.1221, AVGLoss: 22381.1875\n",
      "Epoch [4/10], Loss: 12715.6475, AVGLoss: 21968.1330\n",
      "Epoch [5/10], Loss: 20375.9941, AVGLoss: 21685.9038\n",
      "Epoch [6/10], Loss: 31111.5156, AVGLoss: 21454.5107\n",
      "Epoch [7/10], Loss: 8753.4502, AVGLoss: 21240.0175\n",
      "Epoch [8/10], Loss: 8741.5938, AVGLoss: 21025.6021\n",
      "Epoch [9/10], Loss: 69796.3516, AVGLoss: 20794.5472\n",
      "Epoch [10/10], Loss: 27118.5254, AVGLoss: 20532.5405\n",
      "Fold 2, MAE: 117.44306945800781, MSE: 70480.296875, R^2: 0.17684421725411859\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 7981.4521, AVGLoss: 40485.0773\n",
      "Epoch [2/10], Loss: 13563.5342, AVGLoss: 28612.8748\n",
      "Epoch [3/10], Loss: 9768.3721, AVGLoss: 27108.0965\n",
      "Epoch [4/10], Loss: 24484.1719, AVGLoss: 26731.8425\n",
      "Epoch [5/10], Loss: 22545.4180, AVGLoss: 26492.6839\n",
      "Epoch [6/10], Loss: 11927.8916, AVGLoss: 26259.4554\n",
      "Epoch [7/10], Loss: 12686.1387, AVGLoss: 26014.3614\n",
      "Epoch [8/10], Loss: 7445.3159, AVGLoss: 25750.4553\n",
      "Epoch [9/10], Loss: 10194.1074, AVGLoss: 25459.9499\n",
      "Epoch [10/10], Loss: 31957.5176, AVGLoss: 25121.7890\n",
      "Fold 3, MAE: 95.76428985595703, MSE: 29724.6640625, R^2: 0.21346740017938381\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 7014.2173, AVGLoss: 41391.0894\n",
      "Epoch [2/10], Loss: 9241.3311, AVGLoss: 29861.1329\n",
      "Epoch [3/10], Loss: 54955.0234, AVGLoss: 28396.0080\n",
      "Epoch [4/10], Loss: 26151.7871, AVGLoss: 27919.1172\n",
      "Epoch [5/10], Loss: 30574.1680, AVGLoss: 27591.9917\n",
      "Epoch [6/10], Loss: 11064.3799, AVGLoss: 27289.3191\n",
      "Epoch [7/10], Loss: 36987.9219, AVGLoss: 26976.3901\n",
      "Epoch [8/10], Loss: 39808.9375, AVGLoss: 26618.0364\n",
      "Epoch [9/10], Loss: 13014.6748, AVGLoss: 26185.9923\n",
      "Epoch [10/10], Loss: 40260.0625, AVGLoss: 25668.9262\n",
      "Fold 4, MAE: 88.89202880859375, MSE: 18880.2109375, R^2: 0.29449860899130864\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 12653.0879, AVGLoss: 39108.3615\n",
      "Epoch [2/10], Loss: 29155.2188, AVGLoss: 27758.3267\n",
      "Epoch [3/10], Loss: 20048.2188, AVGLoss: 26501.3879\n",
      "Epoch [4/10], Loss: 20400.2441, AVGLoss: 26100.7933\n",
      "Epoch [5/10], Loss: 14925.4570, AVGLoss: 25780.9952\n",
      "Epoch [6/10], Loss: 28801.8848, AVGLoss: 25477.7821\n",
      "Epoch [7/10], Loss: 40482.1211, AVGLoss: 25181.6342\n",
      "Epoch [8/10], Loss: 8603.0859, AVGLoss: 24876.1076\n",
      "Epoch [9/10], Loss: 17046.2871, AVGLoss: 24559.3798\n",
      "Epoch [10/10], Loss: 15848.1758, AVGLoss: 24212.5124\n",
      "Fold 5, MAE: 100.34197998046875, MSE: 36413.81640625, R^2: 0.21203768048218385\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 25362.9043, AVGLoss: 41955.4625\n",
      "Epoch [2/10], Loss: 26492.7168, AVGLoss: 30449.3415\n",
      "Epoch [3/10], Loss: 9025.1475, AVGLoss: 29114.4398\n",
      "Epoch [4/10], Loss: 16056.5957, AVGLoss: 28646.5889\n",
      "Epoch [5/10], Loss: 10765.6660, AVGLoss: 28279.6284\n",
      "Epoch [6/10], Loss: 200084.7031, AVGLoss: 27946.4077\n",
      "Epoch [7/10], Loss: 64570.3828, AVGLoss: 27607.7029\n",
      "Epoch [8/10], Loss: 19963.2012, AVGLoss: 27263.0002\n",
      "Epoch [9/10], Loss: 46579.9688, AVGLoss: 26898.0203\n",
      "Epoch [10/10], Loss: 16274.8291, AVGLoss: 26489.7230\n",
      "Fold 6, MAE: 82.8014907836914, MSE: 12516.2236328125, R^2: 0.019031130906260296\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 42680.0117, AVGLoss: 40787.6649\n",
      "Epoch [2/10], Loss: 14207.6572, AVGLoss: 30185.8760\n",
      "Epoch [3/10], Loss: 31101.6074, AVGLoss: 29042.0883\n",
      "Epoch [4/10], Loss: 36134.7188, AVGLoss: 28619.6265\n",
      "Epoch [5/10], Loss: 7546.2715, AVGLoss: 28235.6691\n",
      "Epoch [6/10], Loss: 11147.3467, AVGLoss: 27848.1029\n",
      "Epoch [7/10], Loss: 23158.8672, AVGLoss: 27426.1282\n",
      "Epoch [8/10], Loss: 53570.9258, AVGLoss: 26937.6795\n",
      "Epoch [9/10], Loss: 13265.4395, AVGLoss: 26368.2033\n",
      "Epoch [10/10], Loss: 9705.4004, AVGLoss: 25711.8514\n",
      "Fold 7, MAE: 83.00027465820312, MSE: 12580.4814453125, R^2: 0.20293113341818492\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 67077.1797, AVGLoss: 41897.3795\n",
      "Epoch [2/10], Loss: 16660.2656, AVGLoss: 30343.6875\n",
      "Epoch [3/10], Loss: 9732.4404, AVGLoss: 29043.4084\n",
      "Epoch [4/10], Loss: 12827.6240, AVGLoss: 28579.2375\n",
      "Epoch [5/10], Loss: 30516.6426, AVGLoss: 28220.9902\n",
      "Epoch [6/10], Loss: 20429.9863, AVGLoss: 27902.3022\n",
      "Epoch [7/10], Loss: 7434.2676, AVGLoss: 27594.4386\n",
      "Epoch [8/10], Loss: 37264.5586, AVGLoss: 27279.8040\n",
      "Epoch [9/10], Loss: 32293.2891, AVGLoss: 26944.1271\n",
      "Epoch [10/10], Loss: 31726.8574, AVGLoss: 26577.6364\n",
      "Fold 8, MAE: 77.15717315673828, MSE: 13459.158203125, R^2: 0.3150569259501804\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 31795.2676, AVGLoss: 39763.4619\n",
      "Epoch [2/10], Loss: 7471.6050, AVGLoss: 29727.8487\n",
      "Epoch [3/10], Loss: 35585.2344, AVGLoss: 28708.5584\n",
      "Epoch [4/10], Loss: 11020.7295, AVGLoss: 28275.2091\n",
      "Epoch [5/10], Loss: 5192.5278, AVGLoss: 27926.7233\n",
      "Epoch [6/10], Loss: 12594.0039, AVGLoss: 27620.5533\n",
      "Epoch [7/10], Loss: 18041.5410, AVGLoss: 27313.1611\n",
      "Epoch [8/10], Loss: 9213.2148, AVGLoss: 26977.5464\n",
      "Epoch [9/10], Loss: 11279.1484, AVGLoss: 26590.9064\n",
      "Epoch [10/10], Loss: 21187.8203, AVGLoss: 26133.3511\n",
      "Fold 9, MAE: 85.38223266601562, MSE: 16609.80859375, R^2: 0.4335808845503122\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 12838.6104, AVGLoss: 41824.0777\n",
      "Epoch [2/10], Loss: 14947.9521, AVGLoss: 29790.5064\n",
      "Epoch [3/10], Loss: 11011.7891, AVGLoss: 28056.0825\n",
      "Epoch [4/10], Loss: 13875.0605, AVGLoss: 27605.1310\n",
      "Epoch [5/10], Loss: 29649.1836, AVGLoss: 27305.6540\n",
      "Epoch [6/10], Loss: 13806.3135, AVGLoss: 27006.0679\n",
      "Epoch [7/10], Loss: 12564.4824, AVGLoss: 26678.6946\n",
      "Epoch [8/10], Loss: 57111.9414, AVGLoss: 26314.0918\n",
      "Epoch [9/10], Loss: 12802.7734, AVGLoss: 25913.3901\n",
      "Epoch [10/10], Loss: 20798.7637, AVGLoss: 25478.7755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 03:31:46,147] Trial 5 finished with value: 0.2511438249315127 and parameters: {'lr': 1.367258721438188e-05, 'num_layers': 3, 'n_units_l0': 127, 'n_units_l1': 60, 'n_units_l2': 27}. Best is trial 3 with value: 0.40348780795787587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 88.61422729492188, MSE: 22758.509765625, R^2: 0.3700392226425876\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 17952.5781, AVGLoss: 17098.0919\n",
      "Epoch [2/10], Loss: 4483.4131, AVGLoss: 13894.6624\n",
      "Epoch [3/10], Loss: 5793.0889, AVGLoss: 13206.1909\n",
      "Epoch [4/10], Loss: 12512.6660, AVGLoss: 11870.4322\n",
      "Epoch [5/10], Loss: 3847.0764, AVGLoss: 11031.0603\n",
      "Epoch [6/10], Loss: 11296.4707, AVGLoss: 11131.6576\n",
      "Epoch [7/10], Loss: 8068.3154, AVGLoss: 10645.2446\n",
      "Epoch [8/10], Loss: 13753.7354, AVGLoss: 10486.7595\n",
      "Epoch [9/10], Loss: 2301.7700, AVGLoss: 10316.5245\n",
      "Epoch [10/10], Loss: 4579.0298, AVGLoss: 10206.3776\n",
      "Fold 1, MAE: 97.27667236328125, MSE: 25165.240234375, R^2: 0.352316179808538\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 7386.5068, AVGLoss: 14970.7119\n",
      "Epoch [2/10], Loss: 24622.1855, AVGLoss: 13232.7264\n",
      "Epoch [3/10], Loss: 4460.2949, AVGLoss: 12832.4206\n",
      "Epoch [4/10], Loss: 7798.8740, AVGLoss: 12200.3075\n",
      "Epoch [5/10], Loss: 7294.5811, AVGLoss: 11913.0118\n",
      "Epoch [6/10], Loss: 6332.1875, AVGLoss: 11335.1184\n",
      "Epoch [7/10], Loss: 5817.8057, AVGLoss: 11052.2381\n",
      "Epoch [8/10], Loss: 12739.3623, AVGLoss: 10763.5114\n",
      "Epoch [9/10], Loss: 3971.5918, AVGLoss: 10706.3415\n",
      "Epoch [10/10], Loss: 12666.0664, AVGLoss: 10429.5772\n",
      "Fold 2, MAE: 89.08897399902344, MSE: 35993.41796875, R^2: 0.5796245410945533\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 6941.3276, AVGLoss: 17072.0566\n",
      "Epoch [2/10], Loss: 11659.0254, AVGLoss: 13429.8308\n",
      "Epoch [3/10], Loss: 17709.8926, AVGLoss: 12679.1863\n",
      "Epoch [4/10], Loss: 4156.6367, AVGLoss: 12343.5448\n",
      "Epoch [5/10], Loss: 9464.8965, AVGLoss: 11897.5489\n",
      "Epoch [6/10], Loss: 7605.3301, AVGLoss: 11703.5721\n",
      "Epoch [7/10], Loss: 8692.1377, AVGLoss: 11535.4016\n",
      "Epoch [8/10], Loss: 8936.8379, AVGLoss: 11338.7934\n",
      "Epoch [9/10], Loss: 17680.0000, AVGLoss: 11255.8820\n",
      "Epoch [10/10], Loss: 8050.6992, AVGLoss: 11230.4091\n",
      "Fold 3, MAE: 83.30137634277344, MSE: 24116.806640625, R^2: 0.36185466172431546\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 21047.9629, AVGLoss: 17345.1673\n",
      "Epoch [2/10], Loss: 4625.1880, AVGLoss: 14371.8939\n",
      "Epoch [3/10], Loss: 8577.8740, AVGLoss: 13115.1312\n",
      "Epoch [4/10], Loss: 12141.5098, AVGLoss: 12199.4756\n",
      "Epoch [5/10], Loss: 4771.4819, AVGLoss: 11733.7785\n",
      "Epoch [6/10], Loss: 26399.5156, AVGLoss: 11152.8132\n",
      "Epoch [7/10], Loss: 4123.4028, AVGLoss: 10665.6045\n",
      "Epoch [8/10], Loss: 2952.0583, AVGLoss: 11082.1873\n",
      "Epoch [9/10], Loss: 9109.7285, AVGLoss: 11310.4593\n",
      "Epoch [10/10], Loss: 16190.0244, AVGLoss: 10335.4391\n",
      "Fold 4, MAE: 75.99859619140625, MSE: 15523.9462890625, R^2: 0.4199129799980479\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 13463.8604, AVGLoss: 16073.9140\n",
      "Epoch [2/10], Loss: 7810.0630, AVGLoss: 13402.5654\n",
      "Epoch [3/10], Loss: 5536.4365, AVGLoss: 12513.9594\n",
      "Epoch [4/10], Loss: 13919.6719, AVGLoss: 11608.0499\n",
      "Epoch [5/10], Loss: 41880.5039, AVGLoss: 11097.8756\n",
      "Epoch [6/10], Loss: 19474.0020, AVGLoss: 10525.0008\n",
      "Epoch [7/10], Loss: 11431.9131, AVGLoss: 10397.8240\n",
      "Epoch [8/10], Loss: 8125.6230, AVGLoss: 10183.0741\n",
      "Epoch [9/10], Loss: 2548.7258, AVGLoss: 9874.6745\n",
      "Epoch [10/10], Loss: 4804.4146, AVGLoss: 9659.6877\n",
      "Fold 5, MAE: 81.83908081054688, MSE: 28527.986328125, R^2: 0.38268007953848815\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 13692.6602, AVGLoss: 28496.2130\n",
      "Epoch [2/10], Loss: 7005.9170, AVGLoss: 29216.8740\n",
      "Epoch [3/10], Loss: 10470.0947, AVGLoss: 18821.2566\n",
      "Epoch [4/10], Loss: 7212.5742, AVGLoss: 18231.5383\n",
      "Epoch [5/10], Loss: 23091.9844, AVGLoss: 16782.3701\n",
      "Epoch [6/10], Loss: 30004.6875, AVGLoss: 13864.5062\n",
      "Epoch [7/10], Loss: 10817.5547, AVGLoss: 13347.6909\n",
      "Epoch [8/10], Loss: 29891.4824, AVGLoss: 13051.9287\n",
      "Epoch [9/10], Loss: 11914.8799, AVGLoss: 14733.3388\n",
      "Epoch [10/10], Loss: 5780.5508, AVGLoss: 14632.7710\n",
      "Fold 6, MAE: 60.638671875, MSE: 7268.8115234375, R^2: 0.4303010713386768\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 11675.2041, AVGLoss: 18044.8609\n",
      "Epoch [2/10], Loss: 17068.0820, AVGLoss: 15150.9999\n",
      "Epoch [3/10], Loss: 13211.6025, AVGLoss: 14309.3372\n",
      "Epoch [4/10], Loss: 6159.6499, AVGLoss: 13845.5845\n",
      "Epoch [5/10], Loss: 8603.2480, AVGLoss: 13370.8970\n",
      "Epoch [6/10], Loss: 5145.6050, AVGLoss: 12615.9358\n",
      "Epoch [7/10], Loss: 11326.5693, AVGLoss: 12234.2580\n",
      "Epoch [8/10], Loss: 8277.9033, AVGLoss: 11934.6262\n",
      "Epoch [9/10], Loss: 18755.3789, AVGLoss: 11867.0616\n",
      "Epoch [10/10], Loss: 9697.0439, AVGLoss: 11661.6084\n",
      "Fold 7, MAE: 83.63556671142578, MSE: 16818.923828125, R^2: -0.06560626464622499\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 25083.1504, AVGLoss: 18229.0636\n",
      "Epoch [2/10], Loss: 8132.3315, AVGLoss: 15175.9271\n",
      "Epoch [3/10], Loss: 7109.3940, AVGLoss: 13990.8029\n",
      "Epoch [4/10], Loss: 14514.1875, AVGLoss: 13229.0503\n",
      "Epoch [5/10], Loss: 9104.1211, AVGLoss: 12854.1027\n",
      "Epoch [6/10], Loss: 20655.0898, AVGLoss: 13744.0471\n",
      "Epoch [7/10], Loss: 14200.4414, AVGLoss: 12824.8155\n",
      "Epoch [8/10], Loss: 19572.3340, AVGLoss: 12573.5086\n",
      "Epoch [9/10], Loss: 8000.2856, AVGLoss: 12511.8113\n",
      "Epoch [10/10], Loss: 16009.3213, AVGLoss: 12855.3495\n",
      "Fold 8, MAE: 60.86333465576172, MSE: 8550.2578125, R^2: 0.5648732817764273\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 4218.0645, AVGLoss: 17446.3595\n",
      "Epoch [2/10], Loss: 9694.2012, AVGLoss: 14392.3525\n",
      "Epoch [3/10], Loss: 5333.9849, AVGLoss: 13203.3314\n",
      "Epoch [4/10], Loss: 3857.6379, AVGLoss: 13103.3872\n",
      "Epoch [5/10], Loss: 129612.7891, AVGLoss: 12314.9253\n",
      "Epoch [6/10], Loss: 8373.1260, AVGLoss: 11891.5006\n",
      "Epoch [7/10], Loss: 3838.7217, AVGLoss: 11682.4426\n",
      "Epoch [8/10], Loss: 9327.7109, AVGLoss: 12769.8483\n",
      "Epoch [9/10], Loss: 3175.3052, AVGLoss: 13292.9404\n",
      "Epoch [10/10], Loss: 3077.0669, AVGLoss: 12552.9035\n",
      "Fold 9, MAE: 92.85454559326172, MSE: 23541.90625, R^2: 0.19718600963484845\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 28912.4570, AVGLoss: 18656.9502\n",
      "Epoch [2/10], Loss: 7846.3862, AVGLoss: 20551.5459\n",
      "Epoch [3/10], Loss: 56918.1641, AVGLoss: 18890.8507\n",
      "Epoch [4/10], Loss: 18995.7520, AVGLoss: 18050.4870\n",
      "Epoch [5/10], Loss: 25088.9766, AVGLoss: 17836.7924\n",
      "Epoch [6/10], Loss: 8847.2178, AVGLoss: 17621.5374\n",
      "Epoch [7/10], Loss: 19781.0820, AVGLoss: 17065.7162\n",
      "Epoch [8/10], Loss: 15796.2373, AVGLoss: 17037.4948\n",
      "Epoch [9/10], Loss: 29106.6289, AVGLoss: 16742.4911\n",
      "Epoch [10/10], Loss: 16314.3027, AVGLoss: 16484.5035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 04:11:19,082] Trial 6 finished with value: 0.3746414333339966 and parameters: {'lr': 0.021931500746914075, 'num_layers': 5, 'n_units_l0': 92, 'n_units_l1': 83, 'n_units_l2': 18, 'n_units_l3': 116, 'n_units_l4': 20}. Best is trial 3 with value: 0.40348780795787587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 82.4711685180664, MSE: 17222.697265625, R^2: 0.5232717930722959\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 11901.2295, AVGLoss: 32729.2336\n",
      "Epoch [2/10], Loss: 11303.9404, AVGLoss: 26933.2475\n",
      "Epoch [3/10], Loss: 16145.8223, AVGLoss: 25790.1962\n",
      "Epoch [4/10], Loss: 16116.3926, AVGLoss: 24447.0944\n",
      "Epoch [5/10], Loss: 10458.9600, AVGLoss: 22630.3708\n",
      "Epoch [6/10], Loss: 27555.6738, AVGLoss: 20244.7573\n",
      "Epoch [7/10], Loss: 10530.1738, AVGLoss: 18359.1746\n",
      "Epoch [8/10], Loss: 9283.7881, AVGLoss: 17487.1220\n",
      "Epoch [9/10], Loss: 37101.2500, AVGLoss: 16965.0290\n",
      "Epoch [10/10], Loss: 7268.7251, AVGLoss: 16568.9116\n",
      "Fold 1, MAE: 87.5767822265625, MSE: 21769.857421875, R^2: 0.43970396835044134\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 7663.7612, AVGLoss: 28206.8106\n",
      "Epoch [2/10], Loss: 21288.0176, AVGLoss: 21997.3385\n",
      "Epoch [3/10], Loss: 32326.1953, AVGLoss: 21117.8318\n",
      "Epoch [4/10], Loss: 15407.9326, AVGLoss: 20167.9045\n",
      "Epoch [5/10], Loss: 12913.5469, AVGLoss: 18866.9373\n",
      "Epoch [6/10], Loss: 10014.2812, AVGLoss: 17104.8913\n",
      "Epoch [7/10], Loss: 11962.1230, AVGLoss: 15600.9070\n",
      "Epoch [8/10], Loss: 10747.3154, AVGLoss: 14912.8185\n",
      "Epoch [9/10], Loss: 7442.5723, AVGLoss: 14603.3861\n",
      "Epoch [10/10], Loss: 10931.3877, AVGLoss: 14402.3846\n",
      "Fold 2, MAE: 98.5641860961914, MSE: 48860.3046875, R^2: 0.429349147254644\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 13285.4463, AVGLoss: 32559.0273\n",
      "Epoch [2/10], Loss: 47295.2070, AVGLoss: 26503.3454\n",
      "Epoch [3/10], Loss: 7134.8330, AVGLoss: 25244.3971\n",
      "Epoch [4/10], Loss: 34865.3320, AVGLoss: 23488.6899\n",
      "Epoch [5/10], Loss: 6802.2866, AVGLoss: 20819.5790\n",
      "Epoch [6/10], Loss: 8877.4580, AVGLoss: 18589.5793\n",
      "Epoch [7/10], Loss: 11348.9375, AVGLoss: 17686.8347\n",
      "Epoch [8/10], Loss: 17518.2539, AVGLoss: 17195.0124\n",
      "Epoch [9/10], Loss: 12178.4863, AVGLoss: 16835.1581\n",
      "Epoch [10/10], Loss: 2592.2024, AVGLoss: 16541.8449\n",
      "Fold 3, MAE: 80.50045776367188, MSE: 21616.419921875, R^2: 0.428016379979433\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 287683.9688, AVGLoss: 34373.2715\n",
      "Epoch [2/10], Loss: 139490.2969, AVGLoss: 27713.9121\n",
      "Epoch [3/10], Loss: 21462.4395, AVGLoss: 26243.7166\n",
      "Epoch [4/10], Loss: 29676.5273, AVGLoss: 24211.9592\n",
      "Epoch [5/10], Loss: 17181.1484, AVGLoss: 21087.6971\n",
      "Epoch [6/10], Loss: 172461.1719, AVGLoss: 18936.4814\n",
      "Epoch [7/10], Loss: 12658.5996, AVGLoss: 18135.8342\n",
      "Epoch [8/10], Loss: 7736.3408, AVGLoss: 17688.9710\n",
      "Epoch [9/10], Loss: 5837.1187, AVGLoss: 17375.2861\n",
      "Epoch [10/10], Loss: 13478.5029, AVGLoss: 17121.2043\n",
      "Fold 4, MAE: 79.62955474853516, MSE: 16641.7109375, R^2: 0.3781452284485164\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 34401.5938, AVGLoss: 31766.4757\n",
      "Epoch [2/10], Loss: 52351.3672, AVGLoss: 25603.4512\n",
      "Epoch [3/10], Loss: 15992.1963, AVGLoss: 24239.8835\n",
      "Epoch [4/10], Loss: 23359.4492, AVGLoss: 22489.0506\n",
      "Epoch [5/10], Loss: 10302.6143, AVGLoss: 19883.3305\n",
      "Epoch [6/10], Loss: 8204.7129, AVGLoss: 17743.4257\n",
      "Epoch [7/10], Loss: 8507.9482, AVGLoss: 16933.9986\n",
      "Epoch [8/10], Loss: 5051.0869, AVGLoss: 16569.9276\n",
      "Epoch [9/10], Loss: 24774.1855, AVGLoss: 16299.5829\n",
      "Epoch [10/10], Loss: 3799.8967, AVGLoss: 16067.7752\n",
      "Fold 5, MAE: 86.33731079101562, MSE: 27072.94921875, R^2: 0.4141657316174635\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 15503.5918, AVGLoss: 35141.3988\n",
      "Epoch [2/10], Loss: 20901.4668, AVGLoss: 28826.5163\n",
      "Epoch [3/10], Loss: 10963.5850, AVGLoss: 27722.7159\n",
      "Epoch [4/10], Loss: 82491.4844, AVGLoss: 26529.5967\n",
      "Epoch [5/10], Loss: 11976.4922, AVGLoss: 24688.4826\n",
      "Epoch [6/10], Loss: 9171.5986, AVGLoss: 21766.1146\n",
      "Epoch [7/10], Loss: 37544.0938, AVGLoss: 19655.0758\n",
      "Epoch [8/10], Loss: 37478.8711, AVGLoss: 18827.3076\n",
      "Epoch [9/10], Loss: 15318.9590, AVGLoss: 18352.9516\n",
      "Epoch [10/10], Loss: 14777.3857, AVGLoss: 17980.0966\n",
      "Fold 6, MAE: 55.75745391845703, MSE: 6951.060546875, R^2: 0.4552050363583503\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 107201.0078, AVGLoss: 34946.5162\n",
      "Epoch [2/10], Loss: 64912.6797, AVGLoss: 28402.3110\n",
      "Epoch [3/10], Loss: 94059.2188, AVGLoss: 26755.1786\n",
      "Epoch [4/10], Loss: 54638.9570, AVGLoss: 24460.3120\n",
      "Epoch [5/10], Loss: 8700.7979, AVGLoss: 21425.5751\n",
      "Epoch [6/10], Loss: 6338.1558, AVGLoss: 19207.2850\n",
      "Epoch [7/10], Loss: 7527.4258, AVGLoss: 18310.7785\n",
      "Epoch [8/10], Loss: 20761.8008, AVGLoss: 17857.2472\n",
      "Epoch [9/10], Loss: 13434.7568, AVGLoss: 17539.2902\n",
      "Epoch [10/10], Loss: 18565.4766, AVGLoss: 17277.1225\n",
      "Fold 7, MAE: 78.60197448730469, MSE: 13725.4423828125, R^2: 0.13038922924182972\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 11252.7822, AVGLoss: 35634.9028\n",
      "Epoch [2/10], Loss: 15259.5166, AVGLoss: 28928.2474\n",
      "Epoch [3/10], Loss: 21533.9785, AVGLoss: 27904.9449\n",
      "Epoch [4/10], Loss: 36608.7773, AVGLoss: 26673.8567\n",
      "Epoch [5/10], Loss: 43410.2656, AVGLoss: 25111.4981\n",
      "Epoch [6/10], Loss: 8904.0195, AVGLoss: 22856.0735\n",
      "Epoch [7/10], Loss: 10946.2471, AVGLoss: 20459.0968\n",
      "Epoch [8/10], Loss: 8573.1025, AVGLoss: 19219.8567\n",
      "Epoch [9/10], Loss: 8707.9727, AVGLoss: 18637.8551\n",
      "Epoch [10/10], Loss: 16820.6465, AVGLoss: 18260.0516\n",
      "Fold 8, MAE: 63.71400451660156, MSE: 10025.2509765625, R^2: 0.4898100833617568\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 6072.8154, AVGLoss: 33493.6664\n",
      "Epoch [2/10], Loss: 8089.9531, AVGLoss: 27977.8574\n",
      "Epoch [3/10], Loss: 23013.1484, AVGLoss: 26545.7399\n",
      "Epoch [4/10], Loss: 9541.3916, AVGLoss: 24325.4109\n",
      "Epoch [5/10], Loss: 9473.2598, AVGLoss: 21021.3611\n",
      "Epoch [6/10], Loss: 83892.6016, AVGLoss: 18736.8447\n",
      "Epoch [7/10], Loss: 13035.8857, AVGLoss: 17922.3267\n",
      "Epoch [8/10], Loss: 6731.0420, AVGLoss: 17471.9322\n",
      "Epoch [9/10], Loss: 13049.7471, AVGLoss: 17122.4359\n",
      "Epoch [10/10], Loss: 8202.5957, AVGLoss: 16809.6828\n",
      "Fold 9, MAE: 83.92906188964844, MSE: 18505.8203125, R^2: 0.36892398553826466\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 56903.0430, AVGLoss: 33162.6749\n",
      "Epoch [2/10], Loss: 32406.8066, AVGLoss: 27386.9317\n",
      "Epoch [3/10], Loss: 46030.9453, AVGLoss: 26155.6804\n",
      "Epoch [4/10], Loss: 42484.3867, AVGLoss: 24613.8292\n",
      "Epoch [5/10], Loss: 14133.6387, AVGLoss: 22157.4541\n",
      "Epoch [6/10], Loss: 21924.2695, AVGLoss: 19563.2091\n",
      "Epoch [7/10], Loss: 4775.2856, AVGLoss: 18300.2524\n",
      "Epoch [8/10], Loss: 7107.9888, AVGLoss: 17664.8308\n",
      "Epoch [9/10], Loss: 22066.4570, AVGLoss: 17223.9481\n",
      "Epoch [10/10], Loss: 24665.3203, AVGLoss: 16872.3406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 04:47:32,713] Trial 7 finished with value: 0.40851867084895466 and parameters: {'lr': 1.7879740314594983e-05, 'num_layers': 5, 'n_units_l0': 68, 'n_units_l1': 62, 'n_units_l2': 61, 'n_units_l3': 29, 'n_units_l4': 75}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 72.55000305175781, MSE: 16203.701171875, R^2: 0.5514779183388459\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 7885.7344, AVGLoss: 24088.8058\n",
      "Epoch [2/10], Loss: 6989.3062, AVGLoss: 16918.5776\n",
      "Epoch [3/10], Loss: 13152.6465, AVGLoss: 15816.5273\n",
      "Epoch [4/10], Loss: 11626.5869, AVGLoss: 15060.4946\n",
      "Epoch [5/10], Loss: 4690.1768, AVGLoss: 14377.0347\n",
      "Epoch [6/10], Loss: 8048.4683, AVGLoss: 13718.4174\n",
      "Epoch [7/10], Loss: 5860.4497, AVGLoss: 13116.6091\n",
      "Epoch [8/10], Loss: 12939.4541, AVGLoss: 12664.5358\n",
      "Epoch [9/10], Loss: 6091.9429, AVGLoss: 12315.6085\n",
      "Epoch [10/10], Loss: 5766.5532, AVGLoss: 12025.6717\n",
      "Fold 1, MAE: 89.20728302001953, MSE: 24707.23828125, R^2: 0.36410393989606316\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 6964.9688, AVGLoss: 20291.0181\n",
      "Epoch [2/10], Loss: 14244.0068, AVGLoss: 14664.2789\n",
      "Epoch [3/10], Loss: 6229.0420, AVGLoss: 13932.3752\n",
      "Epoch [4/10], Loss: 19574.4883, AVGLoss: 13564.7779\n",
      "Epoch [5/10], Loss: 12137.1123, AVGLoss: 13300.0637\n",
      "Epoch [6/10], Loss: 12578.6504, AVGLoss: 13085.3350\n",
      "Epoch [7/10], Loss: 12389.0674, AVGLoss: 12905.6909\n",
      "Epoch [8/10], Loss: 26006.6211, AVGLoss: 12738.7106\n",
      "Epoch [9/10], Loss: 35302.2109, AVGLoss: 12579.3154\n",
      "Epoch [10/10], Loss: 18220.1230, AVGLoss: 12404.6834\n",
      "Fold 2, MAE: 103.27986907958984, MSE: 48469.1328125, R^2: 0.4339177322158949\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 29877.2051, AVGLoss: 25488.5121\n",
      "Epoch [2/10], Loss: 29283.9609, AVGLoss: 17527.4572\n",
      "Epoch [3/10], Loss: 19184.4883, AVGLoss: 15882.4971\n",
      "Epoch [4/10], Loss: 56243.4922, AVGLoss: 14713.7978\n",
      "Epoch [5/10], Loss: 7130.8330, AVGLoss: 13717.9603\n",
      "Epoch [6/10], Loss: 9970.7305, AVGLoss: 13003.7781\n",
      "Epoch [7/10], Loss: 24434.4922, AVGLoss: 12508.1236\n",
      "Epoch [8/10], Loss: 7798.6416, AVGLoss: 12195.8538\n",
      "Epoch [9/10], Loss: 8844.9424, AVGLoss: 11960.2488\n",
      "Epoch [10/10], Loss: 11467.5508, AVGLoss: 11767.3356\n",
      "Fold 3, MAE: 87.65629577636719, MSE: 27014.736328125, R^2: 0.2851737057926148\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 20796.8965, AVGLoss: 25765.3624\n",
      "Epoch [2/10], Loss: 20349.7988, AVGLoss: 17497.0537\n",
      "Epoch [3/10], Loss: 5788.2173, AVGLoss: 16300.4070\n",
      "Epoch [4/10], Loss: 29121.0430, AVGLoss: 15336.9882\n",
      "Epoch [5/10], Loss: 17244.4316, AVGLoss: 14421.6635\n",
      "Epoch [6/10], Loss: 6242.4985, AVGLoss: 13658.9933\n",
      "Epoch [7/10], Loss: 7690.6230, AVGLoss: 13113.4089\n",
      "Epoch [8/10], Loss: 5969.5728, AVGLoss: 12729.4164\n",
      "Epoch [9/10], Loss: 62720.2734, AVGLoss: 12432.4589\n",
      "Epoch [10/10], Loss: 5119.8442, AVGLoss: 12188.1402\n",
      "Fold 4, MAE: 75.0955581665039, MSE: 14809.474609375, R^2: 0.4466107906222908\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 3927.6497, AVGLoss: 23952.6112\n",
      "Epoch [2/10], Loss: 3376.4236, AVGLoss: 16351.8704\n",
      "Epoch [3/10], Loss: 5664.9199, AVGLoss: 15333.0109\n",
      "Epoch [4/10], Loss: 9714.0801, AVGLoss: 14482.2678\n",
      "Epoch [5/10], Loss: 2265.0664, AVGLoss: 13657.9045\n",
      "Epoch [6/10], Loss: 14176.0312, AVGLoss: 12970.1556\n",
      "Epoch [7/10], Loss: 10491.5488, AVGLoss: 12480.7186\n",
      "Epoch [8/10], Loss: 23318.4785, AVGLoss: 12109.9441\n",
      "Epoch [9/10], Loss: 41444.0078, AVGLoss: 11825.3458\n",
      "Epoch [10/10], Loss: 16831.9414, AVGLoss: 11584.1400\n",
      "Fold 5, MAE: 81.50617980957031, MSE: 26502.619140625, R^2: 0.42650713515899863\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 11329.2891, AVGLoss: 27433.8831\n",
      "Epoch [2/10], Loss: 73395.4219, AVGLoss: 18843.3887\n",
      "Epoch [3/10], Loss: 27876.3359, AVGLoss: 17360.9123\n",
      "Epoch [4/10], Loss: 4453.2070, AVGLoss: 16517.1140\n",
      "Epoch [5/10], Loss: 17894.5938, AVGLoss: 15657.5533\n",
      "Epoch [6/10], Loss: 13693.0518, AVGLoss: 14897.6511\n",
      "Epoch [7/10], Loss: 5846.7773, AVGLoss: 14246.7716\n",
      "Epoch [8/10], Loss: 2369.8669, AVGLoss: 13723.0067\n",
      "Epoch [9/10], Loss: 7185.7041, AVGLoss: 13324.1669\n",
      "Epoch [10/10], Loss: 11590.6055, AVGLoss: 13036.6931\n",
      "Fold 6, MAE: 55.996864318847656, MSE: 6710.71142578125, R^2: 0.4740425741082628\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 26804.4629, AVGLoss: 26917.0718\n",
      "Epoch [2/10], Loss: 9791.7891, AVGLoss: 17827.5485\n",
      "Epoch [3/10], Loss: 8293.7734, AVGLoss: 16564.6826\n",
      "Epoch [4/10], Loss: 20988.5801, AVGLoss: 15652.2976\n",
      "Epoch [5/10], Loss: 16476.4062, AVGLoss: 14767.9960\n",
      "Epoch [6/10], Loss: 11903.1777, AVGLoss: 14033.1410\n",
      "Epoch [7/10], Loss: 6980.2021, AVGLoss: 13517.4644\n",
      "Epoch [8/10], Loss: 16500.9961, AVGLoss: 13126.4540\n",
      "Epoch [9/10], Loss: 25840.5352, AVGLoss: 12818.6961\n",
      "Epoch [10/10], Loss: 6947.8223, AVGLoss: 12553.1842\n",
      "Fold 7, MAE: 78.01927947998047, MSE: 14956.1669921875, R^2: 0.05241337612012453\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 9047.9375, AVGLoss: 26536.6323\n",
      "Epoch [2/10], Loss: 14377.2158, AVGLoss: 18413.4917\n",
      "Epoch [3/10], Loss: 10169.4502, AVGLoss: 16950.1439\n",
      "Epoch [4/10], Loss: 11123.9609, AVGLoss: 15975.5031\n",
      "Epoch [5/10], Loss: 14744.2568, AVGLoss: 15204.2613\n",
      "Epoch [6/10], Loss: 5504.4629, AVGLoss: 14552.9977\n",
      "Epoch [7/10], Loss: 8213.6396, AVGLoss: 14051.9440\n",
      "Epoch [8/10], Loss: 11090.6299, AVGLoss: 13697.9460\n",
      "Epoch [9/10], Loss: 12795.6338, AVGLoss: 13390.7481\n",
      "Epoch [10/10], Loss: 14611.8438, AVGLoss: 13110.5342\n",
      "Fold 8, MAE: 70.40043640136719, MSE: 11935.4501953125, R^2: 0.3925991690568279\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 2469.6504, AVGLoss: 26461.2666\n",
      "Epoch [2/10], Loss: 13242.9951, AVGLoss: 17779.5305\n",
      "Epoch [3/10], Loss: 14942.4795, AVGLoss: 16245.4179\n",
      "Epoch [4/10], Loss: 5958.5542, AVGLoss: 15214.0902\n",
      "Epoch [5/10], Loss: 5754.3486, AVGLoss: 14474.5922\n",
      "Epoch [6/10], Loss: 7076.7754, AVGLoss: 13996.9619\n",
      "Epoch [7/10], Loss: 13535.9639, AVGLoss: 13669.8723\n",
      "Epoch [8/10], Loss: 22164.9395, AVGLoss: 13414.2269\n",
      "Epoch [9/10], Loss: 23625.6660, AVGLoss: 13172.4766\n",
      "Epoch [10/10], Loss: 12713.0928, AVGLoss: 12947.6561\n",
      "Fold 9, MAE: 83.44165802001953, MSE: 19587.798828125, R^2: 0.33202696979120805\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 18412.2168, AVGLoss: 25502.7730\n",
      "Epoch [2/10], Loss: 16556.7129, AVGLoss: 17725.0893\n",
      "Epoch [3/10], Loss: 21524.4668, AVGLoss: 16281.8969\n",
      "Epoch [4/10], Loss: 29986.1680, AVGLoss: 15271.1521\n",
      "Epoch [5/10], Loss: 8995.7441, AVGLoss: 14424.7291\n",
      "Epoch [6/10], Loss: 11486.2686, AVGLoss: 13816.8745\n",
      "Epoch [7/10], Loss: 32880.5312, AVGLoss: 13407.0846\n",
      "Epoch [8/10], Loss: 6797.0366, AVGLoss: 13135.9017\n",
      "Epoch [9/10], Loss: 8305.0957, AVGLoss: 12892.3257\n",
      "Epoch [10/10], Loss: 11576.9258, AVGLoss: 12679.9311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 05:25:46,561] Trial 8 finished with value: 0.38023543682591876 and parameters: {'lr': 8.528435161303137e-05, 'num_layers': 4, 'n_units_l0': 113, 'n_units_l1': 113, 'n_units_l2': 73, 'n_units_l3': 55}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 67.40550231933594, MSE: 14632.8642578125, R^2: 0.5949589754969016\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 15006.2510, AVGLoss: 16040.4211\n",
      "Epoch [2/10], Loss: 18986.0352, AVGLoss: 13575.5262\n",
      "Epoch [3/10], Loss: 5196.5562, AVGLoss: 12552.1540\n",
      "Epoch [4/10], Loss: 4613.9141, AVGLoss: 12049.2522\n",
      "Epoch [5/10], Loss: 19023.0254, AVGLoss: 11976.5118\n",
      "Epoch [6/10], Loss: 14808.8965, AVGLoss: 11633.7491\n",
      "Epoch [7/10], Loss: 9376.9600, AVGLoss: 11125.8298\n",
      "Epoch [8/10], Loss: 11742.7178, AVGLoss: 10777.0301\n",
      "Epoch [9/10], Loss: 4458.5854, AVGLoss: 10918.8122\n",
      "Epoch [10/10], Loss: 29354.2441, AVGLoss: 10234.7038\n",
      "Fold 1, MAE: 97.82805633544922, MSE: 27657.89453125, R^2: 0.2881620730260339\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 30413.2637, AVGLoss: 14745.2931\n",
      "Epoch [2/10], Loss: 13103.4385, AVGLoss: 13098.3271\n",
      "Epoch [3/10], Loss: 6913.5840, AVGLoss: 12244.6197\n",
      "Epoch [4/10], Loss: 7676.9292, AVGLoss: 11959.4514\n",
      "Epoch [5/10], Loss: 13136.3975, AVGLoss: 11820.2099\n",
      "Epoch [6/10], Loss: 4989.2700, AVGLoss: 11347.4249\n",
      "Epoch [7/10], Loss: 9333.8145, AVGLoss: 11367.7877\n",
      "Epoch [8/10], Loss: 11019.5596, AVGLoss: 10900.8456\n",
      "Epoch [9/10], Loss: 8800.7266, AVGLoss: 10675.1220\n",
      "Epoch [10/10], Loss: 7346.3066, AVGLoss: 10232.7701\n",
      "Fold 2, MAE: 104.1400146484375, MSE: 65298.5546875, R^2: 0.23736300844241942\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 22193.5977, AVGLoss: 15626.0785\n",
      "Epoch [2/10], Loss: 3343.9695, AVGLoss: 12848.9875\n",
      "Epoch [3/10], Loss: 17352.4336, AVGLoss: 11832.0753\n",
      "Epoch [4/10], Loss: 23039.1836, AVGLoss: 11314.4334\n",
      "Epoch [5/10], Loss: 4810.2495, AVGLoss: 10973.2344\n",
      "Epoch [6/10], Loss: 3655.4492, AVGLoss: 10656.8174\n",
      "Epoch [7/10], Loss: 5948.0977, AVGLoss: 10347.6801\n",
      "Epoch [8/10], Loss: 8241.4668, AVGLoss: 10131.8151\n",
      "Epoch [9/10], Loss: 10449.0889, AVGLoss: 9933.8529\n",
      "Epoch [10/10], Loss: 4860.0459, AVGLoss: 9801.3926\n",
      "Fold 3, MAE: 87.8733139038086, MSE: 30311.8203125, R^2: 0.19793089948494202\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 5035.6826, AVGLoss: 16612.9113\n",
      "Epoch [2/10], Loss: 4883.8979, AVGLoss: 14079.4769\n",
      "Epoch [3/10], Loss: 7744.5474, AVGLoss: 13147.6923\n",
      "Epoch [4/10], Loss: 11708.3193, AVGLoss: 12647.4981\n",
      "Epoch [5/10], Loss: 21856.2207, AVGLoss: 12245.1727\n",
      "Epoch [6/10], Loss: 6893.6685, AVGLoss: 11653.1801\n",
      "Epoch [7/10], Loss: 10356.1787, AVGLoss: 11120.3159\n",
      "Epoch [8/10], Loss: 9145.0127, AVGLoss: 10446.3769\n",
      "Epoch [9/10], Loss: 4640.8584, AVGLoss: 11282.0080\n",
      "Epoch [10/10], Loss: 5980.8833, AVGLoss: 10396.6689\n",
      "Fold 4, MAE: 73.64726257324219, MSE: 13718.734375, R^2: 0.4873687609051567\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 9773.8027, AVGLoss: 15795.7837\n",
      "Epoch [2/10], Loss: 9121.0176, AVGLoss: 12782.8522\n",
      "Epoch [3/10], Loss: 6880.0605, AVGLoss: 11875.8759\n",
      "Epoch [4/10], Loss: 4587.9766, AVGLoss: 11263.3755\n",
      "Epoch [5/10], Loss: 2486.6643, AVGLoss: 10598.7332\n",
      "Epoch [6/10], Loss: 4274.1123, AVGLoss: 10186.6538\n",
      "Epoch [7/10], Loss: 4085.1448, AVGLoss: 9716.9652\n",
      "Epoch [8/10], Loss: 6218.9697, AVGLoss: 9721.8536\n",
      "Epoch [9/10], Loss: 3527.2373, AVGLoss: 9463.9750\n",
      "Epoch [10/10], Loss: 4060.5745, AVGLoss: 8556.1722\n",
      "Fold 5, MAE: 92.31253814697266, MSE: 30124.19921875, R^2: 0.34813938238962516\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 15597.2871, AVGLoss: 18000.4296\n",
      "Epoch [2/10], Loss: 15849.4795, AVGLoss: 15123.4476\n",
      "Epoch [3/10], Loss: 6533.2563, AVGLoss: 13933.3335\n",
      "Epoch [4/10], Loss: 15071.8252, AVGLoss: 13222.7609\n",
      "Epoch [5/10], Loss: 22282.0117, AVGLoss: 12686.2488\n",
      "Epoch [6/10], Loss: 19966.5586, AVGLoss: 11899.5039\n",
      "Epoch [7/10], Loss: 5736.5557, AVGLoss: 12446.1037\n",
      "Epoch [8/10], Loss: 2639.5151, AVGLoss: 12249.9270\n",
      "Epoch [9/10], Loss: 5818.6421, AVGLoss: 10737.3892\n",
      "Epoch [10/10], Loss: 7377.6943, AVGLoss: 10197.7039\n",
      "Fold 6, MAE: 57.93657684326172, MSE: 8200.9541015625, R^2: 0.3572436690455917\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 16370.8379, AVGLoss: 17295.5840\n",
      "Epoch [2/10], Loss: 5918.0171, AVGLoss: 14613.0295\n",
      "Epoch [3/10], Loss: 13173.4287, AVGLoss: 13875.5150\n",
      "Epoch [4/10], Loss: 10639.9609, AVGLoss: 13684.1555\n",
      "Epoch [5/10], Loss: 5697.9565, AVGLoss: 13305.2688\n",
      "Epoch [6/10], Loss: 7267.5508, AVGLoss: 12664.4165\n",
      "Epoch [7/10], Loss: 8346.6846, AVGLoss: 12234.4908\n",
      "Epoch [8/10], Loss: 12221.6211, AVGLoss: 12417.6087\n",
      "Epoch [9/10], Loss: 7784.5269, AVGLoss: 12480.0956\n",
      "Epoch [10/10], Loss: 9745.4990, AVGLoss: 12528.0353\n",
      "Fold 7, MAE: 76.84297943115234, MSE: 15630.154296875, R^2: 0.009711240925522446\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 18866.9609, AVGLoss: 17354.2221\n",
      "Epoch [2/10], Loss: 7967.6484, AVGLoss: 15102.4690\n",
      "Epoch [3/10], Loss: 16322.2109, AVGLoss: 14341.5482\n",
      "Epoch [4/10], Loss: 6839.0718, AVGLoss: 13807.8806\n",
      "Epoch [5/10], Loss: 9678.7178, AVGLoss: 13481.6379\n",
      "Epoch [6/10], Loss: 8988.9424, AVGLoss: 13094.7213\n",
      "Epoch [7/10], Loss: 6607.5703, AVGLoss: 12693.5668\n",
      "Epoch [8/10], Loss: 6213.4224, AVGLoss: 12563.5213\n",
      "Epoch [9/10], Loss: 14182.7900, AVGLoss: 12519.2433\n",
      "Epoch [10/10], Loss: 24851.1797, AVGLoss: 12437.9148\n",
      "Fold 8, MAE: 61.38481521606445, MSE: 9988.2578125, R^2: 0.49169271780681467\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 45326.1133, AVGLoss: 16997.1330\n",
      "Epoch [2/10], Loss: 14294.3545, AVGLoss: 14043.4655\n",
      "Epoch [3/10], Loss: 8763.8311, AVGLoss: 13179.8123\n",
      "Epoch [4/10], Loss: 6633.8237, AVGLoss: 12618.7417\n",
      "Epoch [5/10], Loss: 21131.1953, AVGLoss: 12464.6889\n",
      "Epoch [6/10], Loss: 18079.0918, AVGLoss: 12196.4132\n",
      "Epoch [7/10], Loss: 21877.3418, AVGLoss: 11853.8663\n",
      "Epoch [8/10], Loss: 6612.9990, AVGLoss: 11953.5986\n",
      "Epoch [9/10], Loss: 3080.2544, AVGLoss: 11797.9934\n",
      "Epoch [10/10], Loss: 13173.1084, AVGLoss: 11567.6071\n",
      "Fold 9, MAE: 88.39445495605469, MSE: 19510.76953125, R^2: 0.33465371198140637\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 10309.1025, AVGLoss: 16963.0961\n",
      "Epoch [2/10], Loss: 43973.3867, AVGLoss: 14523.8246\n",
      "Epoch [3/10], Loss: 6795.8281, AVGLoss: 13862.9153\n",
      "Epoch [4/10], Loss: 9279.9814, AVGLoss: 13402.8735\n",
      "Epoch [5/10], Loss: 14634.1064, AVGLoss: 12408.6652\n",
      "Epoch [6/10], Loss: 19791.1133, AVGLoss: 11928.5676\n",
      "Epoch [7/10], Loss: 10387.7012, AVGLoss: 11424.3022\n",
      "Epoch [8/10], Loss: 14893.3232, AVGLoss: 11098.3395\n",
      "Epoch [9/10], Loss: 11722.2588, AVGLoss: 10905.6078\n",
      "Epoch [10/10], Loss: 14298.7266, AVGLoss: 10835.5811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 05:58:37,984] Trial 9 finished with value: 0.32449827597455627 and parameters: {'lr': 0.021626086687883992, 'num_layers': 3, 'n_units_l0': 69, 'n_units_l1': 70, 'n_units_l2': 102}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 75.54235076904297, MSE: 18326.537109375, R^2: 0.4927172957380501\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 49474.3477, AVGLoss: 38986.3711\n",
      "Epoch [2/10], Loss: 12210.9434, AVGLoss: 28489.4377\n",
      "Epoch [3/10], Loss: 21658.0977, AVGLoss: 27495.1635\n",
      "Epoch [4/10], Loss: 14501.0322, AVGLoss: 27122.8849\n",
      "Epoch [5/10], Loss: 12398.5283, AVGLoss: 26819.7320\n",
      "Epoch [6/10], Loss: 43268.5312, AVGLoss: 26512.8191\n",
      "Epoch [7/10], Loss: 21767.0957, AVGLoss: 26163.1290\n",
      "Epoch [8/10], Loss: 84328.0703, AVGLoss: 25757.7195\n",
      "Epoch [9/10], Loss: 10480.6416, AVGLoss: 25290.1528\n",
      "Epoch [10/10], Loss: 9637.0078, AVGLoss: 24748.0829\n",
      "Fold 1, MAE: 95.8653335571289, MSE: 26916.73046875, R^2: 0.3072376665729204\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 7259.5020, AVGLoss: 33900.5467\n",
      "Epoch [2/10], Loss: 5580.0908, AVGLoss: 23528.6375\n",
      "Epoch [3/10], Loss: 13131.6680, AVGLoss: 22424.9081\n",
      "Epoch [4/10], Loss: 23670.5488, AVGLoss: 21988.6925\n",
      "Epoch [5/10], Loss: 14347.8076, AVGLoss: 21648.5432\n",
      "Epoch [6/10], Loss: 9861.1309, AVGLoss: 21290.1283\n",
      "Epoch [7/10], Loss: 20813.7129, AVGLoss: 20901.9300\n",
      "Epoch [8/10], Loss: 12249.0000, AVGLoss: 20491.5165\n",
      "Epoch [9/10], Loss: 8901.8584, AVGLoss: 20069.2550\n",
      "Epoch [10/10], Loss: 12767.4912, AVGLoss: 19621.0977\n",
      "Fold 2, MAE: 114.65128326416016, MSE: 67078.609375, R^2: 0.21657319045196055\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 33806.9375, AVGLoss: 39168.0933\n",
      "Epoch [2/10], Loss: 14757.7881, AVGLoss: 27968.2325\n",
      "Epoch [3/10], Loss: 8748.6133, AVGLoss: 26835.3568\n",
      "Epoch [4/10], Loss: 72003.2031, AVGLoss: 26395.3544\n",
      "Epoch [5/10], Loss: 33295.5352, AVGLoss: 26046.0875\n",
      "Epoch [6/10], Loss: 42230.5039, AVGLoss: 25713.5205\n",
      "Epoch [7/10], Loss: 12165.5068, AVGLoss: 25371.5166\n",
      "Epoch [8/10], Loss: 4251.9307, AVGLoss: 25003.4756\n",
      "Epoch [9/10], Loss: 9487.7461, AVGLoss: 24596.9273\n",
      "Epoch [10/10], Loss: 14562.6768, AVGLoss: 24138.1670\n",
      "Fold 3, MAE: 92.26912689208984, MSE: 28525.40234375, R^2: 0.24520039667230686\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 10895.7510, AVGLoss: 41641.1246\n",
      "Epoch [2/10], Loss: 35438.2227, AVGLoss: 29784.7687\n",
      "Epoch [3/10], Loss: 11902.2510, AVGLoss: 28262.2046\n",
      "Epoch [4/10], Loss: 74938.6719, AVGLoss: 27778.5694\n",
      "Epoch [5/10], Loss: 13486.8994, AVGLoss: 27429.1921\n",
      "Epoch [6/10], Loss: 24795.5605, AVGLoss: 27073.4016\n",
      "Epoch [7/10], Loss: 44256.5000, AVGLoss: 26689.3311\n",
      "Epoch [8/10], Loss: 40478.0391, AVGLoss: 26278.5493\n",
      "Epoch [9/10], Loss: 8272.9189, AVGLoss: 25834.2745\n",
      "Epoch [10/10], Loss: 10702.4844, AVGLoss: 25348.5640\n",
      "Fold 4, MAE: 88.18167114257812, MSE: 18833.46875, R^2: 0.2962451811323179\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 13505.4102, AVGLoss: 38320.0847\n",
      "Epoch [2/10], Loss: 8458.0303, AVGLoss: 27280.4413\n",
      "Epoch [3/10], Loss: 7573.4717, AVGLoss: 26140.3044\n",
      "Epoch [4/10], Loss: 43133.1836, AVGLoss: 25519.8293\n",
      "Epoch [5/10], Loss: 4301.5513, AVGLoss: 24959.2181\n",
      "Epoch [6/10], Loss: 4596.0464, AVGLoss: 24411.6396\n",
      "Epoch [7/10], Loss: 7011.9209, AVGLoss: 23829.3670\n",
      "Epoch [8/10], Loss: 9833.0527, AVGLoss: 23174.9744\n",
      "Epoch [9/10], Loss: 10142.0068, AVGLoss: 22407.1568\n",
      "Epoch [10/10], Loss: 7361.4409, AVGLoss: 21488.2461\n",
      "Fold 5, MAE: 95.51354217529297, MSE: 33530.78125, R^2: 0.27442402870271554\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 7313.6387, AVGLoss: 43051.7963\n",
      "Epoch [2/10], Loss: 38826.1680, AVGLoss: 30605.7038\n",
      "Epoch [3/10], Loss: 20138.4258, AVGLoss: 28931.3742\n",
      "Epoch [4/10], Loss: 13659.0479, AVGLoss: 28419.2875\n",
      "Epoch [5/10], Loss: 62242.0430, AVGLoss: 27977.6053\n",
      "Epoch [6/10], Loss: 11354.0645, AVGLoss: 27522.9196\n",
      "Epoch [7/10], Loss: 75196.6562, AVGLoss: 27036.6507\n",
      "Epoch [8/10], Loss: 6638.7388, AVGLoss: 26476.5519\n",
      "Epoch [9/10], Loss: 10070.4609, AVGLoss: 25830.2081\n",
      "Epoch [10/10], Loss: 12008.5420, AVGLoss: 25071.1882\n",
      "Fold 6, MAE: 78.67198944091797, MSE: 11737.8134765625, R^2: 0.08003954170891037\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 16683.9727, AVGLoss: 42069.5722\n",
      "Epoch [2/10], Loss: 45482.6172, AVGLoss: 30609.8265\n",
      "Epoch [3/10], Loss: 37771.3477, AVGLoss: 29185.7216\n",
      "Epoch [4/10], Loss: 18200.5957, AVGLoss: 28688.8821\n",
      "Epoch [5/10], Loss: 10185.6992, AVGLoss: 28354.1802\n",
      "Epoch [6/10], Loss: 35349.4766, AVGLoss: 28004.3047\n",
      "Epoch [7/10], Loss: 22976.0801, AVGLoss: 27605.9462\n",
      "Epoch [8/10], Loss: 25176.4824, AVGLoss: 27143.1917\n",
      "Epoch [9/10], Loss: 19601.2539, AVGLoss: 26620.9884\n",
      "Epoch [10/10], Loss: 28984.9746, AVGLoss: 26037.0561\n",
      "Fold 7, MAE: 86.35160827636719, MSE: 13408.65625, R^2: 0.15045986442638815\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 52563.5000, AVGLoss: 40453.3465\n",
      "Epoch [2/10], Loss: 20090.0723, AVGLoss: 29690.2943\n",
      "Epoch [3/10], Loss: 9793.9404, AVGLoss: 28886.7881\n",
      "Epoch [4/10], Loss: 11879.2334, AVGLoss: 28465.1461\n",
      "Epoch [5/10], Loss: 49158.3594, AVGLoss: 28052.2876\n",
      "Epoch [6/10], Loss: 44745.1719, AVGLoss: 27584.5014\n",
      "Epoch [7/10], Loss: 9588.2939, AVGLoss: 27083.1953\n",
      "Epoch [8/10], Loss: 16851.2656, AVGLoss: 26572.0326\n",
      "Epoch [9/10], Loss: 18874.5801, AVGLoss: 26038.3113\n",
      "Epoch [10/10], Loss: 9382.4033, AVGLoss: 25440.7652\n",
      "Fold 8, MAE: 75.25285339355469, MSE: 13160.9833984375, R^2: 0.3302310869100179\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 94000.0312, AVGLoss: 39453.4111\n",
      "Epoch [2/10], Loss: 9741.7285, AVGLoss: 29905.0153\n",
      "Epoch [3/10], Loss: 11677.5430, AVGLoss: 28927.7079\n",
      "Epoch [4/10], Loss: 267923.3438, AVGLoss: 28555.5080\n",
      "Epoch [5/10], Loss: 6348.6460, AVGLoss: 28190.7847\n",
      "Epoch [6/10], Loss: 3446.9131, AVGLoss: 27797.8232\n",
      "Epoch [7/10], Loss: 18761.1172, AVGLoss: 27359.1121\n",
      "Epoch [8/10], Loss: 15108.4258, AVGLoss: 26865.8462\n",
      "Epoch [9/10], Loss: 102215.0703, AVGLoss: 26310.9486\n",
      "Epoch [10/10], Loss: 6268.2437, AVGLoss: 25675.1550\n",
      "Fold 9, MAE: 86.86955261230469, MSE: 17744.75390625, R^2: 0.3948775210897484\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 14839.5586, AVGLoss: 39038.4604\n",
      "Epoch [2/10], Loss: 10409.0410, AVGLoss: 28916.8744\n",
      "Epoch [3/10], Loss: 21828.0469, AVGLoss: 27821.4796\n",
      "Epoch [4/10], Loss: 10864.6416, AVGLoss: 27415.3262\n",
      "Epoch [5/10], Loss: 29888.5605, AVGLoss: 27105.2784\n",
      "Epoch [6/10], Loss: 15291.5322, AVGLoss: 26802.7822\n",
      "Epoch [7/10], Loss: 8792.3379, AVGLoss: 26468.7941\n",
      "Epoch [8/10], Loss: 38330.5273, AVGLoss: 26100.8530\n",
      "Epoch [9/10], Loss: 63257.7734, AVGLoss: 25702.3434\n",
      "Epoch [10/10], Loss: 17688.1270, AVGLoss: 25259.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 06:31:43,638] Trial 10 finished with value: 0.2674107901738998 and parameters: {'lr': 1.0215196206727948e-05, 'num_layers': 4, 'n_units_l0': 20, 'n_units_l1': 90, 'n_units_l2': 65, 'n_units_l3': 89}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 87.24059295654297, MSE: 22441.3125, R^2: 0.378819424071712\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 22321.4062, AVGLoss: 28833.3601\n",
      "Epoch [2/10], Loss: 76043.9375, AVGLoss: 23620.4466\n",
      "Epoch [3/10], Loss: 21734.2754, AVGLoss: 18562.6960\n",
      "Epoch [4/10], Loss: 17775.9863, AVGLoss: 16787.1444\n",
      "Epoch [5/10], Loss: 10155.3174, AVGLoss: 16007.6959\n",
      "Epoch [6/10], Loss: 12702.3164, AVGLoss: 15359.2163\n",
      "Epoch [7/10], Loss: 7223.1089, AVGLoss: 14740.4089\n",
      "Epoch [8/10], Loss: 12329.1553, AVGLoss: 14212.5262\n",
      "Epoch [9/10], Loss: 11620.2646, AVGLoss: 13783.2543\n",
      "Epoch [10/10], Loss: 17446.1406, AVGLoss: 13444.7737\n",
      "Fold 1, MAE: 91.5932388305664, MSE: 24200.59765625, R^2: 0.377143441301387\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 7976.5654, AVGLoss: 23757.9902\n",
      "Epoch [2/10], Loss: 16059.9844, AVGLoss: 19340.5499\n",
      "Epoch [3/10], Loss: 6926.4673, AVGLoss: 16238.0812\n",
      "Epoch [4/10], Loss: 4066.7026, AVGLoss: 14935.2360\n",
      "Epoch [5/10], Loss: 12707.8789, AVGLoss: 14399.6678\n",
      "Epoch [6/10], Loss: 5132.7881, AVGLoss: 14063.7305\n",
      "Epoch [7/10], Loss: 6612.4033, AVGLoss: 13830.5616\n",
      "Epoch [8/10], Loss: 12197.6855, AVGLoss: 13667.4673\n",
      "Epoch [9/10], Loss: 14915.1270, AVGLoss: 13544.9311\n",
      "Epoch [10/10], Loss: 11986.3135, AVGLoss: 13444.2707\n",
      "Fold 2, MAE: 96.4540786743164, MSE: 46767.18359375, R^2: 0.45379515643662416\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 12033.8770, AVGLoss: 28406.0185\n",
      "Epoch [2/10], Loss: 10075.6533, AVGLoss: 21706.1206\n",
      "Epoch [3/10], Loss: 7554.9116, AVGLoss: 17416.8943\n",
      "Epoch [4/10], Loss: 5822.3545, AVGLoss: 16235.0641\n",
      "Epoch [5/10], Loss: 22022.9199, AVGLoss: 15327.9454\n",
      "Epoch [6/10], Loss: 9574.5371, AVGLoss: 14511.9081\n",
      "Epoch [7/10], Loss: 8526.3652, AVGLoss: 13857.6515\n",
      "Epoch [8/10], Loss: 8559.4082, AVGLoss: 13353.5119\n",
      "Epoch [9/10], Loss: 12737.8691, AVGLoss: 13010.8008\n",
      "Epoch [10/10], Loss: 7741.1846, AVGLoss: 12755.7771\n",
      "Fold 3, MAE: 84.11454010009766, MSE: 25512.498046875, R^2: 0.3249238046688182\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 22863.7207, AVGLoss: 29367.0175\n",
      "Epoch [2/10], Loss: 23025.0430, AVGLoss: 22422.5098\n",
      "Epoch [3/10], Loss: 66198.0781, AVGLoss: 17755.8282\n",
      "Epoch [4/10], Loss: 28974.8125, AVGLoss: 16776.8127\n",
      "Epoch [5/10], Loss: 6771.6333, AVGLoss: 16198.0155\n",
      "Epoch [6/10], Loss: 32909.6758, AVGLoss: 15655.8003\n",
      "Epoch [7/10], Loss: 12661.2812, AVGLoss: 15093.2044\n",
      "Epoch [8/10], Loss: 16087.9697, AVGLoss: 14570.9512\n",
      "Epoch [9/10], Loss: 9760.8984, AVGLoss: 14077.6270\n",
      "Epoch [10/10], Loss: 11068.5635, AVGLoss: 13702.4410\n",
      "Fold 4, MAE: 75.93717956542969, MSE: 15288.279296875, R^2: 0.42871922979292787\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 25644.5352, AVGLoss: 27735.4182\n",
      "Epoch [2/10], Loss: 42487.4453, AVGLoss: 21629.8594\n",
      "Epoch [3/10], Loss: 11175.1650, AVGLoss: 17178.7072\n",
      "Epoch [4/10], Loss: 21261.1934, AVGLoss: 16220.9294\n",
      "Epoch [5/10], Loss: 6458.8335, AVGLoss: 15697.4867\n",
      "Epoch [6/10], Loss: 47957.7188, AVGLoss: 15225.0361\n",
      "Epoch [7/10], Loss: 17631.9609, AVGLoss: 14715.2923\n",
      "Epoch [8/10], Loss: 4635.2002, AVGLoss: 14203.1032\n",
      "Epoch [9/10], Loss: 52996.8203, AVGLoss: 13728.4803\n",
      "Epoch [10/10], Loss: 6309.6055, AVGLoss: 13277.1607\n",
      "Fold 5, MAE: 81.08444213867188, MSE: 26470.18359375, R^2: 0.42720897386456136\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 36641.1836, AVGLoss: 30882.4146\n",
      "Epoch [2/10], Loss: 28745.3105, AVGLoss: 25980.1266\n",
      "Epoch [3/10], Loss: 16736.2969, AVGLoss: 20972.6401\n",
      "Epoch [4/10], Loss: 27579.5059, AVGLoss: 18514.1428\n",
      "Epoch [5/10], Loss: 19884.4512, AVGLoss: 17624.5101\n",
      "Epoch [6/10], Loss: 4031.0557, AVGLoss: 16976.6360\n",
      "Epoch [7/10], Loss: 33570.3555, AVGLoss: 16340.8508\n",
      "Epoch [8/10], Loss: 12000.3047, AVGLoss: 15718.3806\n",
      "Epoch [9/10], Loss: 12436.1172, AVGLoss: 15173.7855\n",
      "Epoch [10/10], Loss: 9192.0371, AVGLoss: 14764.1799\n",
      "Fold 6, MAE: 59.81312942504883, MSE: 8233.431640625, R^2: 0.35469820113990247\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 18752.3809, AVGLoss: 30459.9509\n",
      "Epoch [2/10], Loss: 10522.0186, AVGLoss: 23920.9034\n",
      "Epoch [3/10], Loss: 7436.0195, AVGLoss: 18694.4421\n",
      "Epoch [4/10], Loss: 14253.6426, AVGLoss: 17500.0365\n",
      "Epoch [5/10], Loss: 11370.8828, AVGLoss: 16924.3181\n",
      "Epoch [6/10], Loss: 9876.8506, AVGLoss: 16462.7281\n",
      "Epoch [7/10], Loss: 16290.7715, AVGLoss: 15988.6628\n",
      "Epoch [8/10], Loss: 8886.7939, AVGLoss: 15530.4139\n",
      "Epoch [9/10], Loss: 7139.7271, AVGLoss: 15025.0165\n",
      "Epoch [10/10], Loss: 15830.2627, AVGLoss: 14510.6580\n",
      "Fold 7, MAE: 76.80097961425781, MSE: 13796.81640625, R^2: 0.12586705804014942\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 29662.1426, AVGLoss: 30778.8884\n",
      "Epoch [2/10], Loss: 23038.9160, AVGLoss: 24173.1148\n",
      "Epoch [3/10], Loss: 21542.6738, AVGLoss: 19040.9133\n",
      "Epoch [4/10], Loss: 7645.1128, AVGLoss: 17851.3215\n",
      "Epoch [5/10], Loss: 18615.7480, AVGLoss: 17258.0251\n",
      "Epoch [6/10], Loss: 5787.8726, AVGLoss: 16733.3200\n",
      "Epoch [7/10], Loss: 30472.4355, AVGLoss: 16213.2699\n",
      "Epoch [8/10], Loss: 4092.1484, AVGLoss: 15667.8296\n",
      "Epoch [9/10], Loss: 11827.3604, AVGLoss: 15198.2741\n",
      "Epoch [10/10], Loss: 11838.5586, AVGLoss: 14830.8211\n",
      "Fold 8, MAE: 66.9861068725586, MSE: 10437.619140625, R^2: 0.46882451241018774\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 82677.6875, AVGLoss: 29786.7779\n",
      "Epoch [2/10], Loss: 4599.0337, AVGLoss: 22987.7232\n",
      "Epoch [3/10], Loss: 5717.0103, AVGLoss: 18330.2766\n",
      "Epoch [4/10], Loss: 25485.7148, AVGLoss: 17248.6661\n",
      "Epoch [5/10], Loss: 7925.2480, AVGLoss: 16548.6437\n",
      "Epoch [6/10], Loss: 40345.2305, AVGLoss: 15947.1489\n",
      "Epoch [7/10], Loss: 13592.7295, AVGLoss: 15385.7215\n",
      "Epoch [8/10], Loss: 4353.7178, AVGLoss: 14905.0458\n",
      "Epoch [9/10], Loss: 7328.7290, AVGLoss: 14516.8648\n",
      "Epoch [10/10], Loss: 8738.5107, AVGLoss: 14231.3390\n",
      "Fold 9, MAE: 81.03378295898438, MSE: 18380.712890625, R^2: 0.3731904079167172\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 11859.8291, AVGLoss: 29300.9323\n",
      "Epoch [2/10], Loss: 7884.8369, AVGLoss: 24547.6908\n",
      "Epoch [3/10], Loss: 13060.5820, AVGLoss: 19298.7420\n",
      "Epoch [4/10], Loss: 14430.9307, AVGLoss: 17304.9248\n",
      "Epoch [5/10], Loss: 7235.9346, AVGLoss: 16497.6558\n",
      "Epoch [6/10], Loss: 9646.1846, AVGLoss: 15922.2134\n",
      "Epoch [7/10], Loss: 12856.6768, AVGLoss: 15419.7490\n",
      "Epoch [8/10], Loss: 7819.0303, AVGLoss: 14879.9183\n",
      "Epoch [9/10], Loss: 6990.5176, AVGLoss: 14390.0653\n",
      "Epoch [10/10], Loss: 4859.9883, AVGLoss: 13999.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 07:07:11,801] Trial 11 finished with value: 0.38406955836353845 and parameters: {'lr': 4.861888468343111e-05, 'num_layers': 5, 'n_units_l0': 56, 'n_units_l1': 34, 'n_units_l2': 126, 'n_units_l3': 17, 'n_units_l4': 83}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 73.35481262207031, MSE: 17834.939453125, R^2: 0.5063247980641092\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 23931.7363, AVGLoss: 14965.9890\n",
      "Epoch [2/10], Loss: 5199.5190, AVGLoss: 11959.8786\n",
      "Epoch [3/10], Loss: 10193.6152, AVGLoss: 10669.6527\n",
      "Epoch [4/10], Loss: 8052.9634, AVGLoss: 9972.4078\n",
      "Epoch [5/10], Loss: 5686.4326, AVGLoss: 9776.7528\n",
      "Epoch [6/10], Loss: 9154.4707, AVGLoss: 9407.8039\n",
      "Epoch [7/10], Loss: 6770.0713, AVGLoss: 8956.4539\n",
      "Epoch [8/10], Loss: 9421.8447, AVGLoss: 8764.3259\n",
      "Epoch [9/10], Loss: 8480.5986, AVGLoss: 8570.2243\n",
      "Epoch [10/10], Loss: 49598.0430, AVGLoss: 8356.8343\n",
      "Fold 1, MAE: 91.15430450439453, MSE: 22815.94140625, R^2: 0.41278064046709007\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 6211.2773, AVGLoss: 14293.3087\n",
      "Epoch [2/10], Loss: 27260.3945, AVGLoss: 12397.2856\n",
      "Epoch [3/10], Loss: 9325.6650, AVGLoss: 11998.1117\n",
      "Epoch [4/10], Loss: 5015.2070, AVGLoss: 11076.9547\n",
      "Epoch [5/10], Loss: 4906.1729, AVGLoss: 11021.7185\n",
      "Epoch [6/10], Loss: 8121.5396, AVGLoss: 10263.7701\n",
      "Epoch [7/10], Loss: 11792.3350, AVGLoss: 9364.7990\n",
      "Epoch [8/10], Loss: 8110.6533, AVGLoss: 8684.1949\n",
      "Epoch [9/10], Loss: 7378.0908, AVGLoss: 7927.8807\n",
      "Epoch [10/10], Loss: 1874.0804, AVGLoss: 7209.9511\n",
      "Fold 2, MAE: 118.56047821044922, MSE: 79499.296875, R^2: 0.07150917888309716\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 54689.4648, AVGLoss: 15194.4899\n",
      "Epoch [2/10], Loss: 3294.1206, AVGLoss: 12146.6195\n",
      "Epoch [3/10], Loss: 14453.9072, AVGLoss: 11082.3691\n",
      "Epoch [4/10], Loss: 9300.7051, AVGLoss: 10337.9005\n",
      "Epoch [5/10], Loss: 6069.0601, AVGLoss: 9885.6199\n",
      "Epoch [6/10], Loss: 2745.4233, AVGLoss: 9752.9013\n",
      "Epoch [7/10], Loss: 5399.8335, AVGLoss: 9095.7786\n",
      "Epoch [8/10], Loss: 3361.0801, AVGLoss: 8662.0862\n",
      "Epoch [9/10], Loss: 4569.3696, AVGLoss: 7759.9576\n",
      "Epoch [10/10], Loss: 27772.7598, AVGLoss: 7093.2116\n",
      "Fold 3, MAE: 86.72462463378906, MSE: 31795.232421875, R^2: 0.15867888421363008\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 21481.0918, AVGLoss: 15808.5366\n",
      "Epoch [2/10], Loss: 6375.3521, AVGLoss: 13023.6899\n",
      "Epoch [3/10], Loss: 16453.5410, AVGLoss: 12212.5555\n",
      "Epoch [4/10], Loss: 9429.8691, AVGLoss: 11100.8506\n",
      "Epoch [5/10], Loss: 8394.8877, AVGLoss: 10950.3149\n",
      "Epoch [6/10], Loss: 6452.2446, AVGLoss: 10371.3936\n",
      "Epoch [7/10], Loss: 3853.8188, AVGLoss: 9589.9313\n",
      "Epoch [8/10], Loss: 7883.9683, AVGLoss: 9415.4267\n",
      "Epoch [9/10], Loss: 5277.2690, AVGLoss: 8290.5399\n",
      "Epoch [10/10], Loss: 4456.2949, AVGLoss: 8421.0860\n",
      "Fold 4, MAE: 82.47199249267578, MSE: 18280.783203125, R^2: 0.31689761833896324\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 33544.7891, AVGLoss: 14487.9864\n",
      "Epoch [2/10], Loss: 2865.0586, AVGLoss: 11788.5002\n",
      "Epoch [3/10], Loss: 2018.5214, AVGLoss: 10500.5821\n",
      "Epoch [4/10], Loss: 11975.1377, AVGLoss: 9496.2435\n",
      "Epoch [5/10], Loss: 4632.8271, AVGLoss: 8858.8736\n",
      "Epoch [6/10], Loss: 16102.0537, AVGLoss: 8469.2053\n",
      "Epoch [7/10], Loss: 1756.5045, AVGLoss: 8112.1030\n",
      "Epoch [8/10], Loss: 9292.6865, AVGLoss: 7840.0659\n",
      "Epoch [9/10], Loss: 23253.0859, AVGLoss: 7653.5227\n",
      "Epoch [10/10], Loss: 5625.7524, AVGLoss: 7479.1685\n",
      "Fold 5, MAE: 89.0125732421875, MSE: 25194.03125, R^2: 0.454823789692549\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 8394.0078, AVGLoss: 16767.3919\n",
      "Epoch [2/10], Loss: 13661.7715, AVGLoss: 13386.4467\n",
      "Epoch [3/10], Loss: 11320.1631, AVGLoss: 12092.8106\n",
      "Epoch [4/10], Loss: 5093.0142, AVGLoss: 11265.9619\n",
      "Epoch [5/10], Loss: 11596.6738, AVGLoss: 10984.3212\n",
      "Epoch [6/10], Loss: 4695.9580, AVGLoss: 9945.7024\n",
      "Epoch [7/10], Loss: 16628.0137, AVGLoss: 9119.3151\n",
      "Epoch [8/10], Loss: 4452.0083, AVGLoss: 8490.3483\n",
      "Epoch [9/10], Loss: 2833.0410, AVGLoss: 8417.8836\n",
      "Epoch [10/10], Loss: 6139.4814, AVGLoss: 7929.9360\n",
      "Fold 6, MAE: 70.55166625976562, MSE: 10765.91015625, R^2: 0.15621311697757767\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 11886.0273, AVGLoss: 16254.6274\n",
      "Epoch [2/10], Loss: 12866.7373, AVGLoss: 13412.5198\n",
      "Epoch [3/10], Loss: 16613.2266, AVGLoss: 12308.8979\n",
      "Epoch [4/10], Loss: 13778.5957, AVGLoss: 11653.1697\n",
      "Epoch [5/10], Loss: 3445.2146, AVGLoss: 10766.9117\n",
      "Epoch [6/10], Loss: 6432.9316, AVGLoss: 10038.4501\n",
      "Epoch [7/10], Loss: 16721.4531, AVGLoss: 10440.1704\n",
      "Epoch [8/10], Loss: 9077.8066, AVGLoss: 9350.1180\n",
      "Epoch [9/10], Loss: 12342.6729, AVGLoss: 8866.0154\n",
      "Epoch [10/10], Loss: 9715.7227, AVGLoss: 8450.1593\n",
      "Fold 7, MAE: 83.29296875, MSE: 18372.037109375, R^2: -0.16400777206119344\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 9547.4561, AVGLoss: 16436.6131\n",
      "Epoch [2/10], Loss: 9487.2803, AVGLoss: 13520.0556\n",
      "Epoch [3/10], Loss: 4226.1680, AVGLoss: 12240.5249\n",
      "Epoch [4/10], Loss: 5505.9976, AVGLoss: 11312.9118\n",
      "Epoch [5/10], Loss: 19454.1855, AVGLoss: 10581.4458\n",
      "Epoch [6/10], Loss: 10037.4268, AVGLoss: 9428.3075\n",
      "Epoch [7/10], Loss: 6414.3945, AVGLoss: 8856.6030\n",
      "Epoch [8/10], Loss: 9631.3154, AVGLoss: 9149.3703\n",
      "Epoch [9/10], Loss: 9886.0986, AVGLoss: 8620.6058\n",
      "Epoch [10/10], Loss: 4891.2651, AVGLoss: 7826.8276\n",
      "Fold 8, MAE: 78.2231216430664, MSE: 18366.79296875, R^2: 0.06530495171645656\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 3702.3706, AVGLoss: 15751.1404\n",
      "Epoch [2/10], Loss: 4540.5273, AVGLoss: 12886.9005\n",
      "Epoch [3/10], Loss: 37679.9492, AVGLoss: 11901.5005\n",
      "Epoch [4/10], Loss: 5656.1216, AVGLoss: 10916.2752\n",
      "Epoch [5/10], Loss: 11399.5645, AVGLoss: 10824.0016\n",
      "Epoch [6/10], Loss: 9682.5430, AVGLoss: 10152.1248\n",
      "Epoch [7/10], Loss: 1505.5847, AVGLoss: 9241.2541\n",
      "Epoch [8/10], Loss: 9711.4883, AVGLoss: 8644.0684\n",
      "Epoch [9/10], Loss: 3985.9990, AVGLoss: 8442.9702\n",
      "Epoch [10/10], Loss: 5066.6567, AVGLoss: 7717.7875\n",
      "Fold 9, MAE: 89.40133666992188, MSE: 22770.76171875, R^2: 0.22348324700503308\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 15978.4502, AVGLoss: 15789.4936\n",
      "Epoch [2/10], Loss: 16006.3506, AVGLoss: 12828.1157\n",
      "Epoch [3/10], Loss: 5240.3779, AVGLoss: 11559.3594\n",
      "Epoch [4/10], Loss: 8556.9043, AVGLoss: 10456.7003\n",
      "Epoch [5/10], Loss: 3308.4082, AVGLoss: 9878.9407\n",
      "Epoch [6/10], Loss: 8744.1201, AVGLoss: 9155.9594\n",
      "Epoch [7/10], Loss: 19771.6289, AVGLoss: 8559.3967\n",
      "Epoch [8/10], Loss: 5012.5566, AVGLoss: 8269.1884\n",
      "Epoch [9/10], Loss: 6764.0312, AVGLoss: 8154.9269\n",
      "Epoch [10/10], Loss: 3070.4158, AVGLoss: 7888.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 07:45:07,134] Trial 12 finished with value: 0.21129971434803418 and parameters: {'lr': 0.0037394474284245124, 'num_layers': 5, 'n_units_l0': 89, 'n_units_l1': 46, 'n_units_l2': 58, 'n_units_l3': 46, 'n_units_l4': 46}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 81.48343658447266, MSE: 21050.638671875, R^2: 0.4173134882471383\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 15698.3047, AVGLoss: 30437.5316\n",
      "Epoch [2/10], Loss: 17829.5332, AVGLoss: 25443.6718\n",
      "Epoch [3/10], Loss: 12241.6689, AVGLoss: 22528.9214\n",
      "Epoch [4/10], Loss: 41979.2617, AVGLoss: 18774.5667\n",
      "Epoch [5/10], Loss: 12491.3369, AVGLoss: 17151.8972\n",
      "Epoch [6/10], Loss: 4774.8696, AVGLoss: 16409.3755\n",
      "Epoch [7/10], Loss: 52892.9766, AVGLoss: 15906.7481\n",
      "Epoch [8/10], Loss: 3530.5051, AVGLoss: 15487.9825\n",
      "Epoch [9/10], Loss: 119435.8359, AVGLoss: 15118.8018\n",
      "Epoch [10/10], Loss: 17990.5898, AVGLoss: 14745.4400\n",
      "Fold 1, MAE: 92.59767150878906, MSE: 25421.88671875, R^2: 0.34571071284686783\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 5445.1187, AVGLoss: 25446.9782\n",
      "Epoch [2/10], Loss: 24482.4883, AVGLoss: 21206.1819\n",
      "Epoch [3/10], Loss: 23554.1895, AVGLoss: 19780.5090\n",
      "Epoch [4/10], Loss: 11131.2266, AVGLoss: 17535.9833\n",
      "Epoch [5/10], Loss: 18253.7285, AVGLoss: 15637.6277\n",
      "Epoch [6/10], Loss: 23423.5801, AVGLoss: 14939.5869\n",
      "Epoch [7/10], Loss: 8927.1631, AVGLoss: 14631.3154\n",
      "Epoch [8/10], Loss: 20380.9824, AVGLoss: 14434.3799\n",
      "Epoch [9/10], Loss: 7052.4717, AVGLoss: 14280.8700\n",
      "Epoch [10/10], Loss: 16948.9297, AVGLoss: 14143.8989\n",
      "Fold 2, MAE: 96.40414428710938, MSE: 46957.63671875, R^2: 0.45157087111237404\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 40004.6836, AVGLoss: 29953.3753\n",
      "Epoch [2/10], Loss: 9749.8398, AVGLoss: 24798.8456\n",
      "Epoch [3/10], Loss: 14843.4287, AVGLoss: 21515.9940\n",
      "Epoch [4/10], Loss: 8594.0078, AVGLoss: 18157.5935\n",
      "Epoch [5/10], Loss: 60189.1094, AVGLoss: 17063.7782\n",
      "Epoch [6/10], Loss: 8394.6816, AVGLoss: 16485.7449\n",
      "Epoch [7/10], Loss: 16890.0215, AVGLoss: 16004.7951\n",
      "Epoch [8/10], Loss: 7689.6177, AVGLoss: 15582.1606\n",
      "Epoch [9/10], Loss: 10023.6396, AVGLoss: 15215.7110\n",
      "Epoch [10/10], Loss: 13697.3174, AVGLoss: 14869.4710\n",
      "Fold 3, MAE: 77.53382110595703, MSE: 21505.9453125, R^2: 0.4309396496545669\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 26458.0840, AVGLoss: 31402.3755\n",
      "Epoch [2/10], Loss: 18233.3477, AVGLoss: 26758.7146\n",
      "Epoch [3/10], Loss: 30583.3730, AVGLoss: 23601.2757\n",
      "Epoch [4/10], Loss: 23704.7656, AVGLoss: 19431.9912\n",
      "Epoch [5/10], Loss: 7746.7446, AVGLoss: 17858.8365\n",
      "Epoch [6/10], Loss: 13471.7598, AVGLoss: 17206.9549\n",
      "Epoch [7/10], Loss: 28862.1797, AVGLoss: 16761.8577\n",
      "Epoch [8/10], Loss: 9542.9980, AVGLoss: 16425.2371\n",
      "Epoch [9/10], Loss: 10428.9707, AVGLoss: 16116.1434\n",
      "Epoch [10/10], Loss: 5100.4458, AVGLoss: 15819.6187\n",
      "Fold 4, MAE: 78.4084243774414, MSE: 16318.8828125, R^2: 0.39020836428299355\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 3313.9036, AVGLoss: 29297.0223\n",
      "Epoch [2/10], Loss: 28506.0977, AVGLoss: 24082.1236\n",
      "Epoch [3/10], Loss: 9789.6309, AVGLoss: 20639.7320\n",
      "Epoch [4/10], Loss: 10935.4912, AVGLoss: 17528.1014\n",
      "Epoch [5/10], Loss: 7544.4321, AVGLoss: 16729.8674\n",
      "Epoch [6/10], Loss: 15009.2656, AVGLoss: 16333.7875\n",
      "Epoch [7/10], Loss: 23689.4199, AVGLoss: 16019.8376\n",
      "Epoch [8/10], Loss: 4625.1357, AVGLoss: 15738.5275\n",
      "Epoch [9/10], Loss: 21744.4395, AVGLoss: 15480.4707\n",
      "Epoch [10/10], Loss: 8173.9370, AVGLoss: 15205.5072\n",
      "Fold 5, MAE: 86.52165985107422, MSE: 26644.328125, R^2: 0.4234406491700283\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 52452.7617, AVGLoss: 32193.3314\n",
      "Epoch [2/10], Loss: 20830.1699, AVGLoss: 26900.2274\n",
      "Epoch [3/10], Loss: 5853.1880, AVGLoss: 23649.3369\n",
      "Epoch [4/10], Loss: 9936.6357, AVGLoss: 19809.7680\n",
      "Epoch [5/10], Loss: 8420.3105, AVGLoss: 18586.3083\n",
      "Epoch [6/10], Loss: 10198.2441, AVGLoss: 18138.4529\n",
      "Epoch [7/10], Loss: 7054.0693, AVGLoss: 17823.4663\n",
      "Epoch [8/10], Loss: 7191.9888, AVGLoss: 17570.0343\n",
      "Epoch [9/10], Loss: 14644.2705, AVGLoss: 17336.0760\n",
      "Epoch [10/10], Loss: 14955.3125, AVGLoss: 17104.2536\n",
      "Fold 6, MAE: 53.01869201660156, MSE: 6714.1767578125, R^2: 0.4737711061009595\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 19203.7500, AVGLoss: 32144.3274\n",
      "Epoch [2/10], Loss: 25903.6484, AVGLoss: 26948.6455\n",
      "Epoch [3/10], Loss: 7780.4990, AVGLoss: 22879.0494\n",
      "Epoch [4/10], Loss: 20049.2480, AVGLoss: 18794.5130\n",
      "Epoch [5/10], Loss: 34857.2656, AVGLoss: 17782.0732\n",
      "Epoch [6/10], Loss: 8193.9766, AVGLoss: 17371.7569\n",
      "Epoch [7/10], Loss: 11585.9775, AVGLoss: 17054.6737\n",
      "Epoch [8/10], Loss: 12919.6768, AVGLoss: 16773.9264\n",
      "Epoch [9/10], Loss: 27343.2285, AVGLoss: 16559.4433\n",
      "Epoch [10/10], Loss: 7854.4478, AVGLoss: 16351.9374\n",
      "Fold 7, MAE: 76.38314819335938, MSE: 13619.322265625, R^2: 0.1371126155887279\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 25778.0840, AVGLoss: 32466.7654\n",
      "Epoch [2/10], Loss: 17462.1074, AVGLoss: 27467.1641\n",
      "Epoch [3/10], Loss: 4866.2437, AVGLoss: 25186.7579\n",
      "Epoch [4/10], Loss: 100363.5547, AVGLoss: 21328.8996\n",
      "Epoch [5/10], Loss: 12996.7568, AVGLoss: 18825.2734\n",
      "Epoch [6/10], Loss: 9047.0498, AVGLoss: 17994.2015\n",
      "Epoch [7/10], Loss: 10801.1611, AVGLoss: 17514.8632\n",
      "Epoch [8/10], Loss: 36374.7539, AVGLoss: 17144.2302\n",
      "Epoch [9/10], Loss: 11024.0439, AVGLoss: 16819.5568\n",
      "Epoch [10/10], Loss: 6865.6641, AVGLoss: 16485.5282\n",
      "Fold 8, MAE: 68.76131439208984, MSE: 11305.1611328125, R^2: 0.42467491305174543\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 32502.3027, AVGLoss: 32090.1061\n",
      "Epoch [2/10], Loss: 32058.9102, AVGLoss: 27336.4949\n",
      "Epoch [3/10], Loss: 4268.9233, AVGLoss: 23959.4856\n",
      "Epoch [4/10], Loss: 11464.3252, AVGLoss: 19590.1176\n",
      "Epoch [5/10], Loss: 4399.6152, AVGLoss: 18094.7647\n",
      "Epoch [6/10], Loss: 17509.5605, AVGLoss: 17474.3994\n",
      "Epoch [7/10], Loss: 7922.3848, AVGLoss: 17043.9555\n",
      "Epoch [8/10], Loss: 4671.6265, AVGLoss: 16651.0641\n",
      "Epoch [9/10], Loss: 23762.4160, AVGLoss: 16267.3434\n",
      "Epoch [10/10], Loss: 8648.5039, AVGLoss: 15850.5964\n",
      "Fold 9, MAE: 79.86382293701172, MSE: 17519.587890625, R^2: 0.4025560190933355\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 13187.5059, AVGLoss: 30574.0575\n",
      "Epoch [2/10], Loss: 27137.6113, AVGLoss: 25611.2957\n",
      "Epoch [3/10], Loss: 11303.5898, AVGLoss: 22170.2795\n",
      "Epoch [4/10], Loss: 8556.8682, AVGLoss: 18830.5021\n",
      "Epoch [5/10], Loss: 11513.0732, AVGLoss: 17808.8745\n",
      "Epoch [6/10], Loss: 5514.8765, AVGLoss: 17254.6940\n",
      "Epoch [7/10], Loss: 16826.2461, AVGLoss: 16839.9633\n",
      "Epoch [8/10], Loss: 7851.6626, AVGLoss: 16496.5301\n",
      "Epoch [9/10], Loss: 26394.3398, AVGLoss: 16172.3411\n",
      "Epoch [10/10], Loss: 13084.1152, AVGLoss: 15886.8929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 08:19:52,396] Trial 13 finished with value: 0.4035071900840622 and parameters: {'lr': 3.393398114876199e-05, 'num_layers': 5, 'n_units_l0': 42, 'n_units_l1': 22, 'n_units_l2': 89, 'n_units_l3': 21, 'n_units_l4': 127}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 70.07286834716797, MSE: 16073.314453125, R^2: 0.5550869999390237\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 5589.5845, AVGLoss: 33629.0487\n",
      "Epoch [2/10], Loss: 14957.2529, AVGLoss: 27291.1264\n",
      "Epoch [3/10], Loss: 9014.0615, AVGLoss: 26367.1256\n",
      "Epoch [4/10], Loss: 11403.5996, AVGLoss: 25379.2505\n",
      "Epoch [5/10], Loss: 21559.6348, AVGLoss: 24070.1168\n",
      "Epoch [6/10], Loss: 27141.6172, AVGLoss: 22373.6732\n",
      "Epoch [7/10], Loss: 6494.6099, AVGLoss: 20419.5158\n",
      "Epoch [8/10], Loss: 11527.2607, AVGLoss: 18824.6707\n",
      "Epoch [9/10], Loss: 18710.7129, AVGLoss: 17890.6974\n",
      "Epoch [10/10], Loss: 10785.3809, AVGLoss: 17345.0649\n",
      "Fold 1, MAE: 87.71614074707031, MSE: 21361.091796875, R^2: 0.450224496372707\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 10199.5898, AVGLoss: 28304.0604\n",
      "Epoch [2/10], Loss: 6762.8203, AVGLoss: 22157.4752\n",
      "Epoch [3/10], Loss: 49967.7031, AVGLoss: 21347.2791\n",
      "Epoch [4/10], Loss: 7441.4233, AVGLoss: 20534.6972\n",
      "Epoch [5/10], Loss: 40329.2148, AVGLoss: 19539.9429\n",
      "Epoch [6/10], Loss: 21499.2227, AVGLoss: 18255.4668\n",
      "Epoch [7/10], Loss: 6811.8701, AVGLoss: 16834.0859\n",
      "Epoch [8/10], Loss: 28742.5605, AVGLoss: 15808.3863\n",
      "Epoch [9/10], Loss: 16944.0586, AVGLoss: 15288.8146\n",
      "Epoch [10/10], Loss: 5344.0723, AVGLoss: 15039.8281\n",
      "Fold 2, MAE: 95.18865966796875, MSE: 48667.6015625, R^2: 0.43159978681961575\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 7867.7461, AVGLoss: 34128.0695\n",
      "Epoch [2/10], Loss: 18896.5957, AVGLoss: 26855.5743\n",
      "Epoch [3/10], Loss: 17088.9395, AVGLoss: 26008.9493\n",
      "Epoch [4/10], Loss: 64077.1602, AVGLoss: 25094.9376\n",
      "Epoch [5/10], Loss: 10342.6123, AVGLoss: 23938.6938\n",
      "Epoch [6/10], Loss: 24888.8281, AVGLoss: 22392.1699\n",
      "Epoch [7/10], Loss: 12449.5586, AVGLoss: 20532.1361\n",
      "Epoch [8/10], Loss: 31255.0117, AVGLoss: 18935.1063\n",
      "Epoch [9/10], Loss: 8069.4209, AVGLoss: 18009.7662\n",
      "Epoch [10/10], Loss: 49643.0977, AVGLoss: 17536.9016\n",
      "Fold 3, MAE: 78.12068939208984, MSE: 20647.046875, R^2: 0.4536666348965769\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 37813.2617, AVGLoss: 35748.2605\n",
      "Epoch [2/10], Loss: 7791.6401, AVGLoss: 28105.6644\n",
      "Epoch [3/10], Loss: 12507.9346, AVGLoss: 27112.5517\n",
      "Epoch [4/10], Loss: 9547.7471, AVGLoss: 26134.9032\n",
      "Epoch [5/10], Loss: 79508.2031, AVGLoss: 24954.1895\n",
      "Epoch [6/10], Loss: 33694.7578, AVGLoss: 23284.9266\n",
      "Epoch [7/10], Loss: 4479.1982, AVGLoss: 21047.1253\n",
      "Epoch [8/10], Loss: 99581.0625, AVGLoss: 19202.0200\n",
      "Epoch [9/10], Loss: 16653.3594, AVGLoss: 18282.1780\n",
      "Epoch [10/10], Loss: 11658.3848, AVGLoss: 17831.9075\n",
      "Fold 4, MAE: 81.08492279052734, MSE: 16874.140625, R^2: 0.3694599436468814\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 4107.2891, AVGLoss: 32385.1650\n",
      "Epoch [2/10], Loss: 12655.5078, AVGLoss: 25972.6263\n",
      "Epoch [3/10], Loss: 10981.0703, AVGLoss: 25207.2973\n",
      "Epoch [4/10], Loss: 15049.9541, AVGLoss: 24467.9314\n",
      "Epoch [5/10], Loss: 4976.7002, AVGLoss: 23664.3836\n",
      "Epoch [6/10], Loss: 19048.7422, AVGLoss: 22568.8614\n",
      "Epoch [7/10], Loss: 12898.8965, AVGLoss: 20947.8463\n",
      "Epoch [8/10], Loss: 7031.6362, AVGLoss: 19036.8784\n",
      "Epoch [9/10], Loss: 34724.7852, AVGLoss: 17587.8051\n",
      "Epoch [10/10], Loss: 8132.5615, AVGLoss: 16833.9495\n",
      "Fold 5, MAE: 86.65760803222656, MSE: 28028.763671875, R^2: 0.39348271328773843\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 15227.5459, AVGLoss: 35730.1596\n",
      "Epoch [2/10], Loss: 43418.7031, AVGLoss: 28968.9260\n",
      "Epoch [3/10], Loss: 18837.8574, AVGLoss: 28226.6057\n",
      "Epoch [4/10], Loss: 10546.9404, AVGLoss: 27517.1417\n",
      "Epoch [5/10], Loss: 8870.5420, AVGLoss: 26714.9571\n",
      "Epoch [6/10], Loss: 36814.5312, AVGLoss: 25844.8657\n",
      "Epoch [7/10], Loss: 6629.9995, AVGLoss: 24784.0764\n",
      "Epoch [8/10], Loss: 19365.5254, AVGLoss: 23411.4289\n",
      "Epoch [9/10], Loss: 15940.7148, AVGLoss: 21826.6039\n",
      "Epoch [10/10], Loss: 33989.5312, AVGLoss: 20415.7726\n",
      "Fold 6, MAE: 61.91893005371094, MSE: 8429.0029296875, R^2: 0.3393701656118062\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 30638.6133, AVGLoss: 35930.0746\n",
      "Epoch [2/10], Loss: 47169.2578, AVGLoss: 28939.7058\n",
      "Epoch [3/10], Loss: 7820.6626, AVGLoss: 28005.9799\n",
      "Epoch [4/10], Loss: 15856.1270, AVGLoss: 26970.2786\n",
      "Epoch [5/10], Loss: 11010.5693, AVGLoss: 25656.8733\n",
      "Epoch [6/10], Loss: 24800.1797, AVGLoss: 23782.8611\n",
      "Epoch [7/10], Loss: 16489.5176, AVGLoss: 21304.7963\n",
      "Epoch [8/10], Loss: 57084.7852, AVGLoss: 19397.6158\n",
      "Epoch [9/10], Loss: 35916.9688, AVGLoss: 18514.8027\n",
      "Epoch [10/10], Loss: 19468.0449, AVGLoss: 18044.7221\n",
      "Fold 7, MAE: 73.51165771484375, MSE: 12806.333984375, R^2: 0.18862159373165666\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 10904.8174, AVGLoss: 35914.6081\n",
      "Epoch [2/10], Loss: 8181.9434, AVGLoss: 28693.9129\n",
      "Epoch [3/10], Loss: 30619.2344, AVGLoss: 27573.4089\n",
      "Epoch [4/10], Loss: 11354.7529, AVGLoss: 26505.2651\n",
      "Epoch [5/10], Loss: 22590.1621, AVGLoss: 25372.6527\n",
      "Epoch [6/10], Loss: 15633.3623, AVGLoss: 23895.9881\n",
      "Epoch [7/10], Loss: 10237.3408, AVGLoss: 22000.0943\n",
      "Epoch [8/10], Loss: 30345.8223, AVGLoss: 20192.5061\n",
      "Epoch [9/10], Loss: 13499.1709, AVGLoss: 19061.4033\n",
      "Epoch [10/10], Loss: 8711.0586, AVGLoss: 18457.7198\n",
      "Fold 8, MAE: 66.35970306396484, MSE: 10488.40625, R^2: 0.46623996968482917\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 11133.8320, AVGLoss: 34589.4413\n",
      "Epoch [2/10], Loss: 89701.9219, AVGLoss: 28245.2631\n",
      "Epoch [3/10], Loss: 9723.6152, AVGLoss: 27349.4306\n",
      "Epoch [4/10], Loss: 118356.9141, AVGLoss: 26417.0965\n",
      "Epoch [5/10], Loss: 32955.5977, AVGLoss: 25164.0158\n",
      "Epoch [6/10], Loss: 57531.2500, AVGLoss: 23409.0944\n",
      "Epoch [7/10], Loss: 42951.0430, AVGLoss: 21173.9892\n",
      "Epoch [8/10], Loss: 4283.0103, AVGLoss: 19337.7386\n",
      "Epoch [9/10], Loss: 5176.6118, AVGLoss: 18427.3987\n",
      "Epoch [10/10], Loss: 15347.5938, AVGLoss: 17955.0210\n",
      "Fold 9, MAE: 79.68057250976562, MSE: 16736.7578125, R^2: 0.4292516563105737\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 12329.2295, AVGLoss: 34320.0881\n",
      "Epoch [2/10], Loss: 28253.1523, AVGLoss: 27721.8340\n",
      "Epoch [3/10], Loss: 21214.4551, AVGLoss: 26679.7513\n",
      "Epoch [4/10], Loss: 24419.7676, AVGLoss: 25753.5336\n",
      "Epoch [5/10], Loss: 33513.8828, AVGLoss: 24735.5147\n",
      "Epoch [6/10], Loss: 19197.0801, AVGLoss: 23482.7781\n",
      "Epoch [7/10], Loss: 13182.9277, AVGLoss: 21939.0486\n",
      "Epoch [8/10], Loss: 15530.8633, AVGLoss: 20358.4628\n",
      "Epoch [9/10], Loss: 34062.7344, AVGLoss: 19156.7415\n",
      "Epoch [10/10], Loss: 5874.6318, AVGLoss: 18417.4240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 08:51:38,985] Trial 14 finished with value: 0.4045876786676848 and parameters: {'lr': 2.2096787734714057e-05, 'num_layers': 4, 'n_units_l0': 35, 'n_units_l1': 22, 'n_units_l2': 84, 'n_units_l3': 70}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 76.88099670410156, MSE: 17197.841796875, R^2: 0.5239598263144623\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 8781.1885, AVGLoss: 20979.9230\n",
      "Epoch [2/10], Loss: 30988.6445, AVGLoss: 18648.0695\n",
      "Epoch [3/10], Loss: 12687.9443, AVGLoss: 18588.4023\n",
      "Epoch [4/10], Loss: 29159.6113, AVGLoss: 18168.2794\n",
      "Epoch [5/10], Loss: 11189.3848, AVGLoss: 18262.7123\n",
      "Epoch [6/10], Loss: 15608.4648, AVGLoss: 17902.1294\n",
      "Epoch [7/10], Loss: 12975.1357, AVGLoss: 17803.6187\n",
      "Epoch [8/10], Loss: 29275.1738, AVGLoss: 33959.2176\n",
      "Epoch [9/10], Loss: 28513.4102, AVGLoss: 34834.0372\n",
      "Epoch [10/10], Loss: 93970.1016, AVGLoss: 34835.7010\n",
      "Fold 1, MAE: 128.72218322753906, MSE: 39513.37890625, R^2: -0.016965364820932693\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 29968.1934, AVGLoss: 16526.7236\n",
      "Epoch [2/10], Loss: 62513.1523, AVGLoss: 17706.0883\n",
      "Epoch [3/10], Loss: 9822.3691, AVGLoss: 26269.0283\n",
      "Epoch [4/10], Loss: 10750.4287, AVGLoss: 27487.7900\n",
      "Epoch [5/10], Loss: 43213.9727, AVGLoss: 27347.6365\n",
      "Epoch [6/10], Loss: 21915.5020, AVGLoss: 27477.8999\n",
      "Epoch [7/10], Loss: 12471.7393, AVGLoss: 28456.0547\n",
      "Epoch [8/10], Loss: 15608.5713, AVGLoss: 28404.2893\n",
      "Epoch [9/10], Loss: 21530.7031, AVGLoss: 28747.3447\n",
      "Epoch [10/10], Loss: 12671.2949, AVGLoss: 29612.5584\n",
      "Fold 2, MAE: 145.75794982910156, MSE: 86957.0, R^2: -0.015590918455222535\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 55711.1211, AVGLoss: 33911.0087\n",
      "Epoch [2/10], Loss: 41405.3789, AVGLoss: 35040.0020\n",
      "Epoch [3/10], Loss: 12107.6201, AVGLoss: 35029.5689\n",
      "Epoch [4/10], Loss: 10596.5801, AVGLoss: 35027.2924\n",
      "Epoch [5/10], Loss: 90607.6484, AVGLoss: 35030.7410\n",
      "Epoch [6/10], Loss: 30634.9004, AVGLoss: 35027.6277\n",
      "Epoch [7/10], Loss: 37652.7656, AVGLoss: 35029.3175\n",
      "Epoch [8/10], Loss: 31839.6367, AVGLoss: 35026.7239\n",
      "Epoch [9/10], Loss: 77387.7812, AVGLoss: 35027.4409\n",
      "Epoch [10/10], Loss: 14437.0020, AVGLoss: 35023.7209\n",
      "Fold 3, MAE: 116.81593322753906, MSE: 37938.8828125, R^2: -0.0038858627363222986\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 14899.3447, AVGLoss: 21521.2907\n",
      "Epoch [2/10], Loss: 10591.2783, AVGLoss: 20015.8609\n",
      "Epoch [3/10], Loss: 22810.7031, AVGLoss: 19720.0759\n",
      "Epoch [4/10], Loss: 112933.3281, AVGLoss: 19743.8673\n",
      "Epoch [5/10], Loss: 16393.1680, AVGLoss: 19174.1866\n",
      "Epoch [6/10], Loss: 25676.8203, AVGLoss: 18959.7985\n",
      "Epoch [7/10], Loss: 16144.0762, AVGLoss: 18883.7931\n",
      "Epoch [8/10], Loss: 31832.0645, AVGLoss: 18578.4901\n",
      "Epoch [9/10], Loss: 7827.5273, AVGLoss: 19064.1318\n",
      "Epoch [10/10], Loss: 11501.7314, AVGLoss: 19073.7221\n",
      "Fold 4, MAE: 90.14663696289062, MSE: 21348.09375, R^2: 0.2022806609528044\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 145056.8906, AVGLoss: 20769.1427\n",
      "Epoch [2/10], Loss: 5522.1309, AVGLoss: 19719.8184\n",
      "Epoch [3/10], Loss: 3276.6067, AVGLoss: 19550.9776\n",
      "Epoch [4/10], Loss: 6687.4722, AVGLoss: 18646.2152\n",
      "Epoch [5/10], Loss: 21504.9258, AVGLoss: 18682.5270\n",
      "Epoch [6/10], Loss: 41465.6055, AVGLoss: 17893.4696\n",
      "Epoch [7/10], Loss: 25872.1855, AVGLoss: 18105.9069\n",
      "Epoch [8/10], Loss: 31997.5547, AVGLoss: 17683.0319\n",
      "Epoch [9/10], Loss: 6796.1060, AVGLoss: 17564.8965\n",
      "Epoch [10/10], Loss: 4765.1826, AVGLoss: 17443.5783\n",
      "Fold 5, MAE: 92.00873565673828, MSE: 28692.841796875, R^2: 0.37911264804862954\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 18625.0215, AVGLoss: 23040.3545\n",
      "Epoch [2/10], Loss: 18210.9941, AVGLoss: 20852.6086\n",
      "Epoch [3/10], Loss: 18658.1797, AVGLoss: 19373.4685\n",
      "Epoch [4/10], Loss: 9158.5039, AVGLoss: 18933.2670\n",
      "Epoch [5/10], Loss: 11708.1611, AVGLoss: 18707.3711\n",
      "Epoch [6/10], Loss: 12073.0088, AVGLoss: 18906.8331\n",
      "Epoch [7/10], Loss: 23322.6152, AVGLoss: 34241.0945\n",
      "Epoch [8/10], Loss: 23213.5918, AVGLoss: 37618.5956\n",
      "Epoch [9/10], Loss: 30139.7031, AVGLoss: 37613.2266\n",
      "Epoch [10/10], Loss: 19371.7227, AVGLoss: 37613.5754\n",
      "Fold 6, MAE: 92.66097259521484, MSE: 13837.05078125, R^2: -0.08448990365525333\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 13081.4922, AVGLoss: 23120.1006\n",
      "Epoch [2/10], Loss: 73182.2031, AVGLoss: 37471.2058\n",
      "Epoch [3/10], Loss: 29179.6895, AVGLoss: 37465.9925\n",
      "Epoch [4/10], Loss: 103523.5625, AVGLoss: 37457.5636\n",
      "Epoch [5/10], Loss: 51893.7734, AVGLoss: 37456.5606\n",
      "Epoch [6/10], Loss: 37511.7070, AVGLoss: 37456.2495\n",
      "Epoch [7/10], Loss: 40831.9102, AVGLoss: 37455.5140\n",
      "Epoch [8/10], Loss: 25045.2324, AVGLoss: 37454.4439\n",
      "Epoch [9/10], Loss: 30559.7773, AVGLoss: 37456.3020\n",
      "Epoch [10/10], Loss: 24448.0156, AVGLoss: 37454.6422\n",
      "Fold 7, MAE: 96.10000610351562, MSE: 16070.3427734375, R^2: -0.018177915483824414\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 29291.7090, AVGLoss: 22355.8575\n",
      "Epoch [2/10], Loss: 5655.1216, AVGLoss: 21446.4388\n",
      "Epoch [3/10], Loss: 30871.2676, AVGLoss: 20276.6316\n",
      "Epoch [4/10], Loss: 11636.7188, AVGLoss: 19912.3996\n",
      "Epoch [5/10], Loss: 9946.3193, AVGLoss: 19898.5278\n",
      "Epoch [6/10], Loss: 11354.3896, AVGLoss: 19755.0750\n",
      "Epoch [7/10], Loss: 4277.7456, AVGLoss: 19211.2158\n",
      "Epoch [8/10], Loss: 20320.1953, AVGLoss: 19309.6279\n",
      "Epoch [9/10], Loss: 21197.6484, AVGLoss: 19061.9756\n",
      "Epoch [10/10], Loss: 20132.5605, AVGLoss: 19192.3918\n",
      "Fold 8, MAE: 73.4899673461914, MSE: 10694.6923828125, R^2: 0.4557418832343352\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 7314.7480, AVGLoss: 30697.4140\n",
      "Epoch [2/10], Loss: 59504.3594, AVGLoss: 35919.4171\n",
      "Epoch [3/10], Loss: 207689.3125, AVGLoss: 35922.5363\n",
      "Epoch [4/10], Loss: 12696.5566, AVGLoss: 35904.6422\n",
      "Epoch [5/10], Loss: 10846.4482, AVGLoss: 35904.6710\n",
      "Epoch [6/10], Loss: 21933.5234, AVGLoss: 35903.3995\n",
      "Epoch [7/10], Loss: 10002.3477, AVGLoss: 35902.1906\n",
      "Epoch [8/10], Loss: 15463.7676, AVGLoss: 35902.4593\n",
      "Epoch [9/10], Loss: 54367.6719, AVGLoss: 35902.4068\n",
      "Epoch [10/10], Loss: 8759.3701, AVGLoss: 35901.1107\n",
      "Fold 9, MAE: 123.62537384033203, MSE: 29909.9296875, R^2: -0.019972989386345175\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 18701.5137, AVGLoss: 22176.6775\n",
      "Epoch [2/10], Loss: 107609.4297, AVGLoss: 19382.3817\n",
      "Epoch [3/10], Loss: 10370.8887, AVGLoss: 19094.0879\n",
      "Epoch [4/10], Loss: 8584.5918, AVGLoss: 18929.5497\n",
      "Epoch [5/10], Loss: 11119.7158, AVGLoss: 18787.0750\n",
      "Epoch [6/10], Loss: 13475.2666, AVGLoss: 18643.0877\n",
      "Epoch [7/10], Loss: 16361.4697, AVGLoss: 18457.2941\n",
      "Epoch [8/10], Loss: 14349.7422, AVGLoss: 18301.5204\n",
      "Epoch [9/10], Loss: 19681.4492, AVGLoss: 18281.2642\n",
      "Epoch [10/10], Loss: 32256.3184, AVGLoss: 18354.7651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 09:25:12,333] Trial 15 finished with value: 0.14050917867313523 and parameters: {'lr': 0.0835700603259095, 'num_layers': 4, 'n_units_l0': 16, 'n_units_l1': 18, 'n_units_l2': 41, 'n_units_l3': 77}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 83.81629943847656, MSE: 17086.578125, R^2: 0.5270395490334836\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 25490.9238, AVGLoss: 15046.4187\n",
      "Epoch [2/10], Loss: 7820.1079, AVGLoss: 11687.6580\n",
      "Epoch [3/10], Loss: 7721.8730, AVGLoss: 10365.6474\n",
      "Epoch [4/10], Loss: 3918.8452, AVGLoss: 9489.3248\n",
      "Epoch [5/10], Loss: 5432.6982, AVGLoss: 8695.4948\n",
      "Epoch [6/10], Loss: 10396.9512, AVGLoss: 8061.9746\n",
      "Epoch [7/10], Loss: 6150.2744, AVGLoss: 7572.5723\n",
      "Epoch [8/10], Loss: 5898.8354, AVGLoss: 7205.2569\n",
      "Epoch [9/10], Loss: 3961.7375, AVGLoss: 6802.0006\n",
      "Epoch [10/10], Loss: 3898.9939, AVGLoss: 6440.7253\n",
      "Fold 1, MAE: 125.96882629394531, MSE: 31105.275390625, R^2: 0.19943616254024377\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 5804.6592, AVGLoss: 14564.6392\n",
      "Epoch [2/10], Loss: 13745.3691, AVGLoss: 12533.3283\n",
      "Epoch [3/10], Loss: 5524.7354, AVGLoss: 11616.3690\n",
      "Epoch [4/10], Loss: 3132.1406, AVGLoss: 10701.1467\n",
      "Epoch [5/10], Loss: 3155.7485, AVGLoss: 9497.5611\n",
      "Epoch [6/10], Loss: 5483.4307, AVGLoss: 8409.2158\n",
      "Epoch [7/10], Loss: 4717.2964, AVGLoss: 7445.0649\n",
      "Epoch [8/10], Loss: 7180.7412, AVGLoss: 6677.2213\n",
      "Epoch [9/10], Loss: 10929.2051, AVGLoss: 6148.3149\n",
      "Epoch [10/10], Loss: 4117.7441, AVGLoss: 5654.6286\n",
      "Fold 2, MAE: 116.83621978759766, MSE: 74125.078125, R^2: 0.1342759644634237\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 7769.3667, AVGLoss: 14779.7058\n",
      "Epoch [2/10], Loss: 3516.1062, AVGLoss: 11637.3115\n",
      "Epoch [3/10], Loss: 7163.5117, AVGLoss: 10215.0638\n",
      "Epoch [4/10], Loss: 5162.1616, AVGLoss: 8635.7612\n",
      "Epoch [5/10], Loss: 21212.8145, AVGLoss: 8079.2393\n",
      "Epoch [6/10], Loss: 9828.0137, AVGLoss: 7078.2992\n",
      "Epoch [7/10], Loss: 8518.8242, AVGLoss: 7184.2903\n",
      "Epoch [8/10], Loss: 7863.0918, AVGLoss: 5689.9644\n",
      "Epoch [9/10], Loss: 9011.8125, AVGLoss: 5179.6364\n",
      "Epoch [10/10], Loss: 1835.7114, AVGLoss: 4786.4208\n",
      "Fold 3, MAE: 112.92559814453125, MSE: 45732.1875, R^2: -0.21010150108980996\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 7500.5522, AVGLoss: 15307.7253\n",
      "Epoch [2/10], Loss: 25938.0820, AVGLoss: 12223.2980\n",
      "Epoch [3/10], Loss: 5074.2617, AVGLoss: 11247.3370\n",
      "Epoch [4/10], Loss: 6386.9443, AVGLoss: 10446.5223\n",
      "Epoch [5/10], Loss: 17850.6855, AVGLoss: 9624.4342\n",
      "Epoch [6/10], Loss: 12092.9893, AVGLoss: 9035.9714\n",
      "Epoch [7/10], Loss: 9045.7773, AVGLoss: 8266.4446\n",
      "Epoch [8/10], Loss: 13085.2090, AVGLoss: 7763.9852\n",
      "Epoch [9/10], Loss: 2528.5376, AVGLoss: 6990.1733\n",
      "Epoch [10/10], Loss: 10429.9932, AVGLoss: 6451.6153\n",
      "Fold 4, MAE: 75.6457290649414, MSE: 15419.71484375, R^2: 0.42380780655547334\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 13621.2891, AVGLoss: 14165.7314\n",
      "Epoch [2/10], Loss: 24808.0586, AVGLoss: 10678.3979\n",
      "Epoch [3/10], Loss: 8210.5928, AVGLoss: 9160.1582\n",
      "Epoch [4/10], Loss: 19868.1504, AVGLoss: 7939.6227\n",
      "Epoch [5/10], Loss: 1827.2349, AVGLoss: 7280.6164\n",
      "Epoch [6/10], Loss: 1967.8755, AVGLoss: 6678.3852\n",
      "Epoch [7/10], Loss: 3031.8589, AVGLoss: 6204.5035\n",
      "Epoch [8/10], Loss: 11870.6670, AVGLoss: 5663.9507\n",
      "Epoch [9/10], Loss: 7378.6826, AVGLoss: 5296.0991\n",
      "Epoch [10/10], Loss: 2762.9451, AVGLoss: 4961.7238\n",
      "Fold 5, MAE: 91.94806671142578, MSE: 28840.693359375, R^2: 0.37591327946894515\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 6915.2651, AVGLoss: 16700.4443\n",
      "Epoch [2/10], Loss: 6152.7949, AVGLoss: 13268.9483\n",
      "Epoch [3/10], Loss: 1531.0076, AVGLoss: 11206.3427\n",
      "Epoch [4/10], Loss: 5813.4810, AVGLoss: 9605.8010\n",
      "Epoch [5/10], Loss: 35043.0000, AVGLoss: 8653.0404\n",
      "Epoch [6/10], Loss: 5904.4824, AVGLoss: 7868.5590\n",
      "Epoch [7/10], Loss: 2006.8079, AVGLoss: 7407.3462\n",
      "Epoch [8/10], Loss: 11880.7217, AVGLoss: 7881.1815\n",
      "Epoch [9/10], Loss: 7239.6987, AVGLoss: 7147.5250\n",
      "Epoch [10/10], Loss: 9229.4824, AVGLoss: 6352.6300\n",
      "Fold 6, MAE: 54.61956787109375, MSE: 7785.41796875, R^2: 0.3898117176497642\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 72366.1094, AVGLoss: 16284.6626\n",
      "Epoch [2/10], Loss: 5742.9082, AVGLoss: 13028.1514\n",
      "Epoch [3/10], Loss: 24709.8301, AVGLoss: 10534.1256\n",
      "Epoch [4/10], Loss: 5875.0068, AVGLoss: 8820.5737\n",
      "Epoch [5/10], Loss: 7439.1499, AVGLoss: 8002.3639\n",
      "Epoch [6/10], Loss: 4842.6763, AVGLoss: 7237.2837\n",
      "Epoch [7/10], Loss: 4781.5361, AVGLoss: 6592.0981\n",
      "Epoch [8/10], Loss: 2081.4746, AVGLoss: 6015.8250\n",
      "Epoch [9/10], Loss: 7514.3604, AVGLoss: 5552.3955\n",
      "Epoch [10/10], Loss: 7848.1685, AVGLoss: 5132.8013\n",
      "Fold 7, MAE: 89.11581420898438, MSE: 22794.373046875, R^2: -0.44419620894437606\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 16841.8574, AVGLoss: 16256.5432\n",
      "Epoch [2/10], Loss: 7657.8672, AVGLoss: 13429.3839\n",
      "Epoch [3/10], Loss: 2477.0015, AVGLoss: 12416.1661\n",
      "Epoch [4/10], Loss: 41437.3516, AVGLoss: 11388.0652\n",
      "Epoch [5/10], Loss: 12140.3281, AVGLoss: 10505.7118\n",
      "Epoch [6/10], Loss: 4881.1470, AVGLoss: 9113.2192\n",
      "Epoch [7/10], Loss: 4716.6021, AVGLoss: 8109.0859\n",
      "Epoch [8/10], Loss: 10903.8027, AVGLoss: 7667.3684\n",
      "Epoch [9/10], Loss: 7023.1030, AVGLoss: 6860.3373\n",
      "Epoch [10/10], Loss: 3109.4421, AVGLoss: 6421.4532\n",
      "Fold 8, MAE: 84.86298370361328, MSE: 19530.966796875, R^2: 0.006059597394392102\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 6874.9121, AVGLoss: 15672.2466\n",
      "Epoch [2/10], Loss: 2562.2986, AVGLoss: 12369.0700\n",
      "Epoch [3/10], Loss: 21185.7070, AVGLoss: 11187.6467\n",
      "Epoch [4/10], Loss: 4681.2666, AVGLoss: 10589.9539\n",
      "Epoch [5/10], Loss: 14683.8057, AVGLoss: 9447.0466\n",
      "Epoch [6/10], Loss: 18555.7480, AVGLoss: 9531.4064\n",
      "Epoch [7/10], Loss: 16385.7930, AVGLoss: 9123.9897\n",
      "Epoch [8/10], Loss: 2918.0537, AVGLoss: 7839.2289\n",
      "Epoch [9/10], Loss: 9343.9785, AVGLoss: 6887.3598\n",
      "Epoch [10/10], Loss: 2739.2617, AVGLoss: 6153.6170\n",
      "Fold 9, MAE: 91.02320861816406, MSE: 20507.974609375, R^2: 0.3006475734714299\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 9375.3936, AVGLoss: 15679.5390\n",
      "Epoch [2/10], Loss: 4925.1699, AVGLoss: 11948.1924\n",
      "Epoch [3/10], Loss: 8771.0078, AVGLoss: 10391.9877\n",
      "Epoch [4/10], Loss: 6694.1719, AVGLoss: 9229.9300\n",
      "Epoch [5/10], Loss: 4861.9604, AVGLoss: 8465.2265\n",
      "Epoch [6/10], Loss: 7248.2129, AVGLoss: 7829.5223\n",
      "Epoch [7/10], Loss: 4061.0027, AVGLoss: 7229.4397\n",
      "Epoch [8/10], Loss: 6706.7510, AVGLoss: 6497.0157\n",
      "Epoch [9/10], Loss: 2698.2310, AVGLoss: 5982.1615\n",
      "Epoch [10/10], Loss: 21194.6055, AVGLoss: 6549.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 10:02:28,724] Trial 16 finished with value: 0.17023625344320217 and parameters: {'lr': 0.0025388202250515722, 'num_layers': 4, 'n_units_l0': 33, 'n_units_l1': 96, 'n_units_l2': 82, 'n_units_l3': 97}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 75.41324615478516, MSE: 17098.552734375, R^2: 0.5267081429225355\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 35297.6992, AVGLoss: 34182.4161\n",
      "Epoch [2/10], Loss: 27129.3555, AVGLoss: 27273.9203\n",
      "Epoch [3/10], Loss: 24625.1133, AVGLoss: 26641.1604\n",
      "Epoch [4/10], Loss: 9628.0488, AVGLoss: 26168.9261\n",
      "Epoch [5/10], Loss: 24163.8398, AVGLoss: 25688.2044\n",
      "Epoch [6/10], Loss: 14357.4502, AVGLoss: 25117.5211\n",
      "Epoch [7/10], Loss: 26099.2168, AVGLoss: 24418.7709\n",
      "Epoch [8/10], Loss: 18953.5000, AVGLoss: 23543.8009\n",
      "Epoch [9/10], Loss: 11146.0967, AVGLoss: 22446.7753\n",
      "Epoch [10/10], Loss: 10953.8076, AVGLoss: 21136.9281\n",
      "Fold 1, MAE: 91.80814361572266, MSE: 24086.978515625, R^2: 0.38006764966649564\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 6477.5996, AVGLoss: 29675.7062\n",
      "Epoch [2/10], Loss: 4251.4775, AVGLoss: 22457.4908\n",
      "Epoch [3/10], Loss: 53224.0977, AVGLoss: 21768.1585\n",
      "Epoch [4/10], Loss: 5222.7344, AVGLoss: 21223.4336\n",
      "Epoch [5/10], Loss: 10903.1211, AVGLoss: 20660.2979\n",
      "Epoch [6/10], Loss: 6480.8906, AVGLoss: 20036.7990\n",
      "Epoch [7/10], Loss: 6875.6094, AVGLoss: 19311.9383\n",
      "Epoch [8/10], Loss: 6384.9766, AVGLoss: 18473.0928\n",
      "Epoch [9/10], Loss: 15624.8955, AVGLoss: 17541.2363\n",
      "Epoch [10/10], Loss: 15164.3906, AVGLoss: 16624.8361\n",
      "Fold 2, MAE: 101.5218734741211, MSE: 55918.88671875, R^2: 0.3469102832655119\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 21556.5449, AVGLoss: 34369.4651\n",
      "Epoch [2/10], Loss: 19548.9668, AVGLoss: 27041.2376\n",
      "Epoch [3/10], Loss: 8164.9731, AVGLoss: 26621.1799\n",
      "Epoch [4/10], Loss: 4806.6938, AVGLoss: 26339.5289\n",
      "Epoch [5/10], Loss: 12631.2246, AVGLoss: 25957.1050\n",
      "Epoch [6/10], Loss: 14146.9814, AVGLoss: 25424.4792\n",
      "Epoch [7/10], Loss: 17706.1152, AVGLoss: 24611.9496\n",
      "Epoch [8/10], Loss: 117410.8750, AVGLoss: 23286.1711\n",
      "Epoch [9/10], Loss: 128830.3125, AVGLoss: 21595.0357\n",
      "Epoch [10/10], Loss: 8506.0742, AVGLoss: 19910.5218\n",
      "Fold 3, MAE: 86.22211456298828, MSE: 24161.294921875, R^2: 0.3606774795490011\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 65280.2461, AVGLoss: 36201.5560\n",
      "Epoch [2/10], Loss: 12774.1777, AVGLoss: 28417.9360\n",
      "Epoch [3/10], Loss: 21973.8809, AVGLoss: 27678.4292\n",
      "Epoch [4/10], Loss: 28084.9941, AVGLoss: 27004.7159\n",
      "Epoch [5/10], Loss: 6188.1318, AVGLoss: 26194.7650\n",
      "Epoch [6/10], Loss: 13626.4678, AVGLoss: 25199.4088\n",
      "Epoch [7/10], Loss: 27791.8750, AVGLoss: 23934.3853\n",
      "Epoch [8/10], Loss: 9841.6016, AVGLoss: 22395.3973\n",
      "Epoch [9/10], Loss: 10661.4355, AVGLoss: 20784.4025\n",
      "Epoch [10/10], Loss: 6721.9023, AVGLoss: 19469.2928\n",
      "Fold 4, MAE: 80.82083129882812, MSE: 16357.03125, R^2: 0.388782875772965\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 6702.2300, AVGLoss: 33595.4350\n",
      "Epoch [2/10], Loss: 40464.4531, AVGLoss: 26312.4282\n",
      "Epoch [3/10], Loss: 6835.1357, AVGLoss: 25617.1399\n",
      "Epoch [4/10], Loss: 10337.8555, AVGLoss: 25134.2403\n",
      "Epoch [5/10], Loss: 109537.0781, AVGLoss: 24694.6189\n",
      "Epoch [6/10], Loss: 12718.7744, AVGLoss: 24189.0859\n",
      "Epoch [7/10], Loss: 22888.9297, AVGLoss: 23587.5868\n",
      "Epoch [8/10], Loss: 8808.4932, AVGLoss: 22835.6293\n",
      "Epoch [9/10], Loss: 67050.3125, AVGLoss: 21899.5607\n",
      "Epoch [10/10], Loss: 9727.3174, AVGLoss: 20727.4885\n",
      "Fold 5, MAE: 93.64094543457031, MSE: 32441.990234375, R^2: 0.29798448369668806\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 18687.5215, AVGLoss: 37313.8331\n",
      "Epoch [2/10], Loss: 21638.1680, AVGLoss: 29101.5069\n",
      "Epoch [3/10], Loss: 89483.1016, AVGLoss: 28503.5076\n",
      "Epoch [4/10], Loss: 10775.4746, AVGLoss: 28048.2867\n",
      "Epoch [5/10], Loss: 18234.6055, AVGLoss: 27557.5783\n",
      "Epoch [6/10], Loss: 18451.4609, AVGLoss: 26947.7475\n",
      "Epoch [7/10], Loss: 14902.0391, AVGLoss: 26172.9701\n",
      "Epoch [8/10], Loss: 10689.2422, AVGLoss: 25193.9497\n",
      "Epoch [9/10], Loss: 21277.5703, AVGLoss: 23982.1562\n",
      "Epoch [10/10], Loss: 7732.8945, AVGLoss: 22619.0321\n",
      "Fold 6, MAE: 68.40811157226562, MSE: 9097.5732421875, R^2: 0.28697049251044404\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 8836.6963, AVGLoss: 36771.5140\n",
      "Epoch [2/10], Loss: 15994.0664, AVGLoss: 29282.2379\n",
      "Epoch [3/10], Loss: 11696.6279, AVGLoss: 28689.8319\n",
      "Epoch [4/10], Loss: 37975.2188, AVGLoss: 28149.4212\n",
      "Epoch [5/10], Loss: 48993.7227, AVGLoss: 27504.9519\n",
      "Epoch [6/10], Loss: 19934.3535, AVGLoss: 26664.7278\n",
      "Epoch [7/10], Loss: 50606.5469, AVGLoss: 25598.1609\n",
      "Epoch [8/10], Loss: 16347.2490, AVGLoss: 24274.3374\n",
      "Epoch [9/10], Loss: 9425.2920, AVGLoss: 22760.2391\n",
      "Epoch [10/10], Loss: 19783.0996, AVGLoss: 21271.0769\n",
      "Fold 7, MAE: 73.92948150634766, MSE: 11301.388671875, R^2: 0.2839713209342519\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 14227.1338, AVGLoss: 37410.3656\n",
      "Epoch [2/10], Loss: 135788.0625, AVGLoss: 29131.7456\n",
      "Epoch [3/10], Loss: 7236.9585, AVGLoss: 28358.8469\n",
      "Epoch [4/10], Loss: 60178.7695, AVGLoss: 27766.7263\n",
      "Epoch [5/10], Loss: 17473.3613, AVGLoss: 27177.3064\n",
      "Epoch [6/10], Loss: 11753.0381, AVGLoss: 26503.1415\n",
      "Epoch [7/10], Loss: 34272.4492, AVGLoss: 25655.7328\n",
      "Epoch [8/10], Loss: 13329.2725, AVGLoss: 24558.2931\n",
      "Epoch [9/10], Loss: 12126.5625, AVGLoss: 23163.1560\n",
      "Epoch [10/10], Loss: 12122.7471, AVGLoss: 21540.8774\n",
      "Fold 8, MAE: 70.41084289550781, MSE: 11049.1005859375, R^2: 0.4377059618575674\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 28771.5918, AVGLoss: 36221.8294\n",
      "Epoch [2/10], Loss: 13979.1992, AVGLoss: 28889.2624\n",
      "Epoch [3/10], Loss: 48355.1406, AVGLoss: 28240.9936\n",
      "Epoch [4/10], Loss: 17365.9336, AVGLoss: 27787.4614\n",
      "Epoch [5/10], Loss: 7703.6094, AVGLoss: 27343.5425\n",
      "Epoch [6/10], Loss: 4989.7725, AVGLoss: 26843.4571\n",
      "Epoch [7/10], Loss: 38740.6602, AVGLoss: 26242.8793\n",
      "Epoch [8/10], Loss: 16115.2920, AVGLoss: 25506.8685\n",
      "Epoch [9/10], Loss: 2659.4160, AVGLoss: 24606.4871\n",
      "Epoch [10/10], Loss: 13812.7832, AVGLoss: 23530.7715\n",
      "Fold 9, MAE: 81.2339096069336, MSE: 16494.060546875, R^2: 0.4375279939027842\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 16374.4912, AVGLoss: 34946.1139\n",
      "Epoch [2/10], Loss: 105679.8672, AVGLoss: 27875.8804\n",
      "Epoch [3/10], Loss: 9343.7383, AVGLoss: 27294.8028\n",
      "Epoch [4/10], Loss: 54827.2344, AVGLoss: 26876.4284\n",
      "Epoch [5/10], Loss: 8788.2070, AVGLoss: 26464.4727\n",
      "Epoch [6/10], Loss: 11284.0215, AVGLoss: 26013.5994\n",
      "Epoch [7/10], Loss: 23212.0391, AVGLoss: 25492.0523\n",
      "Epoch [8/10], Loss: 29817.9160, AVGLoss: 24872.5329\n",
      "Epoch [9/10], Loss: 25550.3125, AVGLoss: 24141.5898\n",
      "Epoch [10/10], Loss: 11688.8623, AVGLoss: 23294.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 10:33:04,728] Trial 17 finished with value: 0.36393979205017196 and parameters: {'lr': 2.395812659346019e-05, 'num_layers': 3, 'n_units_l0': 88, 'n_units_l1': 38, 'n_units_l2': 49}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 85.07441711425781, MSE: 20996.9609375, R^2: 0.4187993793460101\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 6719.0874, AVGLoss: 24853.4918\n",
      "Epoch [2/10], Loss: 15049.6904, AVGLoss: 17073.2285\n",
      "Epoch [3/10], Loss: 6847.3813, AVGLoss: 15551.2577\n",
      "Epoch [4/10], Loss: 8038.9326, AVGLoss: 14518.8106\n",
      "Epoch [5/10], Loss: 13444.7256, AVGLoss: 13637.3295\n",
      "Epoch [6/10], Loss: 10387.2129, AVGLoss: 13086.6702\n",
      "Epoch [7/10], Loss: 11267.7295, AVGLoss: 12770.6889\n",
      "Epoch [8/10], Loss: 5512.9141, AVGLoss: 12516.9936\n",
      "Epoch [9/10], Loss: 5782.0864, AVGLoss: 12303.0036\n",
      "Epoch [10/10], Loss: 14047.4746, AVGLoss: 12116.0764\n",
      "Fold 1, MAE: 89.5791015625, MSE: 22596.91015625, R^2: 0.4184179660647551\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 7893.4766, AVGLoss: 21080.0434\n",
      "Epoch [2/10], Loss: 4602.9116, AVGLoss: 15377.6700\n",
      "Epoch [3/10], Loss: 4645.2446, AVGLoss: 14362.8110\n",
      "Epoch [4/10], Loss: 20325.5332, AVGLoss: 14024.5657\n",
      "Epoch [5/10], Loss: 9864.3730, AVGLoss: 13756.2949\n",
      "Epoch [6/10], Loss: 11865.1621, AVGLoss: 13566.9862\n",
      "Epoch [7/10], Loss: 15149.9902, AVGLoss: 13409.7375\n",
      "Epoch [8/10], Loss: 8068.1641, AVGLoss: 13268.5612\n",
      "Epoch [9/10], Loss: 10887.2812, AVGLoss: 13130.1656\n",
      "Epoch [10/10], Loss: 10670.2002, AVGLoss: 12991.8237\n",
      "Fold 2, MAE: 91.42207336425781, MSE: 44159.94140625, R^2: 0.4842457340681485\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 58180.0664, AVGLoss: 25730.5292\n",
      "Epoch [2/10], Loss: 6617.9355, AVGLoss: 18278.8883\n",
      "Epoch [3/10], Loss: 35723.8516, AVGLoss: 16736.2712\n",
      "Epoch [4/10], Loss: 39107.6445, AVGLoss: 15848.1456\n",
      "Epoch [5/10], Loss: 15580.5234, AVGLoss: 14926.0028\n",
      "Epoch [6/10], Loss: 16126.7480, AVGLoss: 14020.9782\n",
      "Epoch [7/10], Loss: 12641.1602, AVGLoss: 13312.0578\n",
      "Epoch [8/10], Loss: 2492.0256, AVGLoss: 12828.9330\n",
      "Epoch [9/10], Loss: 8172.1094, AVGLoss: 12468.1560\n",
      "Epoch [10/10], Loss: 18267.5977, AVGLoss: 12199.0645\n",
      "Fold 3, MAE: 91.61481475830078, MSE: 28510.40234375, R^2: 0.2455975705750102\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 8999.9678, AVGLoss: 25604.9923\n",
      "Epoch [2/10], Loss: 13179.1709, AVGLoss: 17456.8541\n",
      "Epoch [3/10], Loss: 9006.2979, AVGLoss: 16293.0243\n",
      "Epoch [4/10], Loss: 8336.6133, AVGLoss: 15464.7253\n",
      "Epoch [5/10], Loss: 14383.8652, AVGLoss: 14591.8739\n",
      "Epoch [6/10], Loss: 10208.5801, AVGLoss: 13639.8028\n",
      "Epoch [7/10], Loss: 23060.5273, AVGLoss: 13051.2750\n",
      "Epoch [8/10], Loss: 12722.3369, AVGLoss: 12655.9057\n",
      "Epoch [9/10], Loss: 10409.7578, AVGLoss: 12383.0147\n",
      "Epoch [10/10], Loss: 12835.1689, AVGLoss: 12151.2549\n",
      "Fold 4, MAE: 74.24468231201172, MSE: 15149.3076171875, R^2: 0.43391218712672375\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 44172.8945, AVGLoss: 25184.3399\n",
      "Epoch [2/10], Loss: 15681.1279, AVGLoss: 17603.9929\n",
      "Epoch [3/10], Loss: 6052.2339, AVGLoss: 15678.9816\n",
      "Epoch [4/10], Loss: 10990.2363, AVGLoss: 14921.0517\n",
      "Epoch [5/10], Loss: 10356.2822, AVGLoss: 14076.9503\n",
      "Epoch [6/10], Loss: 7827.9785, AVGLoss: 13225.2557\n",
      "Epoch [7/10], Loss: 6782.8198, AVGLoss: 12591.2405\n",
      "Epoch [8/10], Loss: 2699.5413, AVGLoss: 12105.3760\n",
      "Epoch [9/10], Loss: 3991.9009, AVGLoss: 11741.8670\n",
      "Epoch [10/10], Loss: 36245.1680, AVGLoss: 11494.3556\n",
      "Fold 5, MAE: 85.77972412109375, MSE: 26998.36328125, R^2: 0.41577965645985226\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 10147.1162, AVGLoss: 27848.5257\n",
      "Epoch [2/10], Loss: 4857.6387, AVGLoss: 20182.1498\n",
      "Epoch [3/10], Loss: 19283.5430, AVGLoss: 18119.7958\n",
      "Epoch [4/10], Loss: 19332.1797, AVGLoss: 17265.1338\n",
      "Epoch [5/10], Loss: 15496.3457, AVGLoss: 16482.1597\n",
      "Epoch [6/10], Loss: 16316.0645, AVGLoss: 15720.1861\n",
      "Epoch [7/10], Loss: 6652.7881, AVGLoss: 15087.7249\n",
      "Epoch [8/10], Loss: 17789.9453, AVGLoss: 14619.3157\n",
      "Epoch [9/10], Loss: 12865.8340, AVGLoss: 14245.3074\n",
      "Epoch [10/10], Loss: 6069.3691, AVGLoss: 13958.1732\n",
      "Fold 6, MAE: 56.92448043823242, MSE: 6930.42724609375, R^2: 0.4568222427789955\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 8868.9980, AVGLoss: 26638.0963\n",
      "Epoch [2/10], Loss: 8747.2402, AVGLoss: 18509.5811\n",
      "Epoch [3/10], Loss: 10898.7324, AVGLoss: 17349.1528\n",
      "Epoch [4/10], Loss: 12738.9209, AVGLoss: 16775.4478\n",
      "Epoch [5/10], Loss: 19408.3516, AVGLoss: 16357.0835\n",
      "Epoch [6/10], Loss: 6028.8184, AVGLoss: 15959.6429\n",
      "Epoch [7/10], Loss: 5024.2046, AVGLoss: 15543.6678\n",
      "Epoch [8/10], Loss: 8786.5430, AVGLoss: 15140.7331\n",
      "Epoch [9/10], Loss: 12902.8652, AVGLoss: 14736.1233\n",
      "Epoch [10/10], Loss: 7146.0439, AVGLoss: 14363.7720\n",
      "Fold 7, MAE: 68.21781158447266, MSE: 11818.908203125, R^2: 0.2511825320133726\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 36584.0430, AVGLoss: 27864.2470\n",
      "Epoch [2/10], Loss: 5743.2437, AVGLoss: 19976.6260\n",
      "Epoch [3/10], Loss: 31827.0078, AVGLoss: 17654.7443\n",
      "Epoch [4/10], Loss: 9402.5420, AVGLoss: 16897.7434\n",
      "Epoch [5/10], Loss: 14489.2178, AVGLoss: 16315.5314\n",
      "Epoch [6/10], Loss: 16738.0273, AVGLoss: 15828.0759\n",
      "Epoch [7/10], Loss: 4161.5659, AVGLoss: 15399.0257\n",
      "Epoch [8/10], Loss: 40991.3320, AVGLoss: 15045.3012\n",
      "Epoch [9/10], Loss: 18218.6816, AVGLoss: 14749.8785\n",
      "Epoch [10/10], Loss: 7524.0503, AVGLoss: 14505.5496\n",
      "Fold 8, MAE: 67.68345642089844, MSE: 11038.423828125, R^2: 0.43824925912809964\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 15946.8613, AVGLoss: 26736.7962\n",
      "Epoch [2/10], Loss: 14177.0645, AVGLoss: 18124.4857\n",
      "Epoch [3/10], Loss: 14871.2393, AVGLoss: 16546.2437\n",
      "Epoch [4/10], Loss: 5825.4126, AVGLoss: 15536.1271\n",
      "Epoch [5/10], Loss: 7258.8799, AVGLoss: 14727.5819\n",
      "Epoch [6/10], Loss: 8927.1387, AVGLoss: 14186.1881\n",
      "Epoch [7/10], Loss: 12907.2451, AVGLoss: 13833.5480\n",
      "Epoch [8/10], Loss: 3647.1763, AVGLoss: 13601.3164\n",
      "Epoch [9/10], Loss: 10599.3818, AVGLoss: 13398.3966\n",
      "Epoch [10/10], Loss: 24437.3379, AVGLoss: 13220.0459\n",
      "Fold 9, MAE: 88.54138946533203, MSE: 22032.923828125, R^2: 0.248644604826743\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 39623.6562, AVGLoss: 25320.6879\n",
      "Epoch [2/10], Loss: 8305.3271, AVGLoss: 18219.5057\n",
      "Epoch [3/10], Loss: 14200.1396, AVGLoss: 16907.0625\n",
      "Epoch [4/10], Loss: 41451.1367, AVGLoss: 15925.0318\n",
      "Epoch [5/10], Loss: 12381.4033, AVGLoss: 15081.2869\n",
      "Epoch [6/10], Loss: 13751.9756, AVGLoss: 14472.4665\n",
      "Epoch [7/10], Loss: 8970.5879, AVGLoss: 13988.5897\n",
      "Epoch [8/10], Loss: 33807.1836, AVGLoss: 13648.1424\n",
      "Epoch [9/10], Loss: 23692.2832, AVGLoss: 13395.0323\n",
      "Epoch [10/10], Loss: 13161.7158, AVGLoss: 13173.9834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 11:02:57,872] Trial 18 finished with value: 0.3961858250176387 and parameters: {'lr': 0.0001938678658623871, 'num_layers': 3, 'n_units_l0': 49, 'n_units_l1': 71, 'n_units_l2': 84}. Best is trial 7 with value: 0.40851867084895466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 70.13946533203125, MSE: 15570.447265625, R^2: 0.5690064971346865\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 14492.5908, AVGLoss: 33536.2618\n",
      "Epoch [2/10], Loss: 20185.9668, AVGLoss: 27069.2209\n",
      "Epoch [3/10], Loss: 18328.3945, AVGLoss: 26148.5010\n",
      "Epoch [4/10], Loss: 37580.7539, AVGLoss: 25218.1218\n",
      "Epoch [5/10], Loss: 76011.1484, AVGLoss: 24064.7903\n",
      "Epoch [6/10], Loss: 10697.8271, AVGLoss: 22374.7740\n",
      "Epoch [7/10], Loss: 7617.3833, AVGLoss: 20244.0908\n",
      "Epoch [8/10], Loss: 13709.4209, AVGLoss: 18609.3915\n",
      "Epoch [9/10], Loss: 7478.3594, AVGLoss: 17787.5950\n",
      "Epoch [10/10], Loss: 17865.7656, AVGLoss: 17352.5911\n",
      "Fold 1, MAE: 89.4544906616211, MSE: 21826.16796875, R^2: 0.4382547240297032\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 46670.4570, AVGLoss: 28358.8803\n",
      "Epoch [2/10], Loss: 27458.1387, AVGLoss: 22121.7286\n",
      "Epoch [3/10], Loss: 34564.3320, AVGLoss: 21303.0276\n",
      "Epoch [4/10], Loss: 14548.8936, AVGLoss: 20590.3903\n",
      "Epoch [5/10], Loss: 35232.5000, AVGLoss: 19806.7379\n",
      "Epoch [6/10], Loss: 14101.3779, AVGLoss: 18686.1061\n",
      "Epoch [7/10], Loss: 6025.2173, AVGLoss: 17233.8890\n",
      "Epoch [8/10], Loss: 11033.7500, AVGLoss: 16000.9458\n",
      "Epoch [9/10], Loss: 12494.8926, AVGLoss: 15332.9871\n",
      "Epoch [10/10], Loss: 14670.8984, AVGLoss: 14982.4771\n",
      "Fold 2, MAE: 96.21113586425781, MSE: 48570.0390625, R^2: 0.4327392510809358\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 6528.0996, AVGLoss: 32901.8261\n",
      "Epoch [2/10], Loss: 10318.0352, AVGLoss: 26423.5694\n",
      "Epoch [3/10], Loss: 18961.7832, AVGLoss: 25259.6485\n",
      "Epoch [4/10], Loss: 31706.4961, AVGLoss: 23832.0442\n",
      "Epoch [5/10], Loss: 30884.3203, AVGLoss: 21839.9968\n",
      "Epoch [6/10], Loss: 5677.9146, AVGLoss: 19713.1428\n",
      "Epoch [7/10], Loss: 8874.9961, AVGLoss: 18444.9683\n",
      "Epoch [8/10], Loss: 13903.4844, AVGLoss: 17867.6615\n",
      "Epoch [9/10], Loss: 6257.4844, AVGLoss: 17526.7718\n",
      "Epoch [10/10], Loss: 4993.2920, AVGLoss: 17280.9505\n",
      "Fold 3, MAE: 80.62256622314453, MSE: 21225.248046875, R^2: 0.4383670127885996\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 11543.6904, AVGLoss: 34739.5817\n",
      "Epoch [2/10], Loss: 13454.9053, AVGLoss: 27835.3028\n",
      "Epoch [3/10], Loss: 56981.3906, AVGLoss: 26778.7308\n",
      "Epoch [4/10], Loss: 18097.5664, AVGLoss: 25666.3415\n",
      "Epoch [5/10], Loss: 9917.6621, AVGLoss: 24264.1851\n",
      "Epoch [6/10], Loss: 13539.3779, AVGLoss: 22291.6637\n",
      "Epoch [7/10], Loss: 6177.2485, AVGLoss: 20119.1417\n",
      "Epoch [8/10], Loss: 9379.2588, AVGLoss: 18765.1180\n",
      "Epoch [9/10], Loss: 5995.0435, AVGLoss: 18103.7009\n",
      "Epoch [10/10], Loss: 26807.5469, AVGLoss: 17693.7617\n",
      "Fold 4, MAE: 81.32464599609375, MSE: 16907.490234375, R^2: 0.3682137900549919\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 8619.4590, AVGLoss: 32560.5616\n",
      "Epoch [2/10], Loss: 90991.9297, AVGLoss: 26000.9330\n",
      "Epoch [3/10], Loss: 9239.6006, AVGLoss: 25188.1242\n",
      "Epoch [4/10], Loss: 17408.2324, AVGLoss: 24374.8054\n",
      "Epoch [5/10], Loss: 20038.3262, AVGLoss: 23484.7302\n",
      "Epoch [6/10], Loss: 20723.2402, AVGLoss: 22384.7002\n",
      "Epoch [7/10], Loss: 4304.2285, AVGLoss: 20927.2690\n",
      "Epoch [8/10], Loss: 5713.3125, AVGLoss: 19199.3107\n",
      "Epoch [9/10], Loss: 7436.6543, AVGLoss: 17850.6088\n",
      "Epoch [10/10], Loss: 17707.3105, AVGLoss: 17186.9290\n",
      "Fold 5, MAE: 91.73335266113281, MSE: 29134.287109375, R^2: 0.3695601867703455\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 9891.7061, AVGLoss: 35729.1362\n",
      "Epoch [2/10], Loss: 11305.7744, AVGLoss: 28775.9698\n",
      "Epoch [3/10], Loss: 6925.9336, AVGLoss: 27852.4762\n",
      "Epoch [4/10], Loss: 15519.2041, AVGLoss: 26820.9597\n",
      "Epoch [5/10], Loss: 28434.2461, AVGLoss: 25479.8906\n",
      "Epoch [6/10], Loss: 5721.4214, AVGLoss: 23660.5745\n",
      "Epoch [7/10], Loss: 7406.1587, AVGLoss: 21655.8693\n",
      "Epoch [8/10], Loss: 15712.6982, AVGLoss: 20186.6594\n",
      "Epoch [9/10], Loss: 13581.6689, AVGLoss: 19427.9510\n",
      "Epoch [10/10], Loss: 3957.5183, AVGLoss: 19013.3079\n",
      "Fold 6, MAE: 54.81627655029297, MSE: 7150.94921875, R^2: 0.43953866634355787\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 24413.0137, AVGLoss: 35503.8147\n",
      "Epoch [2/10], Loss: 31621.3828, AVGLoss: 28950.9967\n",
      "Epoch [3/10], Loss: 15482.4346, AVGLoss: 28089.0801\n",
      "Epoch [4/10], Loss: 79064.4062, AVGLoss: 27203.1775\n",
      "Epoch [5/10], Loss: 8205.5752, AVGLoss: 26217.4866\n",
      "Epoch [6/10], Loss: 15872.7842, AVGLoss: 25019.5756\n",
      "Epoch [7/10], Loss: 11701.1162, AVGLoss: 23359.8263\n",
      "Epoch [8/10], Loss: 13914.0459, AVGLoss: 21307.7617\n",
      "Epoch [9/10], Loss: 9660.0332, AVGLoss: 19632.2991\n",
      "Epoch [10/10], Loss: 24934.8281, AVGLoss: 18684.3287\n",
      "Fold 7, MAE: 73.95429992675781, MSE: 12514.46875, R^2: 0.20711349252463207\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 6911.6040, AVGLoss: 34902.3544\n",
      "Epoch [2/10], Loss: 13469.3643, AVGLoss: 28455.3175\n",
      "Epoch [3/10], Loss: 17891.0371, AVGLoss: 27244.4043\n",
      "Epoch [4/10], Loss: 75094.0391, AVGLoss: 26047.3488\n",
      "Epoch [5/10], Loss: 18262.6387, AVGLoss: 24495.4537\n",
      "Epoch [6/10], Loss: 12678.8682, AVGLoss: 22233.1609\n",
      "Epoch [7/10], Loss: 9373.9600, AVGLoss: 20054.8949\n",
      "Epoch [8/10], Loss: 14278.7861, AVGLoss: 18867.8834\n",
      "Epoch [9/10], Loss: 9955.5059, AVGLoss: 18262.0051\n",
      "Epoch [10/10], Loss: 10521.5947, AVGLoss: 17881.1096\n",
      "Fold 8, MAE: 65.51881408691406, MSE: 10478.2646484375, R^2: 0.4667560199808761\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 5700.2075, AVGLoss: 34612.6093\n",
      "Epoch [2/10], Loss: 624745.2500, AVGLoss: 28650.3457\n",
      "Epoch [3/10], Loss: 14077.1055, AVGLoss: 27776.3702\n",
      "Epoch [4/10], Loss: 53078.8945, AVGLoss: 26646.0156\n",
      "Epoch [5/10], Loss: 13788.7109, AVGLoss: 25177.3378\n",
      "Epoch [6/10], Loss: 73142.8125, AVGLoss: 23256.6803\n",
      "Epoch [7/10], Loss: 11326.3193, AVGLoss: 21062.3466\n",
      "Epoch [8/10], Loss: 9115.1035, AVGLoss: 19475.5743\n",
      "Epoch [9/10], Loss: 75981.2734, AVGLoss: 18672.4053\n",
      "Epoch [10/10], Loss: 8631.8320, AVGLoss: 18209.1057\n",
      "Fold 9, MAE: 79.66256713867188, MSE: 16601.87109375, R^2: 0.43385152478895517\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 30326.5371, AVGLoss: 33863.7046\n",
      "Epoch [2/10], Loss: 15630.7480, AVGLoss: 27603.3965\n",
      "Epoch [3/10], Loss: 69478.3047, AVGLoss: 26932.4709\n",
      "Epoch [4/10], Loss: 14096.7578, AVGLoss: 26160.7358\n",
      "Epoch [5/10], Loss: 8737.9375, AVGLoss: 25127.1662\n",
      "Epoch [6/10], Loss: 17378.2344, AVGLoss: 23699.1032\n",
      "Epoch [7/10], Loss: 22626.5957, AVGLoss: 21731.0914\n",
      "Epoch [8/10], Loss: 15019.9160, AVGLoss: 19784.1260\n",
      "Epoch [9/10], Loss: 16981.4570, AVGLoss: 18727.6615\n",
      "Epoch [10/10], Loss: 14896.6211, AVGLoss: 18255.4919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 11:35:51,181] Trial 19 finished with value: 0.41561160115995077 and parameters: {'lr': 2.053456874735523e-05, 'num_layers': 4, 'n_units_l0': 32, 'n_units_l1': 99, 'n_units_l2': 43, 'n_units_l3': 60}. Best is trial 19 with value: 0.41561160115995077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 73.40399169921875, MSE: 15833.6376953125, R^2: 0.5617213432369101\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 24723.3105, AVGLoss: 24903.9844\n",
      "Epoch [2/10], Loss: 24251.4492, AVGLoss: 17717.2788\n",
      "Epoch [3/10], Loss: 9008.7764, AVGLoss: 16718.7704\n",
      "Epoch [4/10], Loss: 7178.8301, AVGLoss: 16024.8263\n",
      "Epoch [5/10], Loss: 5242.7188, AVGLoss: 15382.2716\n",
      "Epoch [6/10], Loss: 4647.8364, AVGLoss: 14922.7002\n",
      "Epoch [7/10], Loss: 36355.4375, AVGLoss: 14582.3933\n",
      "Epoch [8/10], Loss: 10421.2715, AVGLoss: 14309.8665\n",
      "Epoch [9/10], Loss: 10850.3955, AVGLoss: 14079.1455\n",
      "Epoch [10/10], Loss: 10313.9443, AVGLoss: 13878.6320\n",
      "Fold 1, MAE: 90.83367156982422, MSE: 24242.974609375, R^2: 0.37605278250681273\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 35144.3750, AVGLoss: 21046.6403\n",
      "Epoch [2/10], Loss: 7377.8667, AVGLoss: 15133.9995\n",
      "Epoch [3/10], Loss: 13099.0918, AVGLoss: 14255.6959\n",
      "Epoch [4/10], Loss: 15205.7529, AVGLoss: 13989.5784\n",
      "Epoch [5/10], Loss: 31332.1621, AVGLoss: 13819.4510\n",
      "Epoch [6/10], Loss: 25963.1562, AVGLoss: 13682.4541\n",
      "Epoch [7/10], Loss: 39228.4180, AVGLoss: 13574.4564\n",
      "Epoch [8/10], Loss: 137844.4375, AVGLoss: 13476.8601\n",
      "Epoch [9/10], Loss: 3826.5137, AVGLoss: 13375.8179\n",
      "Epoch [10/10], Loss: 37813.2305, AVGLoss: 13293.8087\n",
      "Fold 2, MAE: 96.93441009521484, MSE: 46805.91796875, R^2: 0.4533427597359596\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 11327.9746, AVGLoss: 24546.5712\n",
      "Epoch [2/10], Loss: 19263.0645, AVGLoss: 17925.7211\n",
      "Epoch [3/10], Loss: 15504.5293, AVGLoss: 16924.6149\n",
      "Epoch [4/10], Loss: 7422.2080, AVGLoss: 16196.5006\n",
      "Epoch [5/10], Loss: 3903.1042, AVGLoss: 15651.9749\n",
      "Epoch [6/10], Loss: 7787.8398, AVGLoss: 15219.0526\n",
      "Epoch [7/10], Loss: 18865.1035, AVGLoss: 14884.9486\n",
      "Epoch [8/10], Loss: 14554.7334, AVGLoss: 14635.0616\n",
      "Epoch [9/10], Loss: 130986.8359, AVGLoss: 14414.0371\n",
      "Epoch [10/10], Loss: 14707.5391, AVGLoss: 14201.8082\n",
      "Fold 3, MAE: 88.87151336669922, MSE: 23981.93359375, R^2: 0.36542352933268696\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 62197.9883, AVGLoss: 25976.3154\n",
      "Epoch [2/10], Loss: 6380.2349, AVGLoss: 18241.9413\n",
      "Epoch [3/10], Loss: 5973.8765, AVGLoss: 17242.9516\n",
      "Epoch [4/10], Loss: 12539.9238, AVGLoss: 16696.7607\n",
      "Epoch [5/10], Loss: 8494.6377, AVGLoss: 16209.8445\n",
      "Epoch [6/10], Loss: 8052.4639, AVGLoss: 15814.2014\n",
      "Epoch [7/10], Loss: 5461.2759, AVGLoss: 15524.4294\n",
      "Epoch [8/10], Loss: 15357.3135, AVGLoss: 15275.6490\n",
      "Epoch [9/10], Loss: 22035.2207, AVGLoss: 15043.3244\n",
      "Epoch [10/10], Loss: 22161.1562, AVGLoss: 14834.8353\n",
      "Fold 4, MAE: 76.78385925292969, MSE: 15710.9765625, R^2: 0.4129240376665151\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 3441.0349, AVGLoss: 24051.4907\n",
      "Epoch [2/10], Loss: 2885.7378, AVGLoss: 16990.1160\n",
      "Epoch [3/10], Loss: 3732.3467, AVGLoss: 16059.5750\n",
      "Epoch [4/10], Loss: 1763.1654, AVGLoss: 15554.7189\n",
      "Epoch [5/10], Loss: 26797.8555, AVGLoss: 15136.4890\n",
      "Epoch [6/10], Loss: 22125.0781, AVGLoss: 14801.0896\n",
      "Epoch [7/10], Loss: 4720.6675, AVGLoss: 14525.9648\n",
      "Epoch [8/10], Loss: 17614.9570, AVGLoss: 14287.7262\n",
      "Epoch [9/10], Loss: 13174.6455, AVGLoss: 14070.3785\n",
      "Epoch [10/10], Loss: 3293.8384, AVGLoss: 13874.8787\n",
      "Fold 5, MAE: 87.07866668701172, MSE: 26402.609375, R^2: 0.428671231645938\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 6562.1787, AVGLoss: 26676.9802\n",
      "Epoch [2/10], Loss: 8072.4238, AVGLoss: 19182.1071\n",
      "Epoch [3/10], Loss: 6138.0840, AVGLoss: 18154.6203\n",
      "Epoch [4/10], Loss: 6400.8843, AVGLoss: 17662.6172\n",
      "Epoch [5/10], Loss: 11054.7705, AVGLoss: 17231.3248\n",
      "Epoch [6/10], Loss: 5270.1567, AVGLoss: 16844.2134\n",
      "Epoch [7/10], Loss: 8968.8320, AVGLoss: 16525.4597\n",
      "Epoch [8/10], Loss: 5772.0063, AVGLoss: 16242.1570\n",
      "Epoch [9/10], Loss: 6592.5415, AVGLoss: 16004.6862\n",
      "Epoch [10/10], Loss: 11743.1426, AVGLoss: 15780.7757\n",
      "Fold 6, MAE: 57.74171447753906, MSE: 7560.65966796875, R^2: 0.40742727654483846\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 75230.1016, AVGLoss: 26234.8752\n",
      "Epoch [2/10], Loss: 13491.8545, AVGLoss: 18531.8942\n",
      "Epoch [3/10], Loss: 7669.5117, AVGLoss: 17582.5797\n",
      "Epoch [4/10], Loss: 51863.7109, AVGLoss: 17027.5549\n",
      "Epoch [5/10], Loss: 10236.4766, AVGLoss: 16586.0336\n",
      "Epoch [6/10], Loss: 18253.0371, AVGLoss: 16254.0278\n",
      "Epoch [7/10], Loss: 14032.3301, AVGLoss: 15992.2054\n",
      "Epoch [8/10], Loss: 12948.5518, AVGLoss: 15782.3952\n",
      "Epoch [9/10], Loss: 6190.0947, AVGLoss: 15571.4845\n",
      "Epoch [10/10], Loss: 26525.8105, AVGLoss: 15369.4669\n",
      "Fold 7, MAE: 72.71804809570312, MSE: 12557.4716796875, R^2: 0.2043889892763946\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 6431.0972, AVGLoss: 26916.0531\n",
      "Epoch [2/10], Loss: 24719.3691, AVGLoss: 19179.9001\n",
      "Epoch [3/10], Loss: 13255.6680, AVGLoss: 18000.2561\n",
      "Epoch [4/10], Loss: 11724.4268, AVGLoss: 17408.2364\n",
      "Epoch [5/10], Loss: 18833.8965, AVGLoss: 16912.4306\n",
      "Epoch [6/10], Loss: 11081.6221, AVGLoss: 16540.4529\n",
      "Epoch [7/10], Loss: 19011.1035, AVGLoss: 16265.6569\n",
      "Epoch [8/10], Loss: 11310.8193, AVGLoss: 16037.0713\n",
      "Epoch [9/10], Loss: 12857.8350, AVGLoss: 15832.2870\n",
      "Epoch [10/10], Loss: 11327.8350, AVGLoss: 15637.5087\n",
      "Fold 8, MAE: 66.57714080810547, MSE: 10281.8671875, R^2: 0.4767507949677283\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 4332.8423, AVGLoss: 25796.3305\n",
      "Epoch [2/10], Loss: 14433.7607, AVGLoss: 18388.3947\n",
      "Epoch [3/10], Loss: 393082.2500, AVGLoss: 17574.4425\n",
      "Epoch [4/10], Loss: 14460.1758, AVGLoss: 16942.4934\n",
      "Epoch [5/10], Loss: 7872.5146, AVGLoss: 16444.6252\n",
      "Epoch [6/10], Loss: 11074.2471, AVGLoss: 16068.1026\n",
      "Epoch [7/10], Loss: 19464.8105, AVGLoss: 15779.5058\n",
      "Epoch [8/10], Loss: 3515.9944, AVGLoss: 15534.7994\n",
      "Epoch [9/10], Loss: 11204.2275, AVGLoss: 15345.2665\n",
      "Epoch [10/10], Loss: 7235.7402, AVGLoss: 15161.4293\n",
      "Fold 9, MAE: 82.03213500976562, MSE: 18650.072265625, R^2: 0.36400483891088486\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 16990.5508, AVGLoss: 25391.4143\n",
      "Epoch [2/10], Loss: 11634.2012, AVGLoss: 18379.8490\n",
      "Epoch [3/10], Loss: 9802.7949, AVGLoss: 17407.8384\n",
      "Epoch [4/10], Loss: 7241.2705, AVGLoss: 16940.5245\n",
      "Epoch [5/10], Loss: 9775.5723, AVGLoss: 16524.6872\n",
      "Epoch [6/10], Loss: 5487.0664, AVGLoss: 16165.3279\n",
      "Epoch [7/10], Loss: 16831.0254, AVGLoss: 15877.3775\n",
      "Epoch [8/10], Loss: 13432.8730, AVGLoss: 15620.0292\n",
      "Epoch [9/10], Loss: 11585.4414, AVGLoss: 15379.2977\n",
      "Epoch [10/10], Loss: 8668.1504, AVGLoss: 15139.9166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 12:01:10,543] Trial 20 finished with value: 0.40316915015154614 and parameters: {'lr': 0.00033792485169583937, 'num_layers': 2, 'n_units_l0': 59, 'n_units_l1': 127}. Best is trial 19 with value: 0.41561160115995077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 73.32038879394531, MSE: 16520.62890625, R^2: 0.5427052609277031\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 16909.9434, AVGLoss: 32894.5157\n",
      "Epoch [2/10], Loss: 12630.8916, AVGLoss: 27156.8124\n",
      "Epoch [3/10], Loss: 11704.5625, AVGLoss: 26320.6823\n",
      "Epoch [4/10], Loss: 8583.5576, AVGLoss: 25364.9826\n",
      "Epoch [5/10], Loss: 12874.9854, AVGLoss: 24096.7875\n",
      "Epoch [6/10], Loss: 22145.4531, AVGLoss: 22352.9735\n",
      "Epoch [7/10], Loss: 8351.4902, AVGLoss: 20336.9421\n",
      "Epoch [8/10], Loss: 44603.4062, AVGLoss: 18914.7945\n",
      "Epoch [9/10], Loss: 11354.1934, AVGLoss: 18183.0841\n",
      "Epoch [10/10], Loss: 17714.2422, AVGLoss: 17757.3532\n",
      "Fold 1, MAE: 87.29556274414062, MSE: 21224.646484375, R^2: 0.45373620866925257\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 13613.7041, AVGLoss: 27724.9863\n",
      "Epoch [2/10], Loss: 7633.5698, AVGLoss: 22280.9144\n",
      "Epoch [3/10], Loss: 29330.3691, AVGLoss: 21629.7300\n",
      "Epoch [4/10], Loss: 21982.8105, AVGLoss: 21068.8995\n",
      "Epoch [5/10], Loss: 17158.0898, AVGLoss: 20460.9776\n",
      "Epoch [6/10], Loss: 5326.0723, AVGLoss: 19760.3273\n",
      "Epoch [7/10], Loss: 30900.5957, AVGLoss: 18873.5680\n",
      "Epoch [8/10], Loss: 24936.2148, AVGLoss: 17750.0127\n",
      "Epoch [9/10], Loss: 10990.5322, AVGLoss: 16591.3773\n",
      "Epoch [10/10], Loss: 40238.1445, AVGLoss: 15785.0879\n",
      "Fold 2, MAE: 97.20845794677734, MSE: 50038.2734375, R^2: 0.4155914270119667\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 9789.0391, AVGLoss: 33026.4812\n",
      "Epoch [2/10], Loss: 18863.7520, AVGLoss: 26756.3571\n",
      "Epoch [3/10], Loss: 19821.4980, AVGLoss: 25903.3985\n",
      "Epoch [4/10], Loss: 28911.1660, AVGLoss: 24904.8804\n",
      "Epoch [5/10], Loss: 12702.8389, AVGLoss: 23395.7449\n",
      "Epoch [6/10], Loss: 11283.4707, AVGLoss: 21219.1861\n",
      "Epoch [7/10], Loss: 43318.1172, AVGLoss: 19130.3335\n",
      "Epoch [8/10], Loss: 65450.4844, AVGLoss: 18138.3960\n",
      "Epoch [9/10], Loss: 17248.0723, AVGLoss: 17679.4671\n",
      "Epoch [10/10], Loss: 14353.5674, AVGLoss: 17383.4768\n",
      "Fold 3, MAE: 79.24496459960938, MSE: 20444.556640625, R^2: 0.45902465472420895\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 34918.4609, AVGLoss: 34094.3524\n",
      "Epoch [2/10], Loss: 20545.6055, AVGLoss: 28011.9742\n",
      "Epoch [3/10], Loss: 22687.9707, AVGLoss: 27290.4803\n",
      "Epoch [4/10], Loss: 13639.3916, AVGLoss: 26551.4773\n",
      "Epoch [5/10], Loss: 21613.1758, AVGLoss: 25665.4938\n",
      "Epoch [6/10], Loss: 15858.2246, AVGLoss: 24407.7610\n",
      "Epoch [7/10], Loss: 11876.9541, AVGLoss: 22481.8821\n",
      "Epoch [8/10], Loss: 13297.5010, AVGLoss: 20253.0904\n",
      "Epoch [9/10], Loss: 10805.4795, AVGLoss: 18819.9885\n",
      "Epoch [10/10], Loss: 12548.1016, AVGLoss: 18169.3199\n",
      "Fold 4, MAE: 80.77342987060547, MSE: 16385.125, R^2: 0.38773307320228245\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 18489.5625, AVGLoss: 32565.5274\n",
      "Epoch [2/10], Loss: 21093.8398, AVGLoss: 26228.0859\n",
      "Epoch [3/10], Loss: 6765.2285, AVGLoss: 25212.5275\n",
      "Epoch [4/10], Loss: 3866.5017, AVGLoss: 24427.2219\n",
      "Epoch [5/10], Loss: 12141.0947, AVGLoss: 23511.9937\n",
      "Epoch [6/10], Loss: 135964.0156, AVGLoss: 22287.3985\n",
      "Epoch [7/10], Loss: 16113.3613, AVGLoss: 20579.5193\n",
      "Epoch [8/10], Loss: 4789.9092, AVGLoss: 18718.5306\n",
      "Epoch [9/10], Loss: 9694.4102, AVGLoss: 17363.7564\n",
      "Epoch [10/10], Loss: 23158.6289, AVGLoss: 16707.6181\n",
      "Fold 5, MAE: 86.80609893798828, MSE: 27271.873046875, R^2: 0.4098611878257251\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 41181.5859, AVGLoss: 35305.2743\n",
      "Epoch [2/10], Loss: 61475.6133, AVGLoss: 28750.9339\n",
      "Epoch [3/10], Loss: 9397.9922, AVGLoss: 27947.0836\n",
      "Epoch [4/10], Loss: 17670.2383, AVGLoss: 27120.2600\n",
      "Epoch [5/10], Loss: 133663.7500, AVGLoss: 26219.7343\n",
      "Epoch [6/10], Loss: 15788.5479, AVGLoss: 25099.4232\n",
      "Epoch [7/10], Loss: 17214.1895, AVGLoss: 23586.8360\n",
      "Epoch [8/10], Loss: 13159.2480, AVGLoss: 21769.9388\n",
      "Epoch [9/10], Loss: 8688.9697, AVGLoss: 20277.6789\n",
      "Epoch [10/10], Loss: 5880.2407, AVGLoss: 19360.3260\n",
      "Fold 6, MAE: 59.4188346862793, MSE: 7911.369140625, R^2: 0.37994020343297674\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 23543.3164, AVGLoss: 35632.1045\n",
      "Epoch [2/10], Loss: 43950.0586, AVGLoss: 28663.2238\n",
      "Epoch [3/10], Loss: 28224.9180, AVGLoss: 27350.9254\n",
      "Epoch [4/10], Loss: 17190.8691, AVGLoss: 25848.0571\n",
      "Epoch [5/10], Loss: 10338.4463, AVGLoss: 24018.3134\n",
      "Epoch [6/10], Loss: 23695.5293, AVGLoss: 21842.4035\n",
      "Epoch [7/10], Loss: 23688.9414, AVGLoss: 19935.4565\n",
      "Epoch [8/10], Loss: 21303.0410, AVGLoss: 18843.0531\n",
      "Epoch [9/10], Loss: 15214.6445, AVGLoss: 18284.4886\n",
      "Epoch [10/10], Loss: 11569.1250, AVGLoss: 17942.6138\n",
      "Fold 7, MAE: 74.42535400390625, MSE: 12603.48046875, R^2: 0.20147392995787827\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 50231.0312, AVGLoss: 35679.2214\n",
      "Epoch [2/10], Loss: 9604.1045, AVGLoss: 28567.8002\n",
      "Epoch [3/10], Loss: 8437.0107, AVGLoss: 27659.0981\n",
      "Epoch [4/10], Loss: 15933.2939, AVGLoss: 26834.1986\n",
      "Epoch [5/10], Loss: 13617.5811, AVGLoss: 25939.4686\n",
      "Epoch [6/10], Loss: 8745.0557, AVGLoss: 24918.9702\n",
      "Epoch [7/10], Loss: 30262.7871, AVGLoss: 23627.8931\n",
      "Epoch [8/10], Loss: 21470.0996, AVGLoss: 22031.0070\n",
      "Epoch [9/10], Loss: 14298.5693, AVGLoss: 20462.9707\n",
      "Epoch [10/10], Loss: 28612.1016, AVGLoss: 19389.3432\n",
      "Fold 8, MAE: 66.21431732177734, MSE: 10527.7529296875, R^2: 0.4642375264240832\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 3925.6997, AVGLoss: 33958.3365\n",
      "Epoch [2/10], Loss: 12347.8555, AVGLoss: 28177.3611\n",
      "Epoch [3/10], Loss: 12930.9492, AVGLoss: 27111.1708\n",
      "Epoch [4/10], Loss: 13959.8477, AVGLoss: 25836.9050\n",
      "Epoch [5/10], Loss: 8710.7783, AVGLoss: 23943.6685\n",
      "Epoch [6/10], Loss: 2674.2461, AVGLoss: 21536.3690\n",
      "Epoch [7/10], Loss: 9461.0273, AVGLoss: 19733.6575\n",
      "Epoch [8/10], Loss: 7141.5605, AVGLoss: 18843.2974\n",
      "Epoch [9/10], Loss: 9104.9912, AVGLoss: 18364.6026\n",
      "Epoch [10/10], Loss: 14970.4805, AVGLoss: 18035.5840\n",
      "Fold 9, MAE: 82.41036987304688, MSE: 18052.671875, R^2: 0.3843770840146229\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 38996.5898, AVGLoss: 33868.0031\n",
      "Epoch [2/10], Loss: 10035.5078, AVGLoss: 27700.9334\n",
      "Epoch [3/10], Loss: 49354.3750, AVGLoss: 27136.0154\n",
      "Epoch [4/10], Loss: 12726.2734, AVGLoss: 26366.3787\n",
      "Epoch [5/10], Loss: 14903.5420, AVGLoss: 25041.3058\n",
      "Epoch [6/10], Loss: 19794.4453, AVGLoss: 22903.5779\n",
      "Epoch [7/10], Loss: 14203.0244, AVGLoss: 20493.3291\n",
      "Epoch [8/10], Loss: 10190.0195, AVGLoss: 19038.0462\n",
      "Epoch [9/10], Loss: 2387.2959, AVGLoss: 18423.6113\n",
      "Epoch [10/10], Loss: 9123.1143, AVGLoss: 18065.9970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 12:34:12,228] Trial 21 finished with value: 0.4126358455599092 and parameters: {'lr': 2.1483321154431334e-05, 'num_layers': 4, 'n_units_l0': 28, 'n_units_l1': 101, 'n_units_l2': 43, 'n_units_l3': 61}. Best is trial 19 with value: 0.41561160115995077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 72.5330810546875, MSE: 15520.7119140625, R^2: 0.5703831603360949\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 14906.6113, AVGLoss: 41035.0890\n",
      "Epoch [2/10], Loss: 24004.2422, AVGLoss: 29823.8933\n",
      "Epoch [3/10], Loss: 16929.3652, AVGLoss: 27898.1485\n",
      "Epoch [4/10], Loss: 9818.6377, AVGLoss: 27336.7321\n",
      "Epoch [5/10], Loss: 25633.3613, AVGLoss: 26994.7396\n",
      "Epoch [6/10], Loss: 26458.1406, AVGLoss: 26718.4233\n",
      "Epoch [7/10], Loss: 12274.2666, AVGLoss: 26465.6880\n",
      "Epoch [8/10], Loss: 13533.1523, AVGLoss: 26218.5183\n",
      "Epoch [9/10], Loss: 13741.9453, AVGLoss: 25959.1722\n",
      "Epoch [10/10], Loss: 11997.3721, AVGLoss: 25670.1459\n",
      "Fold 1, MAE: 98.08596801757812, MSE: 28306.103515625, R^2: 0.2714790637043728\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 11533.2197, AVGLoss: 36248.0260\n",
      "Epoch [2/10], Loss: 18913.6094, AVGLoss: 24809.2779\n",
      "Epoch [3/10], Loss: 24732.7578, AVGLoss: 22730.8133\n",
      "Epoch [4/10], Loss: 7687.9087, AVGLoss: 22152.3694\n",
      "Epoch [5/10], Loss: 9164.1260, AVGLoss: 21766.6504\n",
      "Epoch [6/10], Loss: 9312.8379, AVGLoss: 21427.7589\n",
      "Epoch [7/10], Loss: 17239.4902, AVGLoss: 21106.9338\n",
      "Epoch [8/10], Loss: 39234.1367, AVGLoss: 20795.7603\n",
      "Epoch [9/10], Loss: 11258.6514, AVGLoss: 20482.3463\n",
      "Epoch [10/10], Loss: 5452.1895, AVGLoss: 20164.6733\n",
      "Fold 2, MAE: 114.4439926147461, MSE: 69093.8046875, R^2: 0.19303739014669663\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 16386.7910, AVGLoss: 41790.1999\n",
      "Epoch [2/10], Loss: 29591.4551, AVGLoss: 28833.0624\n",
      "Epoch [3/10], Loss: 9822.5947, AVGLoss: 27337.5143\n",
      "Epoch [4/10], Loss: 53262.1211, AVGLoss: 26854.3205\n",
      "Epoch [5/10], Loss: 18417.5293, AVGLoss: 26547.7248\n",
      "Epoch [6/10], Loss: 8849.9873, AVGLoss: 26237.7653\n",
      "Epoch [7/10], Loss: 8180.0586, AVGLoss: 25893.4397\n",
      "Epoch [8/10], Loss: 5847.5132, AVGLoss: 25519.0948\n",
      "Epoch [9/10], Loss: 23986.9375, AVGLoss: 25114.9991\n",
      "Epoch [10/10], Loss: 14520.5664, AVGLoss: 24673.5257\n",
      "Fold 3, MAE: 96.92633819580078, MSE: 29630.1953125, R^2: 0.21596718210126686\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 9983.9268, AVGLoss: 42387.5083\n",
      "Epoch [2/10], Loss: 27103.4121, AVGLoss: 29963.5491\n",
      "Epoch [3/10], Loss: 19820.3184, AVGLoss: 28236.0751\n",
      "Epoch [4/10], Loss: 10497.9150, AVGLoss: 27602.8986\n",
      "Epoch [5/10], Loss: 20991.3730, AVGLoss: 26992.0094\n",
      "Epoch [6/10], Loss: 53827.7617, AVGLoss: 26336.6606\n",
      "Epoch [7/10], Loss: 39909.0664, AVGLoss: 25623.7633\n",
      "Epoch [8/10], Loss: 12795.2539, AVGLoss: 24814.8846\n",
      "Epoch [9/10], Loss: 29599.0977, AVGLoss: 23851.7896\n",
      "Epoch [10/10], Loss: 5050.8857, AVGLoss: 22685.8680\n",
      "Fold 4, MAE: 84.44447326660156, MSE: 17677.408203125, R^2: 0.3394440710683403\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 22666.2695, AVGLoss: 41159.9499\n",
      "Epoch [2/10], Loss: 14300.3145, AVGLoss: 28632.1383\n",
      "Epoch [3/10], Loss: 40119.9609, AVGLoss: 26832.5675\n",
      "Epoch [4/10], Loss: 4939.4385, AVGLoss: 26363.1015\n",
      "Epoch [5/10], Loss: 17601.5234, AVGLoss: 26137.8628\n",
      "Epoch [6/10], Loss: 7461.2266, AVGLoss: 25979.3743\n",
      "Epoch [7/10], Loss: 32086.4941, AVGLoss: 25832.3148\n",
      "Epoch [8/10], Loss: 87004.8203, AVGLoss: 25665.1675\n",
      "Epoch [9/10], Loss: 11033.8867, AVGLoss: 25454.5535\n",
      "Epoch [10/10], Loss: 3553.5771, AVGLoss: 25200.2500\n",
      "Fold 5, MAE: 98.39271545410156, MSE: 36909.953125, R^2: 0.20130183101495702\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 10355.1348, AVGLoss: 43228.0916\n",
      "Epoch [2/10], Loss: 21637.6172, AVGLoss: 31064.0950\n",
      "Epoch [3/10], Loss: 7163.5327, AVGLoss: 29367.2865\n",
      "Epoch [4/10], Loss: 40354.3828, AVGLoss: 28819.0752\n",
      "Epoch [5/10], Loss: 25130.3027, AVGLoss: 28471.7344\n",
      "Epoch [6/10], Loss: 29253.4844, AVGLoss: 28172.9312\n",
      "Epoch [7/10], Loss: 22623.8750, AVGLoss: 27868.1777\n",
      "Epoch [8/10], Loss: 9305.9961, AVGLoss: 27548.6861\n",
      "Epoch [9/10], Loss: 9575.0605, AVGLoss: 27210.5910\n",
      "Epoch [10/10], Loss: 21069.4453, AVGLoss: 26860.5048\n",
      "Fold 6, MAE: 84.46286010742188, MSE: 13153.5908203125, R^2: -0.030923081392243645\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 34108.7383, AVGLoss: 43361.3833\n",
      "Epoch [2/10], Loss: 13371.8584, AVGLoss: 30976.1121\n",
      "Epoch [3/10], Loss: 37023.7227, AVGLoss: 29382.1418\n",
      "Epoch [4/10], Loss: 25957.3750, AVGLoss: 28876.4054\n",
      "Epoch [5/10], Loss: 13994.7529, AVGLoss: 28494.0072\n",
      "Epoch [6/10], Loss: 9683.2422, AVGLoss: 28088.3662\n",
      "Epoch [7/10], Loss: 20283.0195, AVGLoss: 27639.1955\n",
      "Epoch [8/10], Loss: 13849.5020, AVGLoss: 27151.9623\n",
      "Epoch [9/10], Loss: 20805.5801, AVGLoss: 26624.4121\n",
      "Epoch [10/10], Loss: 11489.1816, AVGLoss: 26038.7624\n",
      "Fold 7, MAE: 83.94884490966797, MSE: 12954.5810546875, R^2: 0.1792291368977723\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 48324.7031, AVGLoss: 43071.1103\n",
      "Epoch [2/10], Loss: 16603.7344, AVGLoss: 31000.7671\n",
      "Epoch [3/10], Loss: 9891.6631, AVGLoss: 29231.2712\n",
      "Epoch [4/10], Loss: 29414.1777, AVGLoss: 28685.0820\n",
      "Epoch [5/10], Loss: 21935.0527, AVGLoss: 28308.4523\n",
      "Epoch [6/10], Loss: 18091.5332, AVGLoss: 27936.4351\n",
      "Epoch [7/10], Loss: 25411.2090, AVGLoss: 27540.5690\n",
      "Epoch [8/10], Loss: 7082.3530, AVGLoss: 27120.5837\n",
      "Epoch [9/10], Loss: 17349.4844, AVGLoss: 26670.4582\n",
      "Epoch [10/10], Loss: 37809.1367, AVGLoss: 26175.2074\n",
      "Fold 8, MAE: 76.43032836914062, MSE: 13604.0517578125, R^2: 0.30768323296408107\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 12968.4785, AVGLoss: 42308.5961\n",
      "Epoch [2/10], Loss: 77738.0938, AVGLoss: 30610.1380\n",
      "Epoch [3/10], Loss: 15036.9131, AVGLoss: 29032.6768\n",
      "Epoch [4/10], Loss: 15472.5420, AVGLoss: 28448.6370\n",
      "Epoch [5/10], Loss: 32896.9258, AVGLoss: 28008.5808\n",
      "Epoch [6/10], Loss: 7700.5244, AVGLoss: 27572.4193\n",
      "Epoch [7/10], Loss: 15652.5352, AVGLoss: 27115.8503\n",
      "Epoch [8/10], Loss: 6219.1279, AVGLoss: 26630.8143\n",
      "Epoch [9/10], Loss: 10637.8105, AVGLoss: 26109.5015\n",
      "Epoch [10/10], Loss: 11800.3936, AVGLoss: 25533.5518\n",
      "Fold 9, MAE: 85.82225799560547, MSE: 17432.224609375, R^2: 0.40553526500077075\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 15083.1377, AVGLoss: 41646.3638\n",
      "Epoch [2/10], Loss: 30660.9453, AVGLoss: 29550.5462\n",
      "Epoch [3/10], Loss: 39068.1953, AVGLoss: 28268.5375\n",
      "Epoch [4/10], Loss: 6704.8022, AVGLoss: 27734.5923\n",
      "Epoch [5/10], Loss: 12997.7725, AVGLoss: 27353.5802\n",
      "Epoch [6/10], Loss: 13953.2725, AVGLoss: 26983.4151\n",
      "Epoch [7/10], Loss: 23114.3691, AVGLoss: 26583.0464\n",
      "Epoch [8/10], Loss: 14248.9131, AVGLoss: 26173.1438\n",
      "Epoch [9/10], Loss: 34222.4414, AVGLoss: 25738.1994\n",
      "Epoch [10/10], Loss: 32221.9414, AVGLoss: 25252.2244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 13:06:30,734] Trial 22 finished with value: 0.24470164203333092 and parameters: {'lr': 1.0446298953445264e-05, 'num_layers': 4, 'n_units_l0': 28, 'n_units_l1': 102, 'n_units_l2': 36, 'n_units_l3': 53}. Best is trial 19 with value: 0.41561160115995077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 88.6154556274414, MSE: 22967.2109375, R^2: 0.3642623288272948\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 67253.4922, AVGLoss: 29457.0648\n",
      "Epoch [2/10], Loss: 15896.8232, AVGLoss: 23910.3563\n",
      "Epoch [3/10], Loss: 11637.6709, AVGLoss: 19037.8895\n",
      "Epoch [4/10], Loss: 11784.1934, AVGLoss: 17297.4791\n",
      "Epoch [5/10], Loss: 13758.3936, AVGLoss: 16641.0858\n",
      "Epoch [6/10], Loss: 7568.4653, AVGLoss: 16183.6099\n",
      "Epoch [7/10], Loss: 16721.1289, AVGLoss: 15818.7424\n",
      "Epoch [8/10], Loss: 8532.6680, AVGLoss: 15465.8660\n",
      "Epoch [9/10], Loss: 8204.1162, AVGLoss: 15072.3094\n",
      "Epoch [10/10], Loss: 7556.8833, AVGLoss: 14666.7479\n",
      "Fold 1, MAE: 89.26873016357422, MSE: 23829.263671875, R^2: 0.3867006187923524\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 41661.1797, AVGLoss: 24310.3441\n",
      "Epoch [2/10], Loss: 13478.9297, AVGLoss: 20020.7726\n",
      "Epoch [3/10], Loss: 12115.5977, AVGLoss: 16719.3755\n",
      "Epoch [4/10], Loss: 34306.4805, AVGLoss: 14800.3825\n",
      "Epoch [5/10], Loss: 6853.7119, AVGLoss: 14268.8902\n",
      "Epoch [6/10], Loss: 11010.7393, AVGLoss: 13985.0068\n",
      "Epoch [7/10], Loss: 14048.1934, AVGLoss: 13789.2135\n",
      "Epoch [8/10], Loss: 7301.6094, AVGLoss: 13637.1366\n",
      "Epoch [9/10], Loss: 14924.8496, AVGLoss: 13513.0193\n",
      "Epoch [10/10], Loss: 25270.6133, AVGLoss: 13403.3401\n",
      "Fold 2, MAE: 97.3772201538086, MSE: 47846.58984375, R^2: 0.44118858409511197\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 10867.4209, AVGLoss: 29061.7350\n",
      "Epoch [2/10], Loss: 22278.2285, AVGLoss: 24171.9309\n",
      "Epoch [3/10], Loss: 7527.4858, AVGLoss: 19679.6140\n",
      "Epoch [4/10], Loss: 6426.3032, AVGLoss: 17655.9592\n",
      "Epoch [5/10], Loss: 12102.5967, AVGLoss: 16980.7477\n",
      "Epoch [6/10], Loss: 7315.1675, AVGLoss: 16511.5234\n",
      "Epoch [7/10], Loss: 52627.7109, AVGLoss: 16108.8338\n",
      "Epoch [8/10], Loss: 10020.2471, AVGLoss: 15706.3490\n",
      "Epoch [9/10], Loss: 19022.8203, AVGLoss: 15316.3116\n",
      "Epoch [10/10], Loss: 4855.8882, AVGLoss: 14898.4727\n",
      "Fold 3, MAE: 79.22049713134766, MSE: 22661.12890625, R^2: 0.4003728302003974\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 84951.0547, AVGLoss: 29790.8177\n",
      "Epoch [2/10], Loss: 7579.8008, AVGLoss: 24089.8667\n",
      "Epoch [3/10], Loss: 7122.2690, AVGLoss: 19210.6936\n",
      "Epoch [4/10], Loss: 7653.9023, AVGLoss: 17600.7705\n",
      "Epoch [5/10], Loss: 8074.5093, AVGLoss: 17023.5733\n",
      "Epoch [6/10], Loss: 9652.9248, AVGLoss: 16621.6862\n",
      "Epoch [7/10], Loss: 46901.9297, AVGLoss: 16320.0481\n",
      "Epoch [8/10], Loss: 10837.8848, AVGLoss: 16072.2066\n",
      "Epoch [9/10], Loss: 18998.5996, AVGLoss: 15816.6199\n",
      "Epoch [10/10], Loss: 4098.5200, AVGLoss: 15550.7525\n",
      "Fold 4, MAE: 79.06912994384766, MSE: 16592.494140625, R^2: 0.3799843091243498\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 3063.9839, AVGLoss: 28031.3928\n",
      "Epoch [2/10], Loss: 8269.3838, AVGLoss: 22393.4424\n",
      "Epoch [3/10], Loss: 2420.8193, AVGLoss: 18120.8084\n",
      "Epoch [4/10], Loss: 6719.2622, AVGLoss: 16662.6944\n",
      "Epoch [5/10], Loss: 7921.6309, AVGLoss: 16032.2759\n",
      "Epoch [6/10], Loss: 6318.2529, AVGLoss: 15587.6248\n",
      "Epoch [7/10], Loss: 10475.4658, AVGLoss: 15208.3015\n",
      "Epoch [8/10], Loss: 7406.3994, AVGLoss: 14807.1141\n",
      "Epoch [9/10], Loss: 17646.2695, AVGLoss: 14415.3035\n",
      "Epoch [10/10], Loss: 7278.3584, AVGLoss: 14056.3025\n",
      "Fold 5, MAE: 82.33702087402344, MSE: 26165.388671875, R^2: 0.43380448626855583\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 83505.1094, AVGLoss: 31423.9146\n",
      "Epoch [2/10], Loss: 4899.1240, AVGLoss: 25900.3815\n",
      "Epoch [3/10], Loss: 12547.2686, AVGLoss: 21298.9135\n",
      "Epoch [4/10], Loss: 8252.8975, AVGLoss: 18938.6125\n",
      "Epoch [5/10], Loss: 9247.7080, AVGLoss: 18064.8783\n",
      "Epoch [6/10], Loss: 16914.5059, AVGLoss: 17511.2547\n",
      "Epoch [7/10], Loss: 21297.2441, AVGLoss: 17085.8502\n",
      "Epoch [8/10], Loss: 28046.7930, AVGLoss: 16712.0185\n",
      "Epoch [9/10], Loss: 7471.7295, AVGLoss: 16351.8685\n",
      "Epoch [10/10], Loss: 15894.2354, AVGLoss: 15999.5975\n",
      "Fold 6, MAE: 58.15900802612305, MSE: 7095.068359375, R^2: 0.4439183910002851\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 13275.9023, AVGLoss: 31535.2999\n",
      "Epoch [2/10], Loss: 16468.6309, AVGLoss: 25524.3722\n",
      "Epoch [3/10], Loss: 11533.0752, AVGLoss: 19809.9354\n",
      "Epoch [4/10], Loss: 24992.6543, AVGLoss: 17901.0251\n",
      "Epoch [5/10], Loss: 16208.4033, AVGLoss: 17407.7009\n",
      "Epoch [6/10], Loss: 18938.5156, AVGLoss: 17081.4329\n",
      "Epoch [7/10], Loss: 11397.9121, AVGLoss: 16820.0766\n",
      "Epoch [8/10], Loss: 6114.1064, AVGLoss: 16574.0111\n",
      "Epoch [9/10], Loss: 13706.0225, AVGLoss: 16335.0047\n",
      "Epoch [10/10], Loss: 65222.8203, AVGLoss: 16083.1210\n",
      "Fold 7, MAE: 77.47422790527344, MSE: 13783.6181640625, R^2: 0.12670331879219487\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 70391.4609, AVGLoss: 30878.8794\n",
      "Epoch [2/10], Loss: 18923.1328, AVGLoss: 24277.0608\n",
      "Epoch [3/10], Loss: 22454.8438, AVGLoss: 19315.1425\n",
      "Epoch [4/10], Loss: 20941.5234, AVGLoss: 18091.4291\n",
      "Epoch [5/10], Loss: 81141.2344, AVGLoss: 17583.2557\n",
      "Epoch [6/10], Loss: 11042.4531, AVGLoss: 17180.1246\n",
      "Epoch [7/10], Loss: 29338.4141, AVGLoss: 16807.1083\n",
      "Epoch [8/10], Loss: 11827.3799, AVGLoss: 16457.2623\n",
      "Epoch [9/10], Loss: 9748.4473, AVGLoss: 16112.5671\n",
      "Epoch [10/10], Loss: 6958.7695, AVGLoss: 15772.6087\n",
      "Fold 8, MAE: 68.06095123291016, MSE: 10849.3525390625, R^2: 0.4478712205818022\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 4671.7954, AVGLoss: 30567.6954\n",
      "Epoch [2/10], Loss: 4696.5674, AVGLoss: 25522.7685\n",
      "Epoch [3/10], Loss: 3507.0986, AVGLoss: 20175.4711\n",
      "Epoch [4/10], Loss: 12105.8945, AVGLoss: 18429.1693\n",
      "Epoch [5/10], Loss: 9879.3994, AVGLoss: 17763.9330\n",
      "Epoch [6/10], Loss: 56117.5195, AVGLoss: 17254.1434\n",
      "Epoch [7/10], Loss: 12579.2754, AVGLoss: 16826.1430\n",
      "Epoch [8/10], Loss: 13236.9248, AVGLoss: 16413.0068\n",
      "Epoch [9/10], Loss: 3569.7478, AVGLoss: 15942.7565\n",
      "Epoch [10/10], Loss: 7999.2109, AVGLoss: 15447.2160\n",
      "Fold 9, MAE: 79.79829406738281, MSE: 17051.83984375, R^2: 0.4185069233060812\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 13125.9756, AVGLoss: 29599.4126\n",
      "Epoch [2/10], Loss: 10298.6465, AVGLoss: 24352.5308\n",
      "Epoch [3/10], Loss: 7356.7036, AVGLoss: 19209.3222\n",
      "Epoch [4/10], Loss: 14852.0566, AVGLoss: 17623.5243\n",
      "Epoch [5/10], Loss: 12498.6318, AVGLoss: 17053.2425\n",
      "Epoch [6/10], Loss: 7086.8750, AVGLoss: 16645.2908\n",
      "Epoch [7/10], Loss: 21139.4297, AVGLoss: 16285.3353\n",
      "Epoch [8/10], Loss: 8881.2334, AVGLoss: 15896.8633\n",
      "Epoch [9/10], Loss: 2962.1018, AVGLoss: 15489.2405\n",
      "Epoch [10/10], Loss: 8818.4727, AVGLoss: 15093.7181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 13:43:15,227] Trial 23 finished with value: 0.40141640859194655 and parameters: {'lr': 3.818172011372832e-05, 'num_layers': 5, 'n_units_l0': 26, 'n_units_l1': 81, 'n_units_l2': 49, 'n_units_l3': 66, 'n_units_l4': 85}. Best is trial 19 with value: 0.41561160115995077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 71.81346130371094, MSE: 16794.8984375, R^2: 0.5351134037583347\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 13803.7754, AVGLoss: 23437.6252\n",
      "Epoch [2/10], Loss: 15037.0059, AVGLoss: 16052.5719\n",
      "Epoch [3/10], Loss: 52253.3320, AVGLoss: 14427.3607\n",
      "Epoch [4/10], Loss: 10865.8643, AVGLoss: 13291.0052\n",
      "Epoch [5/10], Loss: 6751.2866, AVGLoss: 12570.7178\n",
      "Epoch [6/10], Loss: 8375.0527, AVGLoss: 12107.1494\n",
      "Epoch [7/10], Loss: 7491.1089, AVGLoss: 11768.1360\n",
      "Epoch [8/10], Loss: 7448.6421, AVGLoss: 11500.8481\n",
      "Epoch [9/10], Loss: 3390.7078, AVGLoss: 11269.3186\n",
      "Epoch [10/10], Loss: 6980.6938, AVGLoss: 11049.8507\n",
      "Fold 1, MAE: 90.95266723632812, MSE: 21743.54296875, R^2: 0.4403812675856319\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 3821.6550, AVGLoss: 19637.5591\n",
      "Epoch [2/10], Loss: 12275.0957, AVGLoss: 14399.2130\n",
      "Epoch [3/10], Loss: 29616.8906, AVGLoss: 13747.2101\n",
      "Epoch [4/10], Loss: 17456.1738, AVGLoss: 13370.2541\n",
      "Epoch [5/10], Loss: 10961.4375, AVGLoss: 13051.3550\n",
      "Epoch [6/10], Loss: 9334.8291, AVGLoss: 12704.3442\n",
      "Epoch [7/10], Loss: 11445.2236, AVGLoss: 12358.6314\n",
      "Epoch [8/10], Loss: 13898.5811, AVGLoss: 12015.0014\n",
      "Epoch [9/10], Loss: 16151.1973, AVGLoss: 11688.4587\n",
      "Epoch [10/10], Loss: 8423.0361, AVGLoss: 11359.8167\n",
      "Fold 2, MAE: 107.18539428710938, MSE: 57972.02734375, R^2: 0.3229312574139931\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 17608.6914, AVGLoss: 23949.8771\n",
      "Epoch [2/10], Loss: 23720.8320, AVGLoss: 16862.4781\n",
      "Epoch [3/10], Loss: 9978.2471, AVGLoss: 15647.7678\n",
      "Epoch [4/10], Loss: 4758.4751, AVGLoss: 14462.7478\n",
      "Epoch [5/10], Loss: 6978.4336, AVGLoss: 13466.9566\n",
      "Epoch [6/10], Loss: 18651.0039, AVGLoss: 12718.6480\n",
      "Epoch [7/10], Loss: 12850.8662, AVGLoss: 12249.6006\n",
      "Epoch [8/10], Loss: 5374.8042, AVGLoss: 11928.6923\n",
      "Epoch [9/10], Loss: 3636.7959, AVGLoss: 11704.3133\n",
      "Epoch [10/10], Loss: 6237.7085, AVGLoss: 11497.9904\n",
      "Fold 3, MAE: 85.81192779541016, MSE: 27198.302734375, R^2: 0.28031655415287404\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 4157.2866, AVGLoss: 25211.3619\n",
      "Epoch [2/10], Loss: 26087.5156, AVGLoss: 17169.2679\n",
      "Epoch [3/10], Loss: 40612.6484, AVGLoss: 16022.6426\n",
      "Epoch [4/10], Loss: 8446.7598, AVGLoss: 15140.9200\n",
      "Epoch [5/10], Loss: 19046.7207, AVGLoss: 14366.9256\n",
      "Epoch [6/10], Loss: 20129.8418, AVGLoss: 13579.1710\n",
      "Epoch [7/10], Loss: 2828.6604, AVGLoss: 12978.1974\n",
      "Epoch [8/10], Loss: 15274.2363, AVGLoss: 12561.2860\n",
      "Epoch [9/10], Loss: 10248.9863, AVGLoss: 12240.4937\n",
      "Epoch [10/10], Loss: 15637.3027, AVGLoss: 11975.3602\n",
      "Fold 4, MAE: 74.71240234375, MSE: 15195.3994140625, R^2: 0.43218992063701744\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 7996.3330, AVGLoss: 22314.0552\n",
      "Epoch [2/10], Loss: 6055.0420, AVGLoss: 15869.1497\n",
      "Epoch [3/10], Loss: 27829.0801, AVGLoss: 14695.5283\n",
      "Epoch [4/10], Loss: 3160.0437, AVGLoss: 13478.9157\n",
      "Epoch [5/10], Loss: 13952.9600, AVGLoss: 12479.4622\n",
      "Epoch [6/10], Loss: 16650.7344, AVGLoss: 11845.8123\n",
      "Epoch [7/10], Loss: 13742.7979, AVGLoss: 11432.9727\n",
      "Epoch [8/10], Loss: 21236.7422, AVGLoss: 11117.0903\n",
      "Epoch [9/10], Loss: 5070.3149, AVGLoss: 10827.8744\n",
      "Epoch [10/10], Loss: 22044.4121, AVGLoss: 10550.8630\n",
      "Fold 5, MAE: 80.1072998046875, MSE: 25584.763671875, R^2: 0.44636870026378983\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 7964.2290, AVGLoss: 25742.5953\n",
      "Epoch [2/10], Loss: 40917.1172, AVGLoss: 18119.6450\n",
      "Epoch [3/10], Loss: 69830.7422, AVGLoss: 16987.3183\n",
      "Epoch [4/10], Loss: 6610.3359, AVGLoss: 16076.8146\n",
      "Epoch [5/10], Loss: 10154.2520, AVGLoss: 15242.5513\n",
      "Epoch [6/10], Loss: 13611.0352, AVGLoss: 14593.5271\n",
      "Epoch [7/10], Loss: 19209.6934, AVGLoss: 14121.7862\n",
      "Epoch [8/10], Loss: 7932.4961, AVGLoss: 13790.4390\n",
      "Epoch [9/10], Loss: 8838.4922, AVGLoss: 13538.1990\n",
      "Epoch [10/10], Loss: 15823.5254, AVGLoss: 13370.8864\n",
      "Fold 6, MAE: 66.61592102050781, MSE: 10365.140625, R^2: 0.1876238167060863\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 4657.9224, AVGLoss: 25105.5962\n",
      "Epoch [2/10], Loss: 11479.7920, AVGLoss: 17532.5823\n",
      "Epoch [3/10], Loss: 15989.9297, AVGLoss: 16532.2823\n",
      "Epoch [4/10], Loss: 20171.4863, AVGLoss: 15741.0763\n",
      "Epoch [5/10], Loss: 25606.8047, AVGLoss: 14941.2572\n",
      "Epoch [6/10], Loss: 38095.9297, AVGLoss: 14134.1724\n",
      "Epoch [7/10], Loss: 13275.0850, AVGLoss: 13505.8706\n",
      "Epoch [8/10], Loss: 7101.0771, AVGLoss: 13112.0139\n",
      "Epoch [9/10], Loss: 61220.8867, AVGLoss: 12808.6776\n",
      "Epoch [10/10], Loss: 6754.0513, AVGLoss: 12575.6955\n",
      "Fold 7, MAE: 71.68863677978516, MSE: 13024.322265625, R^2: 0.17481048364356588\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 9387.7373, AVGLoss: 26020.8719\n",
      "Epoch [2/10], Loss: 12584.1211, AVGLoss: 18051.3207\n",
      "Epoch [3/10], Loss: 12674.3975, AVGLoss: 16676.8512\n",
      "Epoch [4/10], Loss: 13643.9141, AVGLoss: 15637.3058\n",
      "Epoch [5/10], Loss: 15781.9756, AVGLoss: 14690.9830\n",
      "Epoch [6/10], Loss: 9413.8682, AVGLoss: 14072.7531\n",
      "Epoch [7/10], Loss: 8065.3960, AVGLoss: 13648.4476\n",
      "Epoch [8/10], Loss: 8449.7510, AVGLoss: 13254.2419\n",
      "Epoch [9/10], Loss: 20010.5234, AVGLoss: 12956.0386\n",
      "Epoch [10/10], Loss: 28786.8594, AVGLoss: 12692.3868\n",
      "Fold 8, MAE: 65.68592834472656, MSE: 10177.80078125, R^2: 0.48204675066173497\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 11260.4062, AVGLoss: 26280.6591\n",
      "Epoch [2/10], Loss: 8058.4272, AVGLoss: 17638.4490\n",
      "Epoch [3/10], Loss: 8436.1250, AVGLoss: 16017.1691\n",
      "Epoch [4/10], Loss: 42232.8008, AVGLoss: 14827.9863\n",
      "Epoch [5/10], Loss: 27120.0781, AVGLoss: 14091.6477\n",
      "Epoch [6/10], Loss: 4186.7847, AVGLoss: 13696.3464\n",
      "Epoch [7/10], Loss: 11101.2393, AVGLoss: 13408.2513\n",
      "Epoch [8/10], Loss: 2190.0146, AVGLoss: 13135.5201\n",
      "Epoch [9/10], Loss: 6052.2344, AVGLoss: 12875.1619\n",
      "Epoch [10/10], Loss: 3372.0889, AVGLoss: 12614.6424\n",
      "Fold 9, MAE: 89.53048706054688, MSE: 23264.00390625, R^2: 0.20666294481481073\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 25514.7422, AVGLoss: 24433.5045\n",
      "Epoch [2/10], Loss: 12108.3623, AVGLoss: 17111.3309\n",
      "Epoch [3/10], Loss: 25633.2246, AVGLoss: 15699.0613\n",
      "Epoch [4/10], Loss: 5930.5615, AVGLoss: 14560.1466\n",
      "Epoch [5/10], Loss: 9477.9766, AVGLoss: 13792.0320\n",
      "Epoch [6/10], Loss: 6881.1104, AVGLoss: 13349.0988\n",
      "Epoch [7/10], Loss: 14948.2227, AVGLoss: 13028.2404\n",
      "Epoch [8/10], Loss: 10308.2930, AVGLoss: 12742.4199\n",
      "Epoch [9/10], Loss: 5878.1191, AVGLoss: 12472.0155\n",
      "Epoch [10/10], Loss: 8583.8896, AVGLoss: 12213.2414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 14:17:58,425] Trial 24 finished with value: 0.3518842942721252 and parameters: {'lr': 0.00012759059081237959, 'num_layers': 4, 'n_units_l0': 100, 'n_units_l1': 105, 'n_units_l2': 56, 'n_units_l3': 37}. Best is trial 19 with value: 0.41561160115995077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 70.70548248291016, MSE: 16419.2578125, R^2: 0.5455112468417478\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 24076.7578, AVGLoss: 29707.7205\n",
      "Epoch [2/10], Loss: 8652.1084, AVGLoss: 23884.9587\n",
      "Epoch [3/10], Loss: 28010.5215, AVGLoss: 19089.9205\n",
      "Epoch [4/10], Loss: 9741.5859, AVGLoss: 16997.6514\n",
      "Epoch [5/10], Loss: 16036.3691, AVGLoss: 16241.2362\n",
      "Epoch [6/10], Loss: 10309.4453, AVGLoss: 15765.7961\n",
      "Epoch [7/10], Loss: 12063.0146, AVGLoss: 15375.6562\n",
      "Epoch [8/10], Loss: 10946.6943, AVGLoss: 15001.5277\n",
      "Epoch [9/10], Loss: 9191.7598, AVGLoss: 14649.7042\n",
      "Epoch [10/10], Loss: 8891.1689, AVGLoss: 14326.1118\n",
      "Fold 1, MAE: 90.78707885742188, MSE: 24016.98046875, R^2: 0.38186927951112415\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 70231.5625, AVGLoss: 24661.2002\n",
      "Epoch [2/10], Loss: 9163.8184, AVGLoss: 19841.0267\n",
      "Epoch [3/10], Loss: 26826.4414, AVGLoss: 16810.8478\n",
      "Epoch [4/10], Loss: 9044.9238, AVGLoss: 15097.4171\n",
      "Epoch [5/10], Loss: 8220.9668, AVGLoss: 14492.4651\n",
      "Epoch [6/10], Loss: 10885.8262, AVGLoss: 14197.1780\n",
      "Epoch [7/10], Loss: 8815.0547, AVGLoss: 14008.9391\n",
      "Epoch [8/10], Loss: 2886.8066, AVGLoss: 13860.2932\n",
      "Epoch [9/10], Loss: 8610.2100, AVGLoss: 13747.7627\n",
      "Epoch [10/10], Loss: 14666.2949, AVGLoss: 13637.5211\n",
      "Fold 2, MAE: 97.41903686523438, MSE: 47579.9765625, R^2: 0.44430237578614973\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 4907.0586, AVGLoss: 29430.4514\n",
      "Epoch [2/10], Loss: 20224.1816, AVGLoss: 23811.1269\n",
      "Epoch [3/10], Loss: 29188.5488, AVGLoss: 19302.7298\n",
      "Epoch [4/10], Loss: 94669.3828, AVGLoss: 17362.2357\n",
      "Epoch [5/10], Loss: 22942.0332, AVGLoss: 16558.0502\n",
      "Epoch [6/10], Loss: 11032.6982, AVGLoss: 15981.5342\n",
      "Epoch [7/10], Loss: 20561.4375, AVGLoss: 15461.6955\n",
      "Epoch [8/10], Loss: 14704.5547, AVGLoss: 14940.5647\n",
      "Epoch [9/10], Loss: 8467.6602, AVGLoss: 14427.3064\n",
      "Epoch [10/10], Loss: 9243.6738, AVGLoss: 13954.4102\n",
      "Fold 3, MAE: 84.69453430175781, MSE: 23951.876953125, R^2: 0.3662188801146282\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 9340.6504, AVGLoss: 30553.0292\n",
      "Epoch [2/10], Loss: 16007.7568, AVGLoss: 24840.6934\n",
      "Epoch [3/10], Loss: 47090.8711, AVGLoss: 20213.0807\n",
      "Epoch [4/10], Loss: 11797.1592, AVGLoss: 17966.3979\n",
      "Epoch [5/10], Loss: 6540.9204, AVGLoss: 17203.2294\n",
      "Epoch [6/10], Loss: 25212.0762, AVGLoss: 16703.7884\n",
      "Epoch [7/10], Loss: 38048.3086, AVGLoss: 16301.6576\n",
      "Epoch [8/10], Loss: 6302.9438, AVGLoss: 15944.8849\n",
      "Epoch [9/10], Loss: 8010.8940, AVGLoss: 15620.6705\n",
      "Epoch [10/10], Loss: 9687.1338, AVGLoss: 15303.2535\n",
      "Fold 4, MAE: 76.85565185546875, MSE: 15983.1279296875, R^2: 0.40275456681454813\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 9767.9795, AVGLoss: 28988.3559\n",
      "Epoch [2/10], Loss: 3345.4678, AVGLoss: 23359.2992\n",
      "Epoch [3/10], Loss: 20252.9199, AVGLoss: 19146.2839\n",
      "Epoch [4/10], Loss: 10020.6768, AVGLoss: 16874.6190\n",
      "Epoch [5/10], Loss: 9015.2881, AVGLoss: 16261.2818\n",
      "Epoch [6/10], Loss: 3166.2737, AVGLoss: 15878.7674\n",
      "Epoch [7/10], Loss: 3946.7288, AVGLoss: 15570.1931\n",
      "Epoch [8/10], Loss: 6489.4790, AVGLoss: 15276.6965\n",
      "Epoch [9/10], Loss: 2853.8914, AVGLoss: 15016.1226\n",
      "Epoch [10/10], Loss: 9630.7939, AVGLoss: 14771.1834\n",
      "Fold 5, MAE: 84.77582550048828, MSE: 26388.33203125, R^2: 0.42898022519286216\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 10728.9131, AVGLoss: 31590.3967\n",
      "Epoch [2/10], Loss: 9270.1338, AVGLoss: 25354.9669\n",
      "Epoch [3/10], Loss: 12862.6416, AVGLoss: 20693.2619\n",
      "Epoch [4/10], Loss: 10431.4111, AVGLoss: 18895.9685\n",
      "Epoch [5/10], Loss: 8019.8022, AVGLoss: 18244.6541\n",
      "Epoch [6/10], Loss: 7008.0317, AVGLoss: 17816.5326\n",
      "Epoch [7/10], Loss: 14626.6270, AVGLoss: 17471.7160\n",
      "Epoch [8/10], Loss: 14559.6279, AVGLoss: 17152.0026\n",
      "Epoch [9/10], Loss: 6407.7520, AVGLoss: 16859.9859\n",
      "Epoch [10/10], Loss: 6313.2915, AVGLoss: 16578.2678\n",
      "Fold 6, MAE: 56.972896575927734, MSE: 7169.337890625, R^2: 0.4380974064670966\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 45866.9570, AVGLoss: 31705.6825\n",
      "Epoch [2/10], Loss: 28194.6367, AVGLoss: 26026.5233\n",
      "Epoch [3/10], Loss: 9142.3643, AVGLoss: 21125.2032\n",
      "Epoch [4/10], Loss: 8610.6406, AVGLoss: 18416.5188\n",
      "Epoch [5/10], Loss: 23670.1211, AVGLoss: 17600.4326\n",
      "Epoch [6/10], Loss: 13861.1465, AVGLoss: 17123.9767\n",
      "Epoch [7/10], Loss: 9253.7559, AVGLoss: 16773.9526\n",
      "Epoch [8/10], Loss: 12822.6582, AVGLoss: 16485.0155\n",
      "Epoch [9/10], Loss: 8645.1230, AVGLoss: 16236.8561\n",
      "Epoch [10/10], Loss: 8080.9961, AVGLoss: 15986.8252\n",
      "Fold 7, MAE: 72.41534423828125, MSE: 13053.6513671875, R^2: 0.172952336100906\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 17627.6289, AVGLoss: 31878.5203\n",
      "Epoch [2/10], Loss: 11846.7100, AVGLoss: 26065.2364\n",
      "Epoch [3/10], Loss: 22563.9668, AVGLoss: 20783.9431\n",
      "Epoch [4/10], Loss: 39153.4258, AVGLoss: 18313.7250\n",
      "Epoch [5/10], Loss: 8366.3662, AVGLoss: 17548.9369\n",
      "Epoch [6/10], Loss: 24178.8027, AVGLoss: 17032.0736\n",
      "Epoch [7/10], Loss: 21392.7793, AVGLoss: 16606.4303\n",
      "Epoch [8/10], Loss: 16881.0664, AVGLoss: 16223.4552\n",
      "Epoch [9/10], Loss: 12310.8906, AVGLoss: 15876.2400\n",
      "Epoch [10/10], Loss: 21728.0801, AVGLoss: 15542.7770\n",
      "Fold 8, MAE: 71.6732177734375, MSE: 11931.6806640625, R^2: 0.3927910852242228\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 8351.3779, AVGLoss: 30990.0267\n",
      "Epoch [2/10], Loss: 13654.0898, AVGLoss: 25605.9720\n",
      "Epoch [3/10], Loss: 18424.1504, AVGLoss: 20471.8449\n",
      "Epoch [4/10], Loss: 21779.1758, AVGLoss: 18004.4254\n",
      "Epoch [5/10], Loss: 49594.6133, AVGLoss: 17258.3209\n",
      "Epoch [6/10], Loss: 9832.5898, AVGLoss: 16730.2688\n",
      "Epoch [7/10], Loss: 23141.0020, AVGLoss: 16243.9709\n",
      "Epoch [8/10], Loss: 12561.6592, AVGLoss: 15783.9206\n",
      "Epoch [9/10], Loss: 6923.8208, AVGLoss: 15356.0795\n",
      "Epoch [10/10], Loss: 3707.6787, AVGLoss: 14952.1598\n",
      "Fold 9, MAE: 83.95073699951172, MSE: 20129.369140625, R^2: 0.3135586297311339\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 28127.6582, AVGLoss: 30184.1668\n",
      "Epoch [2/10], Loss: 14605.8652, AVGLoss: 25006.0655\n",
      "Epoch [3/10], Loss: 27183.7871, AVGLoss: 20602.2416\n",
      "Epoch [4/10], Loss: 23776.6660, AVGLoss: 17955.5993\n",
      "Epoch [5/10], Loss: 3763.1350, AVGLoss: 17092.7567\n",
      "Epoch [6/10], Loss: 15291.6387, AVGLoss: 16509.8431\n",
      "Epoch [7/10], Loss: 20110.2754, AVGLoss: 16013.3541\n",
      "Epoch [8/10], Loss: 10640.4648, AVGLoss: 15578.4787\n",
      "Epoch [9/10], Loss: 12540.7373, AVGLoss: 15165.8279\n",
      "Epoch [10/10], Loss: 14486.0918, AVGLoss: 14778.1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 14:57:52,610] Trial 25 finished with value: 0.392582865811933 and parameters: {'lr': 2.4901720049331996e-05, 'num_layers': 5, 'n_units_l0': 79, 'n_units_l1': 127, 'n_units_l2': 36, 'n_units_l3': 58, 'n_units_l4': 116}. Best is trial 19 with value: 0.41561160115995077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 68.57418823242188, MSE: 15017.7998046875, R^2: 0.5843038731766582\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 17299.8398, AVGLoss: 16654.5039\n",
      "Epoch [2/10], Loss: 22058.9434, AVGLoss: 12301.4788\n",
      "Epoch [3/10], Loss: 7731.2329, AVGLoss: 11042.1050\n",
      "Epoch [4/10], Loss: 19355.0996, AVGLoss: 10194.8166\n",
      "Epoch [5/10], Loss: 4056.3804, AVGLoss: 9481.2111\n",
      "Epoch [6/10], Loss: 10752.3486, AVGLoss: 8798.8181\n",
      "Epoch [7/10], Loss: 6805.0220, AVGLoss: 8186.1032\n",
      "Epoch [8/10], Loss: 9964.0576, AVGLoss: 7633.0046\n",
      "Epoch [9/10], Loss: 4394.8525, AVGLoss: 7238.9520\n",
      "Epoch [10/10], Loss: 5294.0796, AVGLoss: 6844.5106\n",
      "Fold 1, MAE: 82.50650024414062, MSE: 19534.83203125, R^2: 0.4972273938876852\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 11606.8496, AVGLoss: 15220.6350\n",
      "Epoch [2/10], Loss: 15013.6396, AVGLoss: 13246.5957\n",
      "Epoch [3/10], Loss: 7875.4033, AVGLoss: 12540.3905\n",
      "Epoch [4/10], Loss: 1873.0026, AVGLoss: 11535.4072\n",
      "Epoch [5/10], Loss: 4356.2856, AVGLoss: 10316.2904\n",
      "Epoch [6/10], Loss: 7727.9033, AVGLoss: 9431.8104\n",
      "Epoch [7/10], Loss: 3113.0225, AVGLoss: 8590.9870\n",
      "Epoch [8/10], Loss: 1312.2915, AVGLoss: 7663.8881\n",
      "Epoch [9/10], Loss: 7041.5571, AVGLoss: 6945.9784\n",
      "Epoch [10/10], Loss: 4981.2354, AVGLoss: 6417.2093\n",
      "Fold 2, MAE: 144.77247619628906, MSE: 105453.09375, R^2: -0.23161128890580107\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 10307.6592, AVGLoss: 16918.8397\n",
      "Epoch [2/10], Loss: 15451.7461, AVGLoss: 12259.8103\n",
      "Epoch [3/10], Loss: 4492.5513, AVGLoss: 11338.5719\n",
      "Epoch [4/10], Loss: 17192.5703, AVGLoss: 10378.5105\n",
      "Epoch [5/10], Loss: 14314.0947, AVGLoss: 9202.9608\n",
      "Epoch [6/10], Loss: 9147.8174, AVGLoss: 7967.1663\n",
      "Epoch [7/10], Loss: 8008.9336, AVGLoss: 6932.7729\n",
      "Epoch [8/10], Loss: 18987.5254, AVGLoss: 6191.8908\n",
      "Epoch [9/10], Loss: 6401.7114, AVGLoss: 5728.7049\n",
      "Epoch [10/10], Loss: 8081.7070, AVGLoss: 5346.5679\n",
      "Fold 3, MAE: 106.33439636230469, MSE: 41783.47265625, R^2: -0.1056159137191941\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 10203.6260, AVGLoss: 17294.6676\n",
      "Epoch [2/10], Loss: 7142.2905, AVGLoss: 13286.3067\n",
      "Epoch [3/10], Loss: 7072.1133, AVGLoss: 11949.7239\n",
      "Epoch [4/10], Loss: 12733.8477, AVGLoss: 10848.2418\n",
      "Epoch [5/10], Loss: 7000.0093, AVGLoss: 9885.4123\n",
      "Epoch [6/10], Loss: 37315.6641, AVGLoss: 9003.2576\n",
      "Epoch [7/10], Loss: 9715.2119, AVGLoss: 8371.7976\n",
      "Epoch [8/10], Loss: 4802.4937, AVGLoss: 7886.6893\n",
      "Epoch [9/10], Loss: 6794.4370, AVGLoss: 7493.8351\n",
      "Epoch [10/10], Loss: 4254.7651, AVGLoss: 7192.8294\n",
      "Fold 4, MAE: 74.96830749511719, MSE: 15027.287109375, R^2: 0.4384717237261382\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 11509.0303, AVGLoss: 16321.2384\n",
      "Epoch [2/10], Loss: 11481.5566, AVGLoss: 11935.4845\n",
      "Epoch [3/10], Loss: 1629.1381, AVGLoss: 10685.7679\n",
      "Epoch [4/10], Loss: 3244.0754, AVGLoss: 9675.2999\n",
      "Epoch [5/10], Loss: 6272.5801, AVGLoss: 8795.6435\n",
      "Epoch [6/10], Loss: 3618.1040, AVGLoss: 8102.5538\n",
      "Epoch [7/10], Loss: 9446.7500, AVGLoss: 7519.3228\n",
      "Epoch [8/10], Loss: 3903.5806, AVGLoss: 7087.3848\n",
      "Epoch [9/10], Loss: 826.1571, AVGLoss: 6670.9527\n",
      "Epoch [10/10], Loss: 2787.8628, AVGLoss: 6312.8409\n",
      "Fold 5, MAE: 82.66987609863281, MSE: 25097.07421875, R^2: 0.45692185103721006\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 9183.6455, AVGLoss: 18863.2314\n",
      "Epoch [2/10], Loss: 16188.3975, AVGLoss: 14373.0570\n",
      "Epoch [3/10], Loss: 13397.3008, AVGLoss: 12979.2252\n",
      "Epoch [4/10], Loss: 6052.8853, AVGLoss: 11958.5291\n",
      "Epoch [5/10], Loss: 9143.4229, AVGLoss: 10879.7239\n",
      "Epoch [6/10], Loss: 12031.1211, AVGLoss: 9746.2709\n",
      "Epoch [7/10], Loss: 5933.8823, AVGLoss: 9037.4560\n",
      "Epoch [8/10], Loss: 5067.1758, AVGLoss: 8474.2392\n",
      "Epoch [9/10], Loss: 9530.0566, AVGLoss: 8002.2211\n",
      "Epoch [10/10], Loss: 12181.8545, AVGLoss: 7484.3877\n",
      "Fold 6, MAE: 57.80306625366211, MSE: 7377.76806640625, R^2: 0.4217615474218044\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 26720.1191, AVGLoss: 17774.0504\n",
      "Epoch [2/10], Loss: 9465.2539, AVGLoss: 13524.0594\n",
      "Epoch [3/10], Loss: 11045.7178, AVGLoss: 12416.1771\n",
      "Epoch [4/10], Loss: 7951.6270, AVGLoss: 11543.9849\n",
      "Epoch [5/10], Loss: 8528.2910, AVGLoss: 10809.2871\n",
      "Epoch [6/10], Loss: 8158.1426, AVGLoss: 9657.5680\n",
      "Epoch [7/10], Loss: 8720.5234, AVGLoss: 8512.7434\n",
      "Epoch [8/10], Loss: 4537.9790, AVGLoss: 7630.5867\n",
      "Epoch [9/10], Loss: 5917.1978, AVGLoss: 7081.4595\n",
      "Epoch [10/10], Loss: 7026.9463, AVGLoss: 6688.2285\n",
      "Fold 7, MAE: 84.01642608642578, MSE: 20075.35546875, R^2: -0.27192612556680973\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 7470.6836, AVGLoss: 18024.7397\n",
      "Epoch [2/10], Loss: 22051.7051, AVGLoss: 13629.4866\n",
      "Epoch [3/10], Loss: 13625.3398, AVGLoss: 12433.0800\n",
      "Epoch [4/10], Loss: 7508.5742, AVGLoss: 11202.2739\n",
      "Epoch [5/10], Loss: 12534.6572, AVGLoss: 10263.8257\n",
      "Epoch [6/10], Loss: 6144.5571, AVGLoss: 9518.7645\n",
      "Epoch [7/10], Loss: 5761.8730, AVGLoss: 8915.3249\n",
      "Epoch [8/10], Loss: 3305.8271, AVGLoss: 8382.6500\n",
      "Epoch [9/10], Loss: 7701.8892, AVGLoss: 7882.7860\n",
      "Epoch [10/10], Loss: 2953.6228, AVGLoss: 7483.3243\n",
      "Fold 8, MAE: 75.44216918945312, MSE: 16187.517578125, R^2: 0.1762093850229226\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 10413.3535, AVGLoss: 17709.3523\n",
      "Epoch [2/10], Loss: 10785.5107, AVGLoss: 13606.8903\n",
      "Epoch [3/10], Loss: 3816.7974, AVGLoss: 12384.1684\n",
      "Epoch [4/10], Loss: 20374.3984, AVGLoss: 11101.4022\n",
      "Epoch [5/10], Loss: 10935.5898, AVGLoss: 10072.8919\n",
      "Epoch [6/10], Loss: 10602.8516, AVGLoss: 9198.0294\n",
      "Epoch [7/10], Loss: 7428.0010, AVGLoss: 8552.9257\n",
      "Epoch [8/10], Loss: 26610.6777, AVGLoss: 8045.4866\n",
      "Epoch [9/10], Loss: 2378.9451, AVGLoss: 7676.4741\n",
      "Epoch [10/10], Loss: 8310.6992, AVGLoss: 7314.9108\n",
      "Fold 9, MAE: 115.61778259277344, MSE: 55516.3828125, R^2: -0.8931910924971744\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 22084.7344, AVGLoss: 17556.8221\n",
      "Epoch [2/10], Loss: 12247.9980, AVGLoss: 13201.4531\n",
      "Epoch [3/10], Loss: 30294.7051, AVGLoss: 11550.6555\n",
      "Epoch [4/10], Loss: 9431.8652, AVGLoss: 10259.0625\n",
      "Epoch [5/10], Loss: 10323.4443, AVGLoss: 9176.1287\n",
      "Epoch [6/10], Loss: 7383.4058, AVGLoss: 8334.4484\n",
      "Epoch [7/10], Loss: 5354.1387, AVGLoss: 7419.1695\n",
      "Epoch [8/10], Loss: 14187.7334, AVGLoss: 6633.3426\n",
      "Epoch [9/10], Loss: 6762.4937, AVGLoss: 6034.4874\n",
      "Epoch [10/10], Loss: 4771.1528, AVGLoss: 5626.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 15:33:16,538] Trial 26 finished with value: 0.1002345695623652 and parameters: {'lr': 0.0006829540139294841, 'num_layers': 4, 'n_units_l0': 55, 'n_units_l1': 81, 'n_units_l2': 67, 'n_units_l3': 81}. Best is trial 19 with value: 0.41561160115995077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 73.3755111694336, MSE: 17554.111328125, R^2: 0.5140982152168708\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 5227.9741, AVGLoss: 14973.4256\n",
      "Epoch [2/10], Loss: 8200.7871, AVGLoss: 11331.8927\n",
      "Epoch [3/10], Loss: 8431.4053, AVGLoss: 10313.7616\n",
      "Epoch [4/10], Loss: 11063.4902, AVGLoss: 9560.7615\n",
      "Epoch [5/10], Loss: 4588.3496, AVGLoss: 8900.1376\n",
      "Epoch [6/10], Loss: 7055.3823, AVGLoss: 8363.4064\n",
      "Epoch [7/10], Loss: 7949.6426, AVGLoss: 7924.9776\n",
      "Epoch [8/10], Loss: 6424.0532, AVGLoss: 7747.6882\n",
      "Epoch [9/10], Loss: 5811.0239, AVGLoss: 7313.6048\n",
      "Epoch [10/10], Loss: 6138.5986, AVGLoss: 7534.1626\n",
      "Fold 1, MAE: 86.59569549560547, MSE: 20371.953125, R^2: 0.475682169259964\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 22303.2246, AVGLoss: 14619.2492\n",
      "Epoch [2/10], Loss: 7901.9951, AVGLoss: 12514.0994\n",
      "Epoch [3/10], Loss: 12072.8301, AVGLoss: 11132.4900\n",
      "Epoch [4/10], Loss: 16315.8857, AVGLoss: 9757.4663\n",
      "Epoch [5/10], Loss: 9721.7031, AVGLoss: 8631.8618\n",
      "Epoch [6/10], Loss: 7450.0684, AVGLoss: 7701.7283\n",
      "Epoch [7/10], Loss: 2084.6848, AVGLoss: 6912.0230\n",
      "Epoch [8/10], Loss: 4433.6343, AVGLoss: 6392.6560\n",
      "Epoch [9/10], Loss: 1533.1725, AVGLoss: 5885.0549\n",
      "Epoch [10/10], Loss: 7495.8267, AVGLoss: 5472.7978\n",
      "Fold 2, MAE: 120.90866088867188, MSE: 84397.5078125, R^2: 0.014301789279420052\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 56281.7812, AVGLoss: 15695.5893\n",
      "Epoch [2/10], Loss: 20763.6504, AVGLoss: 12032.3065\n",
      "Epoch [3/10], Loss: 7976.7769, AVGLoss: 10908.3839\n",
      "Epoch [4/10], Loss: 2671.3887, AVGLoss: 9521.3855\n",
      "Epoch [5/10], Loss: 9214.1475, AVGLoss: 8004.3775\n",
      "Epoch [6/10], Loss: 2895.3066, AVGLoss: 7059.4474\n",
      "Epoch [7/10], Loss: 3958.3333, AVGLoss: 6435.7156\n",
      "Epoch [8/10], Loss: 6718.5376, AVGLoss: 6038.0885\n",
      "Epoch [9/10], Loss: 29427.9219, AVGLoss: 5732.8122\n",
      "Epoch [10/10], Loss: 873.2187, AVGLoss: 5488.7665\n",
      "Fold 3, MAE: 106.48894500732422, MSE: 38960.23046875, R^2: -0.030911219343496166\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 8227.3047, AVGLoss: 15793.5390\n",
      "Epoch [2/10], Loss: 7240.1968, AVGLoss: 12737.6928\n",
      "Epoch [3/10], Loss: 30981.3379, AVGLoss: 11543.5094\n",
      "Epoch [4/10], Loss: 8146.6060, AVGLoss: 10526.6113\n",
      "Epoch [5/10], Loss: 6620.5029, AVGLoss: 9946.1168\n",
      "Epoch [6/10], Loss: 4522.6143, AVGLoss: 9424.0747\n",
      "Epoch [7/10], Loss: 5350.7876, AVGLoss: 8777.0218\n",
      "Epoch [8/10], Loss: 8223.2441, AVGLoss: 8203.9710\n",
      "Epoch [9/10], Loss: 3271.0962, AVGLoss: 7625.1789\n",
      "Epoch [10/10], Loss: 7363.7051, AVGLoss: 7230.9043\n",
      "Fold 4, MAE: 78.08625793457031, MSE: 15434.4052734375, R^2: 0.4232589301011207\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 4052.3508, AVGLoss: 14815.2189\n",
      "Epoch [2/10], Loss: 11706.0244, AVGLoss: 11012.7968\n",
      "Epoch [3/10], Loss: 29729.6211, AVGLoss: 9501.5830\n",
      "Epoch [4/10], Loss: 3522.5759, AVGLoss: 8540.7188\n",
      "Epoch [5/10], Loss: 2670.5376, AVGLoss: 7821.2105\n",
      "Epoch [6/10], Loss: 8441.3262, AVGLoss: 7234.8874\n",
      "Epoch [7/10], Loss: 5974.6582, AVGLoss: 6798.8378\n",
      "Epoch [8/10], Loss: 3169.3271, AVGLoss: 6344.4328\n",
      "Epoch [9/10], Loss: 6205.3789, AVGLoss: 5998.1808\n",
      "Epoch [10/10], Loss: 5490.2017, AVGLoss: 5630.8568\n",
      "Fold 5, MAE: 98.7120590209961, MSE: 37152.40234375, R^2: 0.19605535072726343\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 13445.2158, AVGLoss: 16801.8768\n",
      "Epoch [2/10], Loss: 11471.5635, AVGLoss: 13536.2261\n",
      "Epoch [3/10], Loss: 2311.2354, AVGLoss: 12305.0294\n",
      "Epoch [4/10], Loss: 8590.7510, AVGLoss: 11117.1852\n",
      "Epoch [5/10], Loss: 6737.1021, AVGLoss: 10364.9637\n",
      "Epoch [6/10], Loss: 3458.7310, AVGLoss: 9382.7840\n",
      "Epoch [7/10], Loss: 7166.3779, AVGLoss: 8687.5636\n",
      "Epoch [8/10], Loss: 7962.7886, AVGLoss: 8199.6009\n",
      "Epoch [9/10], Loss: 8173.7271, AVGLoss: 7832.2693\n",
      "Epoch [10/10], Loss: 7919.4414, AVGLoss: 7566.3194\n",
      "Fold 6, MAE: 57.435394287109375, MSE: 7197.9443359375, R^2: 0.43585536696354166\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 8440.1523, AVGLoss: 16539.4916\n",
      "Epoch [2/10], Loss: 8916.4180, AVGLoss: 13296.3824\n",
      "Epoch [3/10], Loss: 8826.8994, AVGLoss: 11339.2274\n",
      "Epoch [4/10], Loss: 8353.5117, AVGLoss: 9341.8399\n",
      "Epoch [5/10], Loss: 8001.2593, AVGLoss: 8315.3282\n",
      "Epoch [6/10], Loss: 6689.0430, AVGLoss: 7936.2798\n",
      "Epoch [7/10], Loss: 7183.8330, AVGLoss: 7135.0217\n",
      "Epoch [8/10], Loss: 7560.5439, AVGLoss: 6653.5974\n",
      "Epoch [9/10], Loss: 4838.8350, AVGLoss: 6268.6952\n",
      "Epoch [10/10], Loss: 6316.4248, AVGLoss: 5865.5718\n",
      "Fold 7, MAE: 87.78923034667969, MSE: 21863.708984375, R^2: -0.385231708114375\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 45920.0586, AVGLoss: 16368.9040\n",
      "Epoch [2/10], Loss: 59449.0195, AVGLoss: 12228.3779\n",
      "Epoch [3/10], Loss: 6305.0527, AVGLoss: 10120.0843\n",
      "Epoch [4/10], Loss: 11003.6787, AVGLoss: 8877.4434\n",
      "Epoch [5/10], Loss: 9043.3906, AVGLoss: 8472.4216\n",
      "Epoch [6/10], Loss: 9041.8262, AVGLoss: 8059.9045\n",
      "Epoch [7/10], Loss: 9007.2881, AVGLoss: 7530.8782\n",
      "Epoch [8/10], Loss: 6219.6235, AVGLoss: 6826.5708\n",
      "Epoch [9/10], Loss: 16210.7178, AVGLoss: 6443.6928\n",
      "Epoch [10/10], Loss: 3868.9426, AVGLoss: 6109.7141\n",
      "Fold 8, MAE: 72.18082427978516, MSE: 15669.880859375, R^2: 0.20255218826476296\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 4896.2578, AVGLoss: 16142.3930\n",
      "Epoch [2/10], Loss: 5090.8901, AVGLoss: 12739.1920\n",
      "Epoch [3/10], Loss: 4578.1025, AVGLoss: 11510.7060\n",
      "Epoch [4/10], Loss: 11967.2002, AVGLoss: 10522.1721\n",
      "Epoch [5/10], Loss: 7651.5190, AVGLoss: 9854.1275\n",
      "Epoch [6/10], Loss: 2408.3665, AVGLoss: 9423.0863\n",
      "Epoch [7/10], Loss: 8929.0625, AVGLoss: 8952.2224\n",
      "Epoch [8/10], Loss: 4195.8037, AVGLoss: 8616.6278\n",
      "Epoch [9/10], Loss: 5742.8135, AVGLoss: 8227.0207\n",
      "Epoch [10/10], Loss: 13793.7637, AVGLoss: 7965.9504\n",
      "Fold 9, MAE: 89.3362045288086, MSE: 24069.1015625, R^2: 0.17920796494660152\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 20197.2910, AVGLoss: 15797.8870\n",
      "Epoch [2/10], Loss: 3906.7876, AVGLoss: 12280.0150\n",
      "Epoch [3/10], Loss: 14885.2812, AVGLoss: 10858.7955\n",
      "Epoch [4/10], Loss: 6043.6201, AVGLoss: 9791.8880\n",
      "Epoch [5/10], Loss: 7140.5952, AVGLoss: 8836.0416\n",
      "Epoch [6/10], Loss: 21205.4512, AVGLoss: 8233.8481\n",
      "Epoch [7/10], Loss: 11252.4727, AVGLoss: 7578.3978\n",
      "Epoch [8/10], Loss: 7101.3779, AVGLoss: 7102.6959\n",
      "Epoch [9/10], Loss: 1652.5131, AVGLoss: 6355.4561\n",
      "Epoch [10/10], Loss: 4983.4468, AVGLoss: 5837.3520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 16:09:11,298] Trial 27 finished with value: 0.2002333869373254 and parameters: {'lr': 0.001899975871816656, 'num_layers': 5, 'n_units_l0': 40, 'n_units_l1': 65, 'n_units_l2': 24, 'n_units_l3': 42, 'n_units_l4': 58}. Best is trial 19 with value: 0.41561160115995077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 73.55255126953125, MSE: 18368.236328125, R^2: 0.49156303728845085\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 8731.0615, AVGLoss: 30719.6775\n",
      "Epoch [2/10], Loss: 22710.5156, AVGLoss: 26614.6483\n",
      "Epoch [3/10], Loss: 16483.9570, AVGLoss: 25708.0700\n",
      "Epoch [4/10], Loss: 37843.0000, AVGLoss: 24627.0094\n",
      "Epoch [5/10], Loss: 36979.8711, AVGLoss: 23275.3049\n",
      "Epoch [6/10], Loss: 12910.6572, AVGLoss: 21651.2790\n",
      "Epoch [7/10], Loss: 6364.6890, AVGLoss: 20209.2302\n",
      "Epoch [8/10], Loss: 30269.2363, AVGLoss: 19248.0041\n",
      "Epoch [9/10], Loss: 21473.7871, AVGLoss: 18614.6614\n",
      "Epoch [10/10], Loss: 5005.9360, AVGLoss: 18161.1642\n",
      "Fold 1, MAE: 90.52285766601562, MSE: 21725.013671875, R^2: 0.4408581882745316\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 127197.2734, AVGLoss: 25515.6170\n",
      "Epoch [2/10], Loss: 16119.8594, AVGLoss: 21557.8044\n",
      "Epoch [3/10], Loss: 9929.1973, AVGLoss: 20796.0725\n",
      "Epoch [4/10], Loss: 21648.4805, AVGLoss: 19788.1088\n",
      "Epoch [5/10], Loss: 11834.1641, AVGLoss: 18338.0925\n",
      "Epoch [6/10], Loss: 21361.8086, AVGLoss: 16689.3347\n",
      "Epoch [7/10], Loss: 16888.3555, AVGLoss: 15549.4800\n",
      "Epoch [8/10], Loss: 3114.0027, AVGLoss: 15000.3711\n",
      "Epoch [9/10], Loss: 10126.5273, AVGLoss: 14739.9407\n",
      "Epoch [10/10], Loss: 4151.7939, AVGLoss: 14581.5328\n",
      "Fold 2, MAE: 93.53914642333984, MSE: 48086.015625, R^2: 0.4383922090390663\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 31757.4531, AVGLoss: 30751.3972\n",
      "Epoch [2/10], Loss: 12059.5459, AVGLoss: 26250.3382\n",
      "Epoch [3/10], Loss: 18034.4062, AVGLoss: 25132.3510\n",
      "Epoch [4/10], Loss: 8053.6655, AVGLoss: 23675.5067\n",
      "Epoch [5/10], Loss: 6476.4888, AVGLoss: 21600.2434\n",
      "Epoch [6/10], Loss: 11434.8564, AVGLoss: 19154.3715\n",
      "Epoch [7/10], Loss: 9443.7266, AVGLoss: 17784.3543\n",
      "Epoch [8/10], Loss: 19798.1211, AVGLoss: 17195.0010\n",
      "Epoch [9/10], Loss: 4198.9775, AVGLoss: 16810.2707\n",
      "Epoch [10/10], Loss: 27369.6426, AVGLoss: 16523.2565\n",
      "Fold 3, MAE: 81.44204711914062, MSE: 21637.06640625, R^2: 0.42747014403436134\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 15670.1289, AVGLoss: 31874.9347\n",
      "Epoch [2/10], Loss: 23803.5898, AVGLoss: 27886.4815\n",
      "Epoch [3/10], Loss: 53641.7812, AVGLoss: 27363.9929\n",
      "Epoch [4/10], Loss: 23974.2852, AVGLoss: 26606.1100\n",
      "Epoch [5/10], Loss: 11336.4941, AVGLoss: 25486.2738\n",
      "Epoch [6/10], Loss: 31143.9219, AVGLoss: 23969.2404\n",
      "Epoch [7/10], Loss: 16867.1348, AVGLoss: 21842.4480\n",
      "Epoch [8/10], Loss: 29090.3887, AVGLoss: 19758.3161\n",
      "Epoch [9/10], Loss: 32400.3594, AVGLoss: 18564.9319\n",
      "Epoch [10/10], Loss: 13565.1670, AVGLoss: 18030.6551\n",
      "Fold 4, MAE: 80.7905044555664, MSE: 16617.302734375, R^2: 0.37905721156866357\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 11188.6475, AVGLoss: 29928.8349\n",
      "Epoch [2/10], Loss: 8280.7344, AVGLoss: 25588.7019\n",
      "Epoch [3/10], Loss: 6014.4932, AVGLoss: 24588.7788\n",
      "Epoch [4/10], Loss: 16950.4941, AVGLoss: 23360.0531\n",
      "Epoch [5/10], Loss: 5434.4902, AVGLoss: 21636.2597\n",
      "Epoch [6/10], Loss: 3303.2615, AVGLoss: 19458.5065\n",
      "Epoch [7/10], Loss: 7430.6396, AVGLoss: 17857.4369\n",
      "Epoch [8/10], Loss: 12753.7227, AVGLoss: 17114.7183\n",
      "Epoch [9/10], Loss: 10364.4365, AVGLoss: 16727.0895\n",
      "Epoch [10/10], Loss: 26986.2363, AVGLoss: 16476.7899\n",
      "Fold 5, MAE: 89.29131317138672, MSE: 28401.5078125, R^2: 0.38541689446444116\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 96256.6562, AVGLoss: 33018.4072\n",
      "Epoch [2/10], Loss: 12037.1885, AVGLoss: 28110.8884\n",
      "Epoch [3/10], Loss: 76900.7734, AVGLoss: 27107.1349\n",
      "Epoch [4/10], Loss: 21134.0781, AVGLoss: 25775.6557\n",
      "Epoch [5/10], Loss: 6194.3081, AVGLoss: 23992.1403\n",
      "Epoch [6/10], Loss: 34612.0664, AVGLoss: 21737.1000\n",
      "Epoch [7/10], Loss: 5248.4189, AVGLoss: 19849.7057\n",
      "Epoch [8/10], Loss: 4684.3823, AVGLoss: 18866.8478\n",
      "Epoch [9/10], Loss: 4008.5332, AVGLoss: 18390.6815\n",
      "Epoch [10/10], Loss: 11479.7979, AVGLoss: 18107.1938\n",
      "Fold 6, MAE: 55.892982482910156, MSE: 7082.990234375, R^2: 0.44486503322839865\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 14055.2295, AVGLoss: 32842.8635\n",
      "Epoch [2/10], Loss: 14081.3984, AVGLoss: 28529.4358\n",
      "Epoch [3/10], Loss: 34808.7383, AVGLoss: 27481.7015\n",
      "Epoch [4/10], Loss: 23636.0000, AVGLoss: 25476.5978\n",
      "Epoch [5/10], Loss: 22562.2031, AVGLoss: 22290.4887\n",
      "Epoch [6/10], Loss: 9088.7490, AVGLoss: 19813.7401\n",
      "Epoch [7/10], Loss: 28854.6797, AVGLoss: 18912.8546\n",
      "Epoch [8/10], Loss: 11739.4199, AVGLoss: 18514.2510\n",
      "Epoch [9/10], Loss: 8192.3252, AVGLoss: 18238.8711\n",
      "Epoch [10/10], Loss: 13666.5537, AVGLoss: 18026.9221\n",
      "Fold 7, MAE: 74.91498565673828, MSE: 12608.6484375, R^2: 0.20114652024020463\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 11982.2705, AVGLoss: 32569.3395\n",
      "Epoch [2/10], Loss: 8288.3027, AVGLoss: 27810.0653\n",
      "Epoch [3/10], Loss: 27359.9277, AVGLoss: 26194.0678\n",
      "Epoch [4/10], Loss: 12290.9072, AVGLoss: 24388.5916\n",
      "Epoch [5/10], Loss: 11332.3516, AVGLoss: 21940.2261\n",
      "Epoch [6/10], Loss: 83023.0078, AVGLoss: 19749.7616\n",
      "Epoch [7/10], Loss: 11022.9727, AVGLoss: 18771.2660\n",
      "Epoch [8/10], Loss: 69777.0469, AVGLoss: 18328.8185\n",
      "Epoch [9/10], Loss: 6861.0044, AVGLoss: 18037.0374\n",
      "Epoch [10/10], Loss: 20915.2773, AVGLoss: 17805.0188\n",
      "Fold 8, MAE: 68.2151107788086, MSE: 10990.5830078125, R^2: 0.44068389109318207\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 45220.6562, AVGLoss: 32279.3391\n",
      "Epoch [2/10], Loss: 18072.2148, AVGLoss: 28063.5683\n",
      "Epoch [3/10], Loss: 11089.4600, AVGLoss: 26980.6649\n",
      "Epoch [4/10], Loss: 11225.7314, AVGLoss: 25469.8815\n",
      "Epoch [5/10], Loss: 26820.7344, AVGLoss: 23322.0352\n",
      "Epoch [6/10], Loss: 11108.9688, AVGLoss: 20790.1946\n",
      "Epoch [7/10], Loss: 6040.1328, AVGLoss: 19296.1876\n",
      "Epoch [8/10], Loss: 8357.5225, AVGLoss: 18639.7546\n",
      "Epoch [9/10], Loss: 22964.9922, AVGLoss: 18257.3384\n",
      "Epoch [10/10], Loss: 19546.9883, AVGLoss: 17960.5847\n",
      "Fold 9, MAE: 80.75325012207031, MSE: 15829.9990234375, R^2: 0.4601735252323098\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 10745.0273, AVGLoss: 31609.4602\n",
      "Epoch [2/10], Loss: 7831.7388, AVGLoss: 27391.4408\n",
      "Epoch [3/10], Loss: 17119.0645, AVGLoss: 26918.2591\n",
      "Epoch [4/10], Loss: 19693.9863, AVGLoss: 25856.3850\n",
      "Epoch [5/10], Loss: 22332.2246, AVGLoss: 23914.1686\n",
      "Epoch [6/10], Loss: 7441.7661, AVGLoss: 21541.1440\n",
      "Epoch [7/10], Loss: 17093.6641, AVGLoss: 19631.9108\n",
      "Epoch [8/10], Loss: 10152.9287, AVGLoss: 18715.8237\n",
      "Epoch [9/10], Loss: 7334.3389, AVGLoss: 18339.5379\n",
      "Epoch [10/10], Loss: 11334.2578, AVGLoss: 18120.0969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 16:38:39,391] Trial 28 finished with value: 0.41893336317808016 and parameters: {'lr': 5.044450031349452e-05, 'num_layers': 3, 'n_units_l0': 25, 'n_units_l1': 90, 'n_units_l2': 56}. Best is trial 28 with value: 0.41893336317808016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 72.32888793945312, MSE: 15488.669921875, R^2: 0.5712700146056426\n",
      "Start Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/mihaid/opt/anaconda3/envs/phytree/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 19411.2930, AVGLoss: 31536.0268\n",
      "Epoch [2/10], Loss: 25182.1680, AVGLoss: 26510.2512\n",
      "Epoch [3/10], Loss: 19318.4141, AVGLoss: 25264.9635\n",
      "Epoch [4/10], Loss: 21267.2207, AVGLoss: 23960.0873\n",
      "Epoch [5/10], Loss: 10027.9297, AVGLoss: 22438.4050\n",
      "Epoch [6/10], Loss: 18341.2441, AVGLoss: 20720.6018\n",
      "Epoch [7/10], Loss: 8798.7842, AVGLoss: 19095.2771\n",
      "Epoch [8/10], Loss: 18660.0820, AVGLoss: 17990.5390\n",
      "Epoch [9/10], Loss: 6937.2905, AVGLoss: 17377.9368\n",
      "Epoch [10/10], Loss: 11380.5742, AVGLoss: 16975.5280\n",
      "Fold 1, MAE: 89.35684204101562, MSE: 22223.9609375, R^2: 0.4280165857472584\n",
      "Start Fold 2\n",
      "Epoch [1/10], Loss: 48699.8047, AVGLoss: 26178.6820\n",
      "Epoch [2/10], Loss: 9073.4023, AVGLoss: 21757.9683\n",
      "Epoch [3/10], Loss: 8561.2090, AVGLoss: 21082.3218\n",
      "Epoch [4/10], Loss: 13929.4551, AVGLoss: 20346.1652\n",
      "Epoch [5/10], Loss: 12506.0410, AVGLoss: 19492.2390\n",
      "Epoch [6/10], Loss: 7982.6455, AVGLoss: 18380.5643\n",
      "Epoch [7/10], Loss: 11446.7051, AVGLoss: 17062.9651\n",
      "Epoch [8/10], Loss: 19931.4609, AVGLoss: 15995.8864\n",
      "Epoch [9/10], Loss: 31528.1973, AVGLoss: 15407.5151\n",
      "Epoch [10/10], Loss: 8491.1816, AVGLoss: 15104.2046\n",
      "Fold 2, MAE: 96.59779357910156, MSE: 50929.625, R^2: 0.4051810366673858\n",
      "Start Fold 3\n",
      "Epoch [1/10], Loss: 13916.9482, AVGLoss: 31378.7767\n",
      "Epoch [2/10], Loss: 40312.5586, AVGLoss: 26722.0399\n",
      "Epoch [3/10], Loss: 13253.6045, AVGLoss: 26510.2208\n",
      "Epoch [4/10], Loss: 27081.1738, AVGLoss: 26328.1239\n",
      "Epoch [5/10], Loss: 14196.6797, AVGLoss: 25888.3532\n",
      "Epoch [6/10], Loss: 16653.2773, AVGLoss: 24873.0831\n",
      "Epoch [7/10], Loss: 11156.1992, AVGLoss: 23111.3914\n",
      "Epoch [8/10], Loss: 11364.0557, AVGLoss: 20876.9771\n",
      "Epoch [9/10], Loss: 84048.9688, AVGLoss: 19102.8986\n",
      "Epoch [10/10], Loss: 14978.1641, AVGLoss: 18277.5141\n",
      "Fold 3, MAE: 83.49436950683594, MSE: 21877.97265625, R^2: 0.42109564550100986\n",
      "Start Fold 4\n",
      "Epoch [1/10], Loss: 13546.9072, AVGLoss: 32044.1844\n",
      "Epoch [2/10], Loss: 12499.7686, AVGLoss: 27266.0458\n",
      "Epoch [3/10], Loss: 16976.3496, AVGLoss: 26178.4548\n",
      "Epoch [4/10], Loss: 31518.7363, AVGLoss: 25103.4257\n",
      "Epoch [5/10], Loss: 82961.3984, AVGLoss: 23502.4367\n",
      "Epoch [6/10], Loss: 47485.1992, AVGLoss: 21250.8676\n",
      "Epoch [7/10], Loss: 14267.8164, AVGLoss: 19379.4106\n",
      "Epoch [8/10], Loss: 11614.5273, AVGLoss: 18367.7010\n",
      "Epoch [9/10], Loss: 9686.2656, AVGLoss: 17815.9953\n",
      "Epoch [10/10], Loss: 5180.2036, AVGLoss: 17441.5278\n",
      "Fold 4, MAE: 79.87405395507812, MSE: 16584.359375, R^2: 0.3802883363993331\n",
      "Start Fold 5\n",
      "Epoch [1/10], Loss: 19628.6875, AVGLoss: 30151.1046\n",
      "Epoch [2/10], Loss: 19795.0723, AVGLoss: 25592.3760\n",
      "Epoch [3/10], Loss: 8521.7471, AVGLoss: 24592.8817\n",
      "Epoch [4/10], Loss: 14861.7021, AVGLoss: 23323.5948\n",
      "Epoch [5/10], Loss: 6340.9590, AVGLoss: 21532.5910\n",
      "Epoch [6/10], Loss: 8117.7349, AVGLoss: 19165.3834\n",
      "Epoch [7/10], Loss: 24881.6250, AVGLoss: 17407.5620\n",
      "Epoch [8/10], Loss: 26686.7090, AVGLoss: 16699.5026\n",
      "Epoch [9/10], Loss: 3235.8489, AVGLoss: 16379.5829\n",
      "Epoch [10/10], Loss: 5643.4707, AVGLoss: 16162.0678\n",
      "Fold 5, MAE: 87.27360534667969, MSE: 27375.853515625, R^2: 0.40761112647498676\n",
      "Start Fold 6\n",
      "Epoch [1/10], Loss: 5836.3872, AVGLoss: 33317.0464\n",
      "Epoch [2/10], Loss: 15013.4814, AVGLoss: 28416.9934\n",
      "Epoch [3/10], Loss: 11844.0723, AVGLoss: 27658.3282\n",
      "Epoch [4/10], Loss: 11264.2549, AVGLoss: 26719.6072\n",
      "Epoch [5/10], Loss: 11768.4551, AVGLoss: 25466.9667\n",
      "Epoch [6/10], Loss: 15731.5498, AVGLoss: 23809.4663\n",
      "Epoch [7/10], Loss: 32569.2793, AVGLoss: 21895.9968\n",
      "Epoch [8/10], Loss: 10243.5078, AVGLoss: 20305.9274\n",
      "Epoch [9/10], Loss: 31406.9844, AVGLoss: 19427.2408\n",
      "Epoch [10/10], Loss: 20476.6348, AVGLoss: 18956.4107\n",
      "Fold 6, MAE: 59.12609100341797, MSE: 7655.35693359375, R^2: 0.4000053150895\n",
      "Start Fold 7\n",
      "Epoch [1/10], Loss: 11883.2793, AVGLoss: 33125.0130\n",
      "Epoch [2/10], Loss: 134264.3750, AVGLoss: 28519.7607\n",
      "Epoch [3/10], Loss: 17570.3496, AVGLoss: 27708.6006\n",
      "Epoch [4/10], Loss: 68766.9922, AVGLoss: 26625.8370\n",
      "Epoch [5/10], Loss: 105149.8047, AVGLoss: 25292.5574\n",
      "Epoch [6/10], Loss: 31237.1855, AVGLoss: 23484.3407\n",
      "Epoch [7/10], Loss: 13780.4883, AVGLoss: 21362.8052\n",
      "Epoch [8/10], Loss: 21155.3906, AVGLoss: 19758.4307\n",
      "Epoch [9/10], Loss: 12525.0020, AVGLoss: 18856.1148\n",
      "Epoch [10/10], Loss: 31792.9824, AVGLoss: 18321.1482\n",
      "Fold 7, MAE: 75.80728912353516, MSE: 12743.5087890625, R^2: 0.19260206026701887\n",
      "Start Fold 8\n",
      "Epoch [1/10], Loss: 18047.4453, AVGLoss: 33090.3091\n",
      "Epoch [2/10], Loss: 60778.6250, AVGLoss: 28159.8439\n",
      "Epoch [3/10], Loss: 14175.2842, AVGLoss: 26926.5032\n",
      "Epoch [4/10], Loss: 119751.9688, AVGLoss: 25498.3188\n",
      "Epoch [5/10], Loss: 11600.7861, AVGLoss: 23708.5618\n",
      "Epoch [6/10], Loss: 13808.2861, AVGLoss: 21495.3621\n",
      "Epoch [7/10], Loss: 9721.7236, AVGLoss: 19700.6710\n",
      "Epoch [8/10], Loss: 28184.0156, AVGLoss: 18808.3637\n",
      "Epoch [9/10], Loss: 15871.4658, AVGLoss: 18372.1640\n",
      "Epoch [10/10], Loss: 11208.0156, AVGLoss: 18079.4873\n",
      "Fold 8, MAE: 67.41193389892578, MSE: 10785.5166015625, R^2: 0.4511198103423675\n",
      "Start Fold 9\n",
      "Epoch [1/10], Loss: 6787.5581, AVGLoss: 32351.0842\n",
      "Epoch [2/10], Loss: 24153.9121, AVGLoss: 28092.4350\n",
      "Epoch [3/10], Loss: 22223.5020, AVGLoss: 27312.7389\n",
      "Epoch [4/10], Loss: 35212.6602, AVGLoss: 26319.4057\n",
      "Epoch [5/10], Loss: 14038.8555, AVGLoss: 25052.4294\n",
      "Epoch [6/10], Loss: 22241.3086, AVGLoss: 23262.0832\n",
      "Epoch [7/10], Loss: 2036.0463, AVGLoss: 20913.1709\n",
      "Epoch [8/10], Loss: 20949.9707, AVGLoss: 19125.6042\n",
      "Epoch [9/10], Loss: 17190.0625, AVGLoss: 18315.9209\n",
      "Epoch [10/10], Loss: 149777.0781, AVGLoss: 17903.6413\n",
      "Fold 9, MAE: 81.27217864990234, MSE: 17436.1796875, R^2: 0.4054003497570099\n",
      "Start Fold 10\n",
      "Epoch [1/10], Loss: 15289.3916, AVGLoss: 31581.8262\n",
      "Epoch [2/10], Loss: 33403.3203, AVGLoss: 27065.2585\n",
      "Epoch [3/10], Loss: 9126.1670, AVGLoss: 26299.7443\n",
      "Epoch [4/10], Loss: 37961.5820, AVGLoss: 25413.7186\n",
      "Epoch [5/10], Loss: 9880.2939, AVGLoss: 24410.1976\n",
      "Epoch [6/10], Loss: 9738.8809, AVGLoss: 23142.7707\n",
      "Epoch [7/10], Loss: 20448.8594, AVGLoss: 21511.6085\n",
      "Epoch [8/10], Loss: 8335.9795, AVGLoss: 19887.0141\n",
      "Epoch [9/10], Loss: 11680.0283, AVGLoss: 18717.0951\n",
      "Epoch [10/10], Loss: 9054.5322, AVGLoss: 18030.1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 17:07:02,921] Trial 29 finished with value: 0.40263376615399044 and parameters: {'lr': 4.902399951952506e-05, 'num_layers': 3, 'n_units_l0': 24, 'n_units_l1': 91, 'n_units_l2': 48}. Best is trial 28 with value: 0.41893336317808016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10, MAE: 75.07625579833984, MSE: 16798.365234375, R^2: 0.5350173952940345\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "OUTPUT_SIZE = 1  # predicting only 'd_ll_merged' value\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "def objective(trial):\n",
    "\t# Define the hyperparameters to tune\n",
    "\tlr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "\tnum_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "\thidden_sizes = [trial.suggest_int(f'n_units_l{i}', 16, 128) for i in range(num_layers)]\n",
    "\t#n_splits = trial.suggest_int('n_splits', 5, len(groups.unique()))\n",
    "\n",
    "\t# Cross-validation\n",
    "\tgkf = GroupKFold(n_splits=10)\n",
    "\tmae_kfold = []\n",
    "\tr2_kfold = []\n",
    "\tfor fold, (train_idx, val_idx) in enumerate(gkf.split(features_scaled, labels, groups=groups)):\n",
    "\t\tprint(f\"Start Fold {fold+1}\")\n",
    "\n",
    "\t\tX_train_fold, y_train_fold = features_scaled[train_idx], labels[train_idx]\n",
    "\t\tX_val_fold, y_val_fold = features_scaled[val_idx], labels[val_idx]\n",
    "\t\t\n",
    "\t\ttrain_dataset = TensorDataset(torch.tensor(X_train_fold, dtype=torch.float32), \n",
    "\t\t\t\t\t\t\t\t\ttorch.tensor(y_train_fold, dtype=torch.float32))\n",
    "\t\tval_dataset = TensorDataset(torch.tensor(X_val_fold, dtype=torch.float32), \n",
    "\t\t\t\t\t\t\t\t\ttorch.tensor(y_val_fold, dtype=torch.float32))\n",
    "\t\t\n",
    "\t\ttrain_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\t\tval_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE)\n",
    "  \n",
    "\t\tinput_size = X_train_fold.shape[1]  # Number of features\n",
    "\t\tmodel = DynamicRegressionModel(input_size, hidden_sizes, OUTPUT_SIZE)\n",
    "\t\tcriterion = nn.MSELoss()\n",
    "\t\toptimizer = torch.optim.Adam(model.parameters(), lr=lr)\t\t\n",
    "\t\t\n",
    "\t\t# Training loop for the current fold\n",
    "\t\tnum_epochs = NUM_EPOCHS\n",
    "\t\tfor epoch in range(num_epochs):\n",
    "\t\t\tepoch_losses = []\n",
    "\t\t\tfor inputs, targets in train_loader:\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\toutputs = model(inputs)\n",
    "\t\t\t\tloss = criterion(outputs, targets.view(-1, 1))\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\t\t\n",
    "\t\t\t\tepoch_losses.append(loss.item())\n",
    "\t\t\t\n",
    "\t\t\tavg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "\t\t\tprint(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, AVGLoss: {avg_loss:.4f}')\n",
    "\n",
    "\t\tmodel.eval()  # Set the model to evaluation mode\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tpredictions = []\n",
    "\t\t\tactuals = []\n",
    "\t\t\tfor X_batch, y_batch in val_loader:\n",
    "\t\t\t\ty_pred = model(X_batch)\n",
    "\t\t\t\tpredictions.append(y_pred.numpy())\n",
    "\t\t\t\tactuals.append(y_batch.numpy())\n",
    "\n",
    "\t\t\t# Flatten the list if predictions and actuals are nested lists\n",
    "\t\t\tpredictions = np.concatenate(predictions, axis=0)\n",
    "\t\t\tactuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "\t\t\tmae = mean_absolute_error(actuals, predictions)\n",
    "\t\t\tmse = mean_squared_error(actuals, predictions)\n",
    "\t\t\tr2 = r2_score(actuals, predictions)\n",
    "\t\t\tprint(f'Fold {fold+1}, MAE: {mae}, MSE: {mse}, R^2: {r2}')\n",
    "\t\tmae_kfold.append(mae)\n",
    "\t\tr2_kfold.append(r2)\n",
    "\n",
    "\treturn np.mean(r2_kfold)\n",
    "\n",
    "study = optuna.create_study(direction= 'maximize')\n",
    "#study = optuna.create_study(directions=['minimize','maximize'])\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best hyperparameters\n",
    "best_hyperparams = study.best_trial\n",
    "print(f\"Best hyperparameters: {best_hyperparams.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-17 17:49:49,526] Using an existing study with name 'valStudy30Trial' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "study_name = \"valStudy\"  # Unique identifier of the study.\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "# Save the sampler with pickle to be loaded later.\n",
    "with open(\"sampler.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study.sampler, fout)\n",
    "\n",
    "restored_sampler = pickle.load(open(\"sampler.pkl\", \"rb\"))\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name, storage=storage_name, load_if_exists=True, sampler=restored_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_param_importances(study)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phytree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
